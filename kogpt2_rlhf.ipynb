{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLUYAx-jSMVQ"
      },
      "source": [
        "# Make ChatGPT-replica!!\n",
        "\n",
        "\"학습을 시작하기 전에\" 파트를 반드시 실행시켜 주세요.\n",
        "\n",
        "각 파트 사이사이 마다 raise Exception 구문이 있기 때문에, 한 파트만 학습하고 싶은 경우에도 그냥 이후 셀 실행 하면 됩니다.\n",
        "\n",
        "한 번에 1~3번을 모두 수행하고 싶은 경우, 중간중간에 있는 에러 구문을 제거해주시기 바랍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습을 시작하기 전에"
      ],
      "metadata": {
        "id": "xDB-y_f4RoYQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m5CDIjagvjy"
      },
      "source": [
        "### Google Drive에 모델 저장하기\n",
        "한 번 학습한 모델을 재활용하기 위해 google drive에 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BJFXDikuOLC",
        "outputId": "21596ec7-bbd9-48e6-9b79-de951231b8e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bKSqYythYwF"
      },
      "source": [
        "### 상수, 경로 설정 부분"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPqW4G2WhcAR"
      },
      "outputs": [],
      "source": [
        "# Pretrained model 이름(hugging face) or 체크포인트 저장 경로\n",
        "SFT_MODEL_NAME = './drive/MyDrive/Models/final_SFT_F'\n",
        "\n",
        "SFT_DATASET_PATH = './drive/MyDrive/Models/instagram_chatgpt_F.jsonl'\n",
        "SFT_MODEL_PATH = './drive/MyDrive/Models/final_SFT_F'\n",
        "SFT_MODEL_OUTPUT_PATH = './drive/MyDrive/Models/final_SFT_F'\n",
        "# SFT 모델을 학습시킬 때 샘플링 여부. \n",
        "# 샘플링하지 않고 모든 데이터를 학습시킬 경우 0으로 두기\n",
        "SFT_SAMPLE_DATA_SIZE = 0\n",
        "\n",
        "RM_DATASET_PATH = './drive/MyDrive/Models/kakao_cleaned_rm.jsonl'\n",
        "RM_MODEL_PATH = './drive/MyDrive/Models/final_RM'\n",
        "RM_MODEL_OUTPUT_PATH = './drive/MyDrive/Models/final_RM'\n",
        "\n",
        "PPO_DATASET_PATH = './drive/MyDrive/Models/facebook_ppo.jsonl'\n",
        "PPO_MODEL_PATH = './drive/MyDrive/Models/final_PPO_light_F'\n",
        "PPO_MODEL_OUTPUT_PATH = './drive/MyDrive/Models/final_PPO_light_F'\n",
        "\n",
        "# Inference 시 질문 목록\n",
        "PROMPT_LIST = [\n",
        "  '나 기분 좋아서 옷 샀어',\n",
        "\t'나 오늘 좋은 일 있어서 신발 샀어',\n",
        "\t'나 기분 안 좋아서 쇼핑다녀왔어',\n",
        "\t'너 기분 안 좋아보여서 아이스크림 사왔어',\n",
        "\t'나 돈 모아서 컴퓨터 샀어',\n",
        "\t'나 학교 가는 길에 교통사고 났어',\n",
        "\t'나 기분 안 좋아서 머리 잘랐어',\n",
        "\t'요즘 취업 준비하느라 힘들어',\n",
        "\t'오늘 늦게일어나서 대충 머리감고 나왔어',\n",
        "\t'걔가 너 싫어한대',\n",
        "\t'나 배탈 난 것 같아',\n",
        "\t'나 감기 걸린 것 같아',\n",
        "\t'코로나 걸렸어',\n",
        "\t'시험에 떨어졌어',\n",
        "\t'우울해서 아이패드 샀어',\n",
        "\t'나 부모님한테 혼났어',\n",
        "\t'이러면 아무도 너 안 좋아해',\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import modules"
      ],
      "metadata": {
        "id": "w-w-RwdbTFe9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LIg6pniqSMVU",
        "outputId": "8a33a3a4-f1ea-4a14-e27c-88980f3b4cc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.0.1+cu118\n",
            "Uninstalling torch-2.0.1+cu118:\n",
            "  Successfully uninstalled torch-2.0.1+cu118\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu116\n",
            "Collecting torch==1.13.1+cu116\n",
            "  Downloading https://download.pytorch.org/whl/cu116/torch-1.13.1%2Bcu116-cp310-cp310-linux_x86_64.whl (1977.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m897.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1+cu116) (4.5.0)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1+cu116 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1+cu116 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1+cu116 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.13.1+cu116 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.13.1+cu116\n",
            "Torch version:1.13.1+cu116\n",
            "cuda version: 11.6\n",
            "cudnn version:8302\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting colossalai==0.2.7\n",
            "  Downloading colossalai-0.2.7.tar.gz (686 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m686.7/686.7 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (4.65.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (5.9.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (23.1)\n",
            "Collecting pre-commit (from colossalai==0.2.7)\n",
            "  Downloading pre_commit-3.3.2-py2.py3-none-any.whl (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.8/202.8 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (13.3.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (8.1.3)\n",
            "Collecting fabric (from colossalai==0.2.7)\n",
            "  Downloading fabric-3.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contexttimer (from colossalai==0.2.7)\n",
            "  Downloading contexttimer-0.3.3.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ninja (from colossalai==0.2.7)\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (1.13.1+cu116)\n",
            "Collecting invoke>=2.0 (from fabric->colossalai==0.2.7)\n",
            "  Downloading invoke-2.1.2-py3-none-any.whl (160 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting paramiko>=2.4 (from fabric->colossalai==0.2.7)\n",
            "  Downloading paramiko-3.2.0-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.2/224.2 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator>=5 (from fabric->colossalai==0.2.7)\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit->colossalai==0.2.7)\n",
            "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit->colossalai==0.2.7)\n",
            "  Downloading identify-2.5.24-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nodeenv>=0.11.1 (from pre-commit->colossalai==0.2.7)\n",
            "  Downloading nodeenv-1.8.0-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit->colossalai==0.2.7) (6.0)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit->colossalai==0.2.7)\n",
            "  Downloading virtualenv-20.23.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m109.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->colossalai==0.2.7) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->colossalai==0.2.7) (2.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->colossalai==0.2.7) (4.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->colossalai==0.2.7) (0.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nodeenv>=0.11.1->pre-commit->colossalai==0.2.7) (67.7.2)\n",
            "Collecting bcrypt>=3.2 (from paramiko>=2.4->fabric->colossalai==0.2.7)\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.4->fabric->colossalai==0.2.7) (40.0.2)\n",
            "Collecting pynacl>=1.5 (from paramiko>=2.4->fabric->colossalai==0.2.7)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.6 (from virtualenv>=20.10.0->pre-commit->colossalai==0.2.7)\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->colossalai==0.2.7) (3.12.0)\n",
            "Requirement already satisfied: platformdirs<4,>=3.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->colossalai==0.2.7) (3.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3->paramiko>=2.4->fabric->colossalai==0.2.7) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.4->fabric->colossalai==0.2.7) (2.21)\n",
            "Building wheels for collected packages: colossalai, contexttimer\n",
            "  Building wheel for colossalai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colossalai: filename=colossalai-0.2.7-py3-none-any.whl size=896479 sha256=fe033021605992b94c1703794a5be2b3d2daa8a0ff62ca241b3e4c29b4635a85\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/85/25/32a3af943ea5ca261b1b51dae74a4629599ce1bc6fe58dbbfc\n",
            "  Building wheel for contexttimer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contexttimer: filename=contexttimer-0.3.3-py3-none-any.whl size=5803 sha256=358f35eec09ad5ef827bb70f98e3cc9a4f55f2a87cc081114108e20d1ec6aa4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/1c/da/cfd97201d88ccce214427fa84a5caeb91fef7c5a1b4c4312b4\n",
            "Successfully built colossalai contexttimer\n",
            "Installing collected packages: ninja, distlib, contexttimer, virtualenv, nodeenv, invoke, identify, decorator, cfgv, bcrypt, pynacl, pre-commit, paramiko, fabric, colossalai\n",
            "  Attempting uninstall: decorator\n",
            "    Found existing installation: decorator 4.4.2\n",
            "    Uninstalling decorator-4.4.2:\n",
            "      Successfully uninstalled decorator-4.4.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bcrypt-4.0.1 cfgv-3.3.1 colossalai-0.2.7 contexttimer-0.3.3 decorator-5.1.1 distlib-0.3.6 fabric-3.1.0 identify-2.5.24 invoke-2.1.2 ninja-1.11.1 nodeenv-1.8.0 paramiko-3.2.0 pre-commit-3.3.2 pynacl-1.5.0 virtualenv-20.23.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "decorator"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KoChatGPT'...\n",
            "remote: Enumerating objects: 240, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 240 (delta 63), reused 84 (delta 45), pack-reused 129\u001b[K\n",
            "Receiving objects: 100% (240/240), 11.57 MiB | 18.31 MiB/s, done.\n",
            "Resolving deltas: 100% (93/93), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.7 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langchain==0.0.113\n",
            "  Downloading langchain-0.0.113-py3-none-any.whl (396 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.0/396.0 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML<7,>=6 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.113) (6.0)\n",
            "Collecting SQLAlchemy<2,>=1 (from langchain==0.0.113)\n",
            "  Downloading SQLAlchemy-1.4.48-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.113) (3.8.4)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.113)\n",
            "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.113) (1.22.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.113) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.113) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.113) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.113) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.113) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.113) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.113) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.113) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.113) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.113) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.113)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.113)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.113)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain==0.0.113) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.113) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.113) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.113) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2,>=1->langchain==0.0.113) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.113) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.113)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: SQLAlchemy, mypy-extensions, marshmallow, typing-inspect, marshmallow-enum, dataclasses-json, langchain\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.10\n",
            "    Uninstalling SQLAlchemy-2.0.10:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.10\n",
            "Successfully installed SQLAlchemy-1.4.48 dataclasses-json-0.5.7 langchain-0.0.113 marshmallow-3.19.0 marshmallow-enum-1.5.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.28.0\n",
            "  Downloading transformers-4.28.0-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m118.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers==4.28.0)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m127.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Collecting responses<0.19 (from datasets)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, responses, multiprocess, datasets\n",
            "Successfully installed datasets-2.12.0 dill-0.3.6 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting loralib\n",
            "  Downloading loralib-0.1.1-py3-none-any.whl (8.8 kB)\n",
            "Installing collected packages: loralib\n",
            "Successfully installed loralib-0.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.113)\n",
            "Requirement already satisfied: PyYAML<7,>=6 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.4.48)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.7)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "## setup(1min)\n",
        "# torch 버전 다운. torch>=2.0 에선 colosalai가 동작안함\n",
        "!pip uninstall torch -y\n",
        "!pip install torch==1.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "\n",
        "import torch\n",
        "\n",
        "print(\"Torch version:{}\".format(torch.__version__))\n",
        "print(\"cuda version: {}\".format(torch.version.cuda))\n",
        "\n",
        "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))\n",
        "\n",
        "\n",
        "# for ColossalAI\n",
        "!pip install colossalai==0.2.7\n",
        "\n",
        "# setup data\n",
        "!git clone https://github.com/airobotlab/KoChatGPT\n",
        "\n",
        "# setup library\n",
        "!pip install openai\n",
        "!pip install langchain==0.0.113\n",
        "!pip install pandas>=1.4.1\n",
        "!pip install transformers==4.28.0\n",
        "!pip install tqdm\n",
        "!pip install datasets\n",
        "!pip install loralib\n",
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 코랩 안꺼지게 하기\n",
        "\n",
        "function ClickConnect() {\n",
        "    var buttons = document.querySelectorAll(\"colab-dialog.yes-no-dialog paper-button#cancel\"); \n",
        "    buttons.forEach(function(btn) { \n",
        "        btn.click(); \n",
        "    }); \n",
        "    console.log(\"1분마다 자동 재연결\"); \n",
        "    document.querySelector(\"colab-toolbar-button#connect\").click(); \n",
        "} \n",
        "setInterval(ClickConnect,1000*60);\n",
        "\n",
        "function CleanCurrentOutput(){ \n",
        "    var btn = document.querySelector(\".output-icon.clear_outputs_enabled.output-icon-selected[title$='현재 실행 중...'] iron-icon[command=clear-focused-or-selected-outputs]\"); \n",
        "    if(btn) { console.log(\"30분마다 출력 지우기\");\n",
        "     btn.click(); \n",
        "    } \n",
        "} \n",
        "setInterval(CleanCurrentOutput,1000*60*30);"
      ],
      "metadata": {
        "id": "-yI02vwC50b0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Supervised Fine Tuning"
      ],
      "metadata": {
        "id": "mXO7hOuFwvaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import"
      ],
      "metadata": {
        "id": "PfLmVk-OV2PR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51S4uJpbSMVV"
      },
      "outputs": [],
      "source": [
        "# import\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from datasets import load_dataset\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, pipeline\n",
        "from transformers import Trainer, TrainingArguments, AutoModelWithLMHead\n",
        "from copy import deepcopy\n",
        "from torch.optim import Adam\n",
        "from transformers import AutoTokenizer, BloomTokenizerFast\n",
        "from transformers.models.gpt2.tokenization_gpt2 import GPT2Tokenizer\n",
        "import pandas as pd\n",
        "import argparse\n",
        "import copy\n",
        "import logging\n",
        "import json\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "def safe_save_model_for_hf_trainer(trainer: transformers.Trainer, output_dir: str):\n",
        "    \"\"\"Collects the state dict and dump to disk.\"\"\"\n",
        "    state_dict = trainer.model.state_dict()\n",
        "    if trainer.args.should_save:\n",
        "        cpu_state_dict = {key: value.cpu() for key, value in list(state_dict.items())}\n",
        "        del state_dict\n",
        "        trainer._save(output_dir, state_dict=cpu_state_dict)  # noqa"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## hyperparameter 설정"
      ],
      "metadata": {
        "id": "Utr3zHndV5di"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4OzdlU9SMVV",
        "outputId": "1bba98b0-c62b-413c-d6dc-45b70d123fa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_path_1_SFT='./drive/MyDrive/Models/instagram_chatgpt_F.jsonl', model_name='./drive/MyDrive/Models/final_SFT_F', max_epochs=7, train_batch_size=16, output_dir='./drive/MyDrive/Models/final_SFT_F', save_steps=5000)\n"
          ]
        }
      ],
      "source": [
        "# define argment\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--data_path_1_SFT', type=str, default=SFT_DATASET_PATH)\n",
        "parser.add_argument('--model_name', type=str, default='gpt2')\n",
        "parser.add_argument('--max_epochs', type=int, default=5)\n",
        "parser.add_argument('--train_batch_size', type=int, default=16)\n",
        "parser.add_argument('--output_dir', type=str, default=SFT_MODEL_OUTPUT_PATH)\n",
        "parser.add_argument('--save_steps', type=int, default=5000)\n",
        "\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "# for test\n",
        "args.model_name = SFT_MODEL_NAME  # SK GPT2, https://github.com/SKT-AI/KoGPT2\n",
        "\n",
        "args.max_epochs = 7\n",
        "\n",
        "print(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXT_zkuwSMVX"
      },
      "outputs": [],
      "source": [
        "# data config\n",
        "IGNORE_INDEX = -100\n",
        "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
        "DEFAULT_EOS_TOKEN = \"</s>\"\n",
        "DEFAULT_BOS_TOKEN = \"</s>\"\n",
        "DEFAULT_UNK_TOKEN = \"</s>\"\n",
        "PROMPT_DICT = {\n",
        "    \"prompt_input\": (\n",
        "        \"### Instruction(명령어):\\n{query}\\n\\n### Input(입력):\\n{input}\\n\\n### Response(응답):\"\n",
        "    ),\n",
        "    \"prompt_no_input\": (\n",
        "        \"### Instruction(명령어):\\n{query}\\n\\n### Response(응답):\"\n",
        "    ),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "c42212169dd142b187891ae00899cdbd",
            "90421c9714764cb58b12cbd97425210f",
            "d416153857704318bf073727295c7f17",
            "fdb7094202424f43815dc444891e83a1",
            "c0eca855ae2b4043a16226e5aa0e104d",
            "ebfe23c3b0e24c8db6db9d25295d0d4d",
            "01cf0d336a5d40178b7d9d44a2a29534",
            "287f1dac848148e7abfff0f2fd2f7bee",
            "8c5e4848adc34783ac1edf6df3a1e3f3",
            "645f7c7da3a242f6bd109435a3abe248",
            "934a7cc9ac394bd9a887def3254a97e6",
            "b0bfc5fa5c4a44798b661b3917d459e3",
            "091d6922084d4c37bcf32d44cc922a13",
            "407fc7a4381e45ed8055cfd1084dce03",
            "cb2b71e3663241189724139c53d1308c",
            "6d9fdac856d74d6c884944e177b60345",
            "f323550d64be4ab8bd96dcde3b20e5f6",
            "5ef6968a652849abbd3d9c79ea65d59e",
            "2d24caf9a62f40f88ad911c77888f0c6",
            "39c3b738fe164a639b6a2b80ebed4373",
            "e017504dc5f741d0b1afbabc3b316f1d",
            "899a004ed222431ba0635181c4ee60a7"
          ]
        },
        "id": "_a_EbaW8SMVX",
        "outputId": "23c41d6f-b54f-400b-bd69-04216353349c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c42212169dd142b187891ae00899cdbd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0bfc5fa5c4a44798b661b3917d459e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2TokenizerFast(name_or_path='skt/kogpt2-base-v2', vocab_size=51200, model_max_length=64, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '</s>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=True)\n"
          ]
        }
      ],
      "source": [
        "## 모델 준비\n",
        "model = AutoModelForCausalLM.from_pretrained(args.model_name)\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "    \"skt/kogpt2-base-v2\",\n",
        "    padding_side=\"right\",\n",
        "    model_max_length=64,    \n",
        ")\n",
        "tokenizer.add_special_tokens(\n",
        "    {\n",
        "        \"eos_token\": DEFAULT_EOS_TOKEN,\n",
        "        \"bos_token\": DEFAULT_BOS_TOKEN,\n",
        "        \"unk_token\": DEFAULT_UNK_TOKEN,\n",
        "    }\n",
        ")    \n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "print(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"model name : {args.model_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZ8DaAQc9Hbv",
        "outputId": "40df3330-5691-4bf1-bf25-32f8e0321fa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model name : ./drive/MyDrive/Models/final_SFT_F\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E6u3j_YSMVX",
        "outputId": "e87e2f94-d039-4158-87fa-54f4afb43970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Loading data...\n",
            "WARNING:root:Loading data done!!: 9000\n"
          ]
        }
      ],
      "source": [
        "## prepare data\n",
        "from typing import Optional, Dict, Sequence\n",
        "import random\n",
        "import math\n",
        "    \n",
        "class SFT_dataset(Dataset):\n",
        "    def __init__(self, data_path_1_SFT: str, tokenizer: transformers.PreTrainedTokenizer, verbose=False):\n",
        "        super(SFT_dataset, self).__init__()\n",
        "        logging.warning(\"Loading data...\")\n",
        "        \n",
        "        ## format\n",
        "        pattern_instruction = 'query'  # instruction\n",
        "        pattern_input = 'input'  # 내 데이터엔 input이 없다\n",
        "        pattern_output = 'response'  # output\n",
        "\n",
        "        ############################################################\n",
        "        ## load dataset\n",
        "        with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
        "            list_data_dict = []\n",
        "            if SFT_SAMPLE_DATA_SIZE and SFT_SAMPLE_DATA_SIZE > 0:\n",
        "                random.seed(530)\n",
        "                list_data_dict = random.sample(json.load(json_file), SFT_SAMPLE_DATA_SIZE)\n",
        "            else:\n",
        "                list_data_dict = json.load(json_file)\n",
        "    \n",
        "        ############################################################\n",
        "        ## 데이터셋 만들기, source와 target\n",
        "        prompt_input, prompt_no_input = PROMPT_DICT[\"prompt_input\"], PROMPT_DICT[\"prompt_no_input\"]  # 템플릿 가져오기\n",
        "\n",
        "        # 입력\n",
        "        sources = []\n",
        "        for example in list_data_dict:\n",
        "            if example.get(pattern_input, \"\") != \"\":\n",
        "                tmp = prompt_input.format_map(example)\n",
        "            else:\n",
        "                tmp = prompt_no_input.format_map(example)\n",
        "            sources.append(tmp)\n",
        "\n",
        "        # 출력\n",
        "        targets = []\n",
        "        for example in list_data_dict:\n",
        "            targets.append(f\"{example[pattern_output]}{tokenizer.eos_token}\")\n",
        "\n",
        "        if verbose:\n",
        "            idx = 0\n",
        "            print((sources[idx]))\n",
        "            print((targets[idx]))\n",
        "            print(\"Tokenizing inputs... This may take some time...\")\n",
        "\n",
        "        ############################################################\n",
        "        # data_dict = preprocess(sources, targets, tokenizer)  # https://github.com/Beomi/KoAlpaca/blob/04704348d58b8b1c2e2638d6437a04b4e8ba1823/train.py#L124\n",
        "        examples = [s + t for s, t in zip(sources, targets)]\n",
        "\n",
        "        # source data tokenized\n",
        "        sources_tokenized = self._tokenize_fn(sources, tokenizer)  # source만\n",
        "        examples_tokenized = self._tokenize_fn(examples, tokenizer)  # source + target\n",
        "\n",
        "\n",
        "        ## 입력은 source, 출력은 source+target 이지만 학습은 target 부분만\n",
        "        input_ids = examples_tokenized[\"input_ids\"]\n",
        "        labels = copy.deepcopy(input_ids)\n",
        "        for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
        "            label[:source_len] = IGNORE_INDEX  # source 부분은 -100으로 채운다\n",
        "\n",
        "        data_dict = dict(input_ids=input_ids, labels=labels)        \n",
        "        \n",
        "        self.input_ids = data_dict[\"input_ids\"]\n",
        "        self.labels = data_dict[\"labels\"]\n",
        "        logging.warning(\"Loading data done!!: %d\"%(len(self.labels)))    \n",
        "        \n",
        "    def _tokenize_fn(self, strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
        "        \"\"\"Tokenize a list of strings.\"\"\"\n",
        "        tokenized_list = [\n",
        "            tokenizer(\n",
        "                text,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=\"longest\",\n",
        "                max_length=tokenizer.model_max_length,\n",
        "                truncation=True,\n",
        "            )\n",
        "            for text in strings\n",
        "        ]\n",
        "        input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
        "        input_ids_lens = labels_lens = [\n",
        "            tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
        "        ]\n",
        "\n",
        "        return dict(\n",
        "            input_ids=input_ids,\n",
        "            labels=labels,\n",
        "            input_ids_lens=input_ids_lens,\n",
        "            labels_lens=labels_lens,\n",
        "        )        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    \n",
        "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
        "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorForSupervisedDataset(object):\n",
        "    \"\"\"Collate examples for supervised fine-tuning.\"\"\"\n",
        "\n",
        "    tokenizer: transformers.PreTrainedTokenizer\n",
        "\n",
        "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
        "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
        "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
        "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
        "        )\n",
        "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=IGNORE_INDEX)\n",
        "\n",
        "        return dict(\n",
        "            input_ids=input_ids,\n",
        "            labels=labels,\n",
        "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
        "        )\n",
        "\n",
        "    \n",
        "train_dataset = SFT_dataset(data_path_1_SFT=args.data_path_1_SFT, tokenizer=tokenizer)\n",
        "eval_dataset  = None\n",
        "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습"
      ],
      "metadata": {
        "id": "B8Mu74ggWsqy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "Uuh3PgkLSMVY",
        "outputId": "194c7bbb-caae-4372-a3a0-7f28199d1ca6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3941' max='3941' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3941/3941 07:12, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.421800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.674300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>2.179800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.802600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.503200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.264900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.088700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SFT Model Train done!!!\n"
          ]
        }
      ],
      "source": [
        "## 학습 (10min)\n",
        "# training_args 수정 가능: https://github.com/Beomi/KoAlpaca/blob/main/train.sh 참고\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=SFT_MODEL_OUTPUT_PATH, #The output directory\n",
        "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
        "    num_train_epochs = args.max_epochs, # number of training epochs\n",
        "    per_device_train_batch_size = args.train_batch_size, # batch size for training\n",
        "    per_device_eval_batch_size = args.train_batch_size,  # batch size for evaluation\n",
        "    save_steps = args.save_steps, # after # steps model is saved \n",
        "    warmup_steps = 5,# number of warmup steps for learning rate scheduler\n",
        "    prediction_loss_only=True,\n",
        "    resume_from_checkpoint=True,\n",
        "    learning_rate = 5e-5,\n",
        "    ignore_data_skip = True\n",
        "    )\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "# trainer.train(resume_from_checkpoint=True)\n",
        "trainer.save_state()\n",
        "safe_save_model_for_hf_trainer(trainer=trainer, output_dir=args.output_dir)\n",
        "print(\"SFT Model Train done!!!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 추론"
      ],
      "metadata": {
        "id": "uPRJF2EEWufC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args.output_dir = './drive/MyDrive/Models/final_SFT_F'\n",
        "SFT_MODEL_EVAL_DATA_PATH = './drive/MyDrive/Models/eval_response_sft_kogpt2F.txt'\n",
        "\n",
        "with open('./drive/MyDrive/Models/eval_queries.jsonl', 'r') as r:\n",
        "\teval_queries = json.load(r)\n",
        "\n",
        "PROMPT_LIST = [query['query'] for query in eval_queries]\n",
        "print(PROMPT_LIST[:10])\n",
        "\n",
        "PROMPT_LIST = [\n",
        "  '나 기분 좋아서 옷 샀어',\n",
        "\t'나 오늘 좋은 일 있어서 신발 샀어',\n",
        "\t'나 기분 안 좋아서 쇼핑다녀왔어',\n",
        "\t'너 기분 안 좋아보여서 아이스크림 사왔어',\n",
        "\t'나 돈 모아서 컴퓨터 샀어',\n",
        "\t'나 학교 가는 길에 교통사고 났어',\n",
        "\t'나 기분 안 좋아서 머리 잘랐어',\n",
        "\t'요즘 취업 준비하느라 힘들어',\n",
        "\t'오늘 늦게일어나서 대충 머리감고 나왔어',\n",
        "\t'걔가 너 싫어한대',\n",
        "\t'나 배탈 난 것 같아',\n",
        "\t'나 감기 걸린 것 같아',\n",
        "\t'코로나 걸렸어',\n",
        "\t'시험에 떨어졌어',\n",
        "\t'우울해서 아이패드 샀어',\n",
        "\t'나 부모님한테 혼났어',\n",
        "\t'이러면 아무도 너 안 좋아해',\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMtb9y-y_jnc",
        "outputId": "4ea113f8-fb3a-451c-c13c-7d592761871b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['모르겠어. 약간 특수 펌 같기도 하던데', '어 업무가 너무 힘들어서 그런지 맨날 전화 와서 운다 ㅠ', '사랑해서 결혼하는데 무슨 기를 꺾어...', '건강해지는 방법이라고? 왜?', '어우 맞아요! 전 그거 보고 너무 미안해지더라고요', '아니 궁금해서 눈을 못 떼겠던데', '고등학교 때 가사 수업 하기 싫어서 선택했지', '첫째 누나 무섭다 그러고 둘째 누나는 착하다 그러더라', '요즘 엄마들은 교육열 장난 아닐 듯...', '경주에 엑스포도 있었어? 처음 들어보는데?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7CFw58BSMVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12d531d1-d6a3-4655-9856-a4f0585b45d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######################################################################\n",
            "completion: ### Instruction(명령어):\n",
            "나 기분 좋아서 옷 샀어\n",
            "\n",
            "### Response(응답):와 정말 좋은 아이디어 같아요! 어떤 스타일의 옷을 입었는지 궁금하네요.가 입고 싶으신가요?  저 웃 사이 다 어 하 생\n",
            "######################################################################\n",
            "completion: ### Instruction(명령어):\n",
            "나 오늘 좋은 일 있어서 신발 샀어\n",
            "\n",
            "### Response(응답):와! 좋은 일 있었나봐요! 어떤 신발을 샀어요? 언제 사셨어요? 그리고 어떤 종류의 신발이 좋으세요? 저도 함께  어하 하 기 생\n",
            "######################################################################\n",
            "completion: ### Instruction(명령어):\n",
            "나 기분 안 좋아서 쇼핑다녀왔어\n",
            "\n",
            "### Response(응답):그래도 같이 쇼핑한 것 같아서 좋았겠다. 어떤 상품을 샀어? 얘기해봐. 즐거웠어! 저 어 웃  하 함 생\n",
            "######################################################################\n",
            "completion: ### Instruction(명령어):\n",
            "너 기분 안 좋아보여서 아이스크림 사왔어\n",
            "\n",
            "### Response(응답):아, 그러셨군요. 기분이 안 좋으신 건가요? 무슨 일 있으셨나요? 얘기해봐요. 함께 공감해드릴게요.소식 다  어 건강 \n",
            "######################################################################\n",
            "completion: ### Instruction(명령어):\n",
            "나 돈 모아서 컴퓨터 샀어\n",
            "\n",
            "### Response(응답):와! 정말 대단해요! 컴퓨터 값이 이렇게 비싸다니까요. 어떻게 구입하셨어요? 저도 궁금해요. 생 어 공  이 하 아 함\n",
            "######################################################################\n",
            "completion: ### Instruction(명령어):\n",
            "나 학교 가는 길에 교통사고 났어\n",
            "\n",
            "### Response(응답):정말 심각한 상황이네요. 교통사고가 많이 일어나서 걱정이 많으시겠어요. 어떻게 대처할 계획이 있으세요? 사 대 하 이 생 부 관 어\n",
            "######################################################################\n",
            "completion: ### Instruction(명령어):\n",
            "나 기분 안 좋아서 머리 잘랐어\n",
            "\n",
            "### Response(응답):정말? 고마워! 그런데 너 기분이 안 좋아서 미안해. 어떻게 된 거야? 좀 더 자세히 말해줄래?  어 저 ᄒ 다 웃 하하\n",
            "######################################################################\n",
            "completion: ### Instruction(명령어):\n",
            "요즘 취업 준비하느라 힘들어\n",
            "\n",
            "### Response(응답):어떤 일을 준비하고 있어요? 힘든 일이 있나요? 얘기해봐요. 취업이 언제 가능할지 모르잖아요.  하 어 이  생! 중\n",
            "######################################################################\n",
            "completion: ### Instruction(명령어):\n",
            "오늘 늦게일어나서 대충 머리감고 나왔어\n",
            "\n",
            "### Response(응답):정말 힘들었겠네요. 뭐 좀 도와줄 게 있으면 얘기해봐요. 함께 해결해보는 건 어때요?  하  저   다! 이 생\n",
            "######################################################################\n",
            "completion: ### Instruction(명령어):\n",
            "걔가 너 싫어한대\n",
            "\n",
            "### Response(응답):왜 그러셨어요? 이유가 있나요? 뭐든지 얘기해봐요. 저도 함께 공감해드릴게요.  괜  하 다 함 어 생\n",
            "######################################################################\n",
            "completion: ### Instruction(명령어):\n",
            "나 배탈 난 것 같아\n",
            "\n",
            "### Response(응답):괜찮아? 무슨 일 있었어? 이야기해 봐. 저도 함께 들어줄게. 힘내세요~! 웃기^_^) 건강\n",
            "######################################################################\n",
            "completion: ### Instruction(명령어):\n",
            "나 감기 걸린 것 같아\n",
            "\n",
            "### Response(응답):감기 걸렸다면 정말 다행이네요. 건강이 최우선이에요. 혹시 감기 걸리지 않았나요? 걱정이 된다면 조해 이 생 마! 내 건강\n",
            "######################################################################\n",
            "completion: ### Instruction(명령어):\n",
            "코로나 걸렸어\n",
            "\n",
            "### Response(응답):정말 안타깝네요. 어떻게 된 일인가요? 걱정이 되시겠어요. 얘기해 주세요. 걱정되시면 언제든지 제게 이야기해주세요. 생하 저 하 중 함\n",
            "######################################################################\n",
            "completion: ### Instruction(명령어):\n",
            "시험에 떨어졌어\n",
            "\n",
            "### Response(응답):정말 힘들겠네요. 어떻게 도와드릴까요? 궁금하네요. 좀 더 자세히 들려주세요. 어 하 저 생 아 이! 중 대\n",
            "######################################################################\n",
            "completion: ### Instruction(명령어):\n",
            "우울해서 아이패드 샀어\n",
            "\n",
            "### Response(응답):아이패드는 정말 재밌는 아이패드를 산 것 같아요. 어떤 아이패드를 사셨나요? 궁금하네요!  어함 함 사이 아 웃 생\n",
            "######################################################################\n",
            "completion: ### Instruction(명령어):\n",
            "나 부모님한테 혼났어\n",
            "\n",
            "### Response(응답):정말 힘들겠네요. 어떻게 도와드릴까요? 얘기해봐요. 함께 고민해볼게요. 제 하 괜 저 다 함 어 생 이\n",
            "######################################################################\n",
            "completion: ### Instruction(명령어):\n",
            "이러면 아무도 너 안 좋아해\n",
            "\n",
            "### Response(응답):그럴 수도 있겠죠. 하지만 저는 당신이 좋아하는 것을 존중해야 한다고 생각해요. 함께 즐길 수 있는 다른 취미를 찾아보는 하하 어 생  이 함! 제\n"
          ]
        }
      ],
      "source": [
        "## 추론 테스트\n",
        "generator = pipeline('text-generation', model=args.output_dir, tokenizer=tokenizer)\n",
        "\n",
        "generation_args = dict(\n",
        "    num_beams=4,\n",
        "    repetition_penalty=2.0,\n",
        "    no_repeat_ngram_size=4,\n",
        "    eos_token_id=375, # \\n\n",
        "    max_new_tokens=64,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "list_prompt = PROMPT_LIST\n",
        "\n",
        "list_prompt = [PROMPT_DICT['prompt_no_input'].format_map({'query' : tmp}) for tmp in list_prompt]\n",
        "output_list = []\n",
        "list_result = generator(list_prompt, **generation_args)\n",
        "for prompt, result in zip(list_prompt, list_result):\n",
        "  output = result[0]['generated_text']\n",
        "  print(('#'*70))\n",
        "  print(('completion: %s'%(output)))\n",
        "  output_list.append(output.split(\"Response(응답):\")[1])\n",
        "\n",
        "# with open(SFT_MODEL_EVAL_DATA_PATH, 'w') as w:\n",
        "#   w.write('\\n'.join(output_list))\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7EindF6SMVZ"
      },
      "outputs": [],
      "source": [
        "raise Exception"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU4djUZ_7tit"
      },
      "source": [
        "# 2. RM: 좋은 글 채점기 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import (1에서 import하지 않은 상황)"
      ],
      "metadata": {
        "id": "iEfSfebZW8pP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KphqHc6lgu38"
      },
      "outputs": [],
      "source": [
        "# ## setup(1min)\n",
        "# # torch 버전 다운. torch>=2.0 에선 colosalai가 동작안함\n",
        "# !pip uninstall torch -y\n",
        "# !pip install torch==1.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "\n",
        "# import torch\n",
        "\n",
        "# print(\"Torch version:{}\".format(torch.__version__))\n",
        "# print(\"cuda version: {}\".format(torch.version.cuda))\n",
        "# print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))\n",
        "\n",
        "# # for ColossalAI\n",
        "# !pip install colossalai==0.2.7\n",
        "\n",
        "# # setup data\n",
        "# !git clone https://github.com/airobotlab/KoChatGPT\n",
        "# !mv KoChatGPT/data_kochatgpt .\n",
        "# !mv KoChatGPT/img .\n",
        "\n",
        "# %cd KoChatGPT/colossalai_ChatGPT_230319/\n",
        "# !pip install .\n",
        "# %cd ../../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiuVfmvb7tTD"
      },
      "outputs": [],
      "source": [
        "# import\n",
        "import argparse\n",
        "\n",
        "import loralib as lora\n",
        "import torch\n",
        "torch.cuda.empty_cache() \n",
        "from chatgpt.dataset import RewardDataset\n",
        "from chatgpt.models.base import RewardModel\n",
        "from chatgpt.models.bloom import BLOOMRM\n",
        "from chatgpt.models.gpt import GPTRM\n",
        "from chatgpt.models.opt import OPTRM\n",
        "from chatgpt.trainer import RewardModelTrainer\n",
        "from chatgpt.trainer.strategies import ColossalAIStrategy, DDPStrategy, NaiveStrategy\n",
        "from datasets import load_dataset\n",
        "from torch.optim import Adam\n",
        "from transformers import AutoTokenizer, BloomTokenizerFast\n",
        "from transformers.models.gpt2.tokenization_gpt2 import GPT2Tokenizer\n",
        "\n",
        "from colossalai.nn.optimizer import HybridAdam\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "# data config\n",
        "IGNORE_INDEX = -100\n",
        "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
        "DEFAULT_EOS_TOKEN = \"</s>\"\n",
        "DEFAULT_BOS_TOKEN = \"</s>\"\n",
        "DEFAULT_UNK_TOKEN = \"</s>\"\n",
        "PROMPT_DICT = {\n",
        "    \"prompt_input\": (\n",
        "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Input(입력):\\n{input}\\n\\n### Response(응답):\"\n",
        "    ),\n",
        "    \"prompt_no_input\": (\n",
        "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
        "    ),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RM hyperparameter 설정"
      ],
      "metadata": {
        "id": "OK1iBS05XXvJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNEweAK77tNT"
      },
      "outputs": [],
      "source": [
        "# define argment\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--output_dir', type=str, default=RM_MODEL_OUTPUT_PATH)\n",
        "parser.add_argument('--data_path_2_RM', type=str, default=RM_DATASET_PATH, help='https://huggingface.co/datasets/fka/awesome-chatgpt-prompts/blob/main/prompts.csv')\n",
        "parser.add_argument('--strategy',\n",
        "                    choices=['naive', 'ddp', 'colossalai_gemini', 'colossalai_zero2'],\n",
        "                    default='naive')\n",
        "parser.add_argument('--model', type=str, default='gpt2', choices=['gpt2', 'bloom', 'opt'])\n",
        "parser.add_argument('--pretrain', type=str, default=None)\n",
        "parser.add_argument('--dataset', type=str, default='Dahoas/rm-static')\n",
        "parser.add_argument('--save_path', type=str, default='rm_ckpt.pth')\n",
        "parser.add_argument('--max_epochs', type=int, default=10)\n",
        "parser.add_argument('--batch_size', type=int, default=4)\n",
        "parser.add_argument('--lora_rank', type=int, default=0, help=\"low-rank adaptation matrices rank\")\n",
        "parser.add_argument('--max_len', type=int, default=64)  # wygo 추가\n",
        "\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "# for test\n",
        "args.max_epochs = 5\n",
        "args.pretrain = SFT_MODEL_NAME  # pretrained 모델 가져오기\n",
        "args.verbose = True\n",
        "\n",
        "print(args)\n",
        "if not os.path.exists(args.output_dir):\n",
        "    os.makedirs(args.output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['RANK'] = '0'\n",
        "os.environ['LOCAL_RANK'] = '0'\n",
        "os.environ['WORLD_SIZE'] = '2'\n",
        "os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
        "os.environ['MASTER_PORT'] = '42043'"
      ],
      "metadata": {
        "id": "mwO58p61-uuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtwPLUIq7tIb"
      },
      "outputs": [],
      "source": [
        "# configure strategy\n",
        "if args.strategy == 'naive':\n",
        "    strategy = NaiveStrategy()\n",
        "elif args.strategy == 'ddp':\n",
        "    strategy = DDPStrategy()\n",
        "elif args.strategy == 'colossalai_gemini':\n",
        "    strategy = ColossalAIStrategy(stage=3, placement_policy='cuda')\n",
        "elif args.strategy == 'colossalai_zero2':\n",
        "    strategy = ColossalAIStrategy(stage=2, placement_policy='cuda')\n",
        "else:\n",
        "    raise ValueError(f'Unsupported strategy \"{args.strategy}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZ96VsvwnHG9"
      },
      "outputs": [],
      "source": [
        "# customizing, https://github.com/hpcaitech/ColossalAI/blob/2e16f842a9e5b1fb54e7e41070e9d2bb5cd64d7c/applications/ChatGPT/chatgpt/nn/gpt_rm.py#L29\n",
        "from typing import Optional\n",
        "\n",
        "import torch.nn as nn\n",
        "from transformers.models.gpt2.configuration_gpt2 import GPT2Config\n",
        "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
        "\n",
        "# from ..base import RewardModel\n",
        "from chatgpt.models.base import RewardModel\n",
        "\n",
        "\n",
        "class GPTRM_custom(RewardModel):\n",
        "    \"\"\"\n",
        "    GPT Reward model.\n",
        "    Args:\n",
        "        pretrained (str): Pretrained model name or path.\n",
        "        config (GPT2Config): Model config.\n",
        "        checkpoint (bool): Enable gradient checkpointing.\n",
        "        lora_rank (int): Rank of the low-rank approximation.\n",
        "        lora_train_bias (str): LoRA bias training mode.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 pretrained: Optional[str] = None,\n",
        "                 config: Optional[GPT2Config] = None,\n",
        "                 checkpoint: bool = False,\n",
        "                 lora_rank: int = 0,\n",
        "                 lora_train_bias: str = 'none',\n",
        "                 tokenizer=None) -> None:\n",
        "        if pretrained is not None:\n",
        "            model = GPT2Model.from_pretrained(pretrained)\n",
        "            model.resize_token_embeddings(len(tokenizer))  # wygo 추가!!!\n",
        "        elif config is not None:\n",
        "            model = GPT2Model(config)\n",
        "        else:\n",
        "            model = GPT2Model(GPT2Config())\n",
        "        if checkpoint:\n",
        "            model.gradient_checkpointing_enable()\n",
        "\n",
        "        \n",
        "        # model = model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "        value_head = nn.Linear(model.config.n_embd, 1)\n",
        "        super().__init__(model, value_head, lora_rank, lora_train_bias)\n",
        "\n",
        "        # 추가, 230421    \n",
        "        if pretrained is not None:\n",
        "            self.model = model\n",
        "            self.pretrained = pretrained\n",
        "        \n",
        "    # 추가, 230421, config.json을 생성하기 위해 추가\n",
        "    def save_pretrained(self, dir):\n",
        "        if self.pretrained is not None:\n",
        "            self.model.save_pretrained(dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ee3we4uB8EdK"
      },
      "outputs": [],
      "source": [
        "# configure model, tokenizer\n",
        "with strategy.model_init_context():\n",
        "    # load pretrained gpt2    \n",
        "    if args.model == 'gpt2':\n",
        "#         tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "        # tokenizer = AutoTokenizer.from_pretrained(args.pretrain)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(args.pretrain, padding_side=\"right\", model_max_length=512)\n",
        "        tokenizer.add_special_tokens(\n",
        "            {\n",
        "                \"eos_token\": DEFAULT_EOS_TOKEN,\n",
        "                \"bos_token\": DEFAULT_BOS_TOKEN,\n",
        "                \"unk_token\": DEFAULT_UNK_TOKEN,\n",
        "            }\n",
        "        )\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        model = GPTRM_custom(pretrained=args.pretrain, lora_rank=args.lora_rank, tokenizer=tokenizer).cuda()\n",
        "\n",
        "    elif args.model == 'bloom':\n",
        "        model = BLOOMRM(pretrained=args.pretrain, lora_rank=args.lora_rank).cuda()\n",
        "        tokenizer = BloomTokenizerFast.from_pretrained(args.pretrain)\n",
        "    \n",
        "    elif args.model == 'opt':\n",
        "        model = OPTRM(pretrained=args.pretrain, lora_rank=args.lora_rank).cuda()\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")      \n",
        "    \n",
        "    else:\n",
        "        raise ValueError(f'Unsupported model \"{args.model}\"')\n",
        "    \n",
        "    \n",
        "    # model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GD94Zd-b7tDL"
      },
      "outputs": [],
      "source": [
        "# make ranking data to chosen, rejetced data\n",
        "with open(args.data_path_2_RM, \"r\", encoding='utf-8') as json_file:\n",
        "    list_data_dict = json.load(json_file)\n",
        "    if args.verbose:\n",
        "        print('## data check ##')\n",
        "        print((list_data_dict[0]))\n",
        "        \n",
        "total_data_ranking2chosen = []\n",
        "for tmp in list_data_dict:\n",
        "    one_data_ranking2chosen = []\n",
        "\n",
        "    # data 1) 0 VS 1\n",
        "    data = {}\n",
        "    data['prompt'] = tmp['prompt']\n",
        "    if tmp['ranking'][0] < tmp['ranking'][1]:\n",
        "        data['chosen'] = tmp['completion_0']\n",
        "        data['rejected'] = tmp['completion_1']\n",
        "    else:\n",
        "        data['chosen'] = tmp['completion_1']\n",
        "        data['rejected'] = tmp['completion_0']\n",
        "    one_data_ranking2chosen.append(data)\n",
        "\n",
        "\n",
        "    # data 2) 0 VS 2\n",
        "    data = {}\n",
        "    data['prompt'] = tmp['prompt']\n",
        "    if tmp['ranking'][0] < tmp['ranking'][2]:\n",
        "        data['chosen'] = tmp['completion_0']\n",
        "        data['rejected'] = tmp['completion_2']\n",
        "    else:\n",
        "        data['chosen'] = tmp['completion_2']\n",
        "        data['rejected'] = tmp['completion_0']\n",
        "    one_data_ranking2chosen.append(data)\n",
        "\n",
        "    # data 1) 1 VS 2\n",
        "    data = {}\n",
        "    data['prompt'] = tmp['prompt']\n",
        "    if tmp['ranking'][1] < tmp['ranking'][2]:\n",
        "        data['chosen'] = tmp['completion_1']\n",
        "        data['rejected'] = tmp['completion_2']\n",
        "    else:\n",
        "        data['chosen'] = tmp['completion_2']\n",
        "        data['rejected'] = tmp['completion_1']\n",
        "    one_data_ranking2chosen.append(data)\n",
        "    \n",
        "    \n",
        "    \n",
        "    total_data_ranking2chosen.extend(one_data_ranking2chosen)\n",
        "\n",
        "print('after  data num: %d'%(len(total_data_ranking2chosen)))\n",
        "print('data example: \\n%s'%total_data_ranking2chosen[40])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWzG_w3d7s9h"
      },
      "outputs": [],
      "source": [
        "# prepare for data and dataset\n",
        "import random\n",
        "import math\n",
        "\n",
        "random.seed(230319)\n",
        "random.shuffle(total_data_ranking2chosen)\n",
        "print(total_data_ranking2chosen[45])\n",
        "\n",
        "train_data_len = math.floor(len(total_data_ranking2chosen) * 0.8)\n",
        "train_data = total_data_ranking2chosen[:train_data_len]\n",
        "eval_data = total_data_ranking2chosen[train_data_len:] \n",
        "\n",
        "\n",
        "train_dataset = RewardDataset(train_data, tokenizer, args.max_len)\n",
        "eval_dataset = RewardDataset(eval_data, tokenizer, args.max_len)\n",
        "\n",
        "print(f'train set : {len(train_data)}, eval_set : {len(eval_data)}')\n",
        "\n",
        "# check\n",
        "idx = 10\n",
        "print('#'*70)\n",
        "print('## prompt ##')\n",
        "print(train_data[idx]['prompt'])\n",
        "print('#'*70)\n",
        "print('## chosen ##')\n",
        "print(train_data[idx]['chosen'])\n",
        "print('#'*70)\n",
        "print('## rejected ##')\n",
        "print(train_data[idx]['rejected'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQI5a1hm7s3L"
      },
      "outputs": [],
      "source": [
        "# configure optimizer\n",
        "if args.strategy.startswith('colossalai'):\n",
        "    optim = HybridAdam(model.parameters(), lr=5e-5)\n",
        "else:\n",
        "    optim = Adam(model.parameters(), lr=5e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97mbryrTgXJ0"
      },
      "outputs": [],
      "source": [
        "# batch_size here is expected to be C(k,2), k means # response of each prompt\n",
        "# be limited with the format of dataset 'Dahoas/rm-static', we'd better use batch_size as 1\n",
        "trainer = RewardModelTrainer(model=model,\n",
        "                             strategy=strategy,\n",
        "                             optim=optim,\n",
        "                             train_dataset=train_dataset,\n",
        "                             eval_dataset=eval_dataset,\n",
        "                             batch_size=args.batch_size,\n",
        "                             max_epochs=args.max_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE6HOKdmgY6X"
      },
      "source": [
        "## 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpOYBhbH8HLh"
      },
      "outputs": [],
      "source": [
        "# train!!\n",
        "trainer.fit(use_lora=args.lora_rank)\n",
        "\n",
        "## save\n",
        "# save model checkpoint after fitting on only rank0\n",
        "strategy.save_model(model, os.path.join(args.output_dir, 'RM.pt'), only_rank0=True)\n",
        "# save optimizer checkpoint on all ranks\n",
        "strategy.save_optimizer(optim,\n",
        "                        os.path.join(args.output_dir, 'RM_optim_checkpoint_%d.pt' % (torch.cuda.current_device())),\n",
        "                        only_rank0=False)\n",
        "\n",
        "model.save_pretrained(args.output_dir)  # config.json 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 추론"
      ],
      "metadata": {
        "id": "LN8diXLnYTom"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaGv2_qUsRrb"
      },
      "outputs": [],
      "source": [
        "# 보상모델 체크\n",
        "def inference_RM(input_text='인공지능은 인공지능 입니다'):\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
        "        torch.cuda.current_device())\n",
        "    output = model(input_ids)\n",
        "    output_reward = output.cpu().detach().numpy()[0]\n",
        "    \n",
        "    print('input: %s\\nreward score: %.1f'%(input_text, output_reward))\n",
        "    \n",
        "    return output_reward\n",
        "\n",
        "\n",
        "# input_text = '한국은 대한민국 입니다'\n",
        "input_text = '인공지능은 인공지능 입니다'\n",
        "\n",
        "output_reward = inference_RM(input_text=input_text)\n",
        "\n",
        "# Test\n",
        "inference_RM(input_text='어떤 신발을 샀어?')\n",
        "inference_RM(input_text='샀다고 신발을?')\n",
        "inference_RM(input_text='어육 제육 키키')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_nNydSKAtOu"
      },
      "outputs": [],
      "source": [
        "raise Exception"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BYQV4ca3Ytna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqkr7S_-pO9m"
      },
      "source": [
        "#3. PPO 사람의 피드백을 반영하여 학습\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import(1, 2에서 하지 않은 경우)"
      ],
      "metadata": {
        "id": "-EKBo-gqYqwk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fo6KWWcpdxh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "10f6199b-c05b-4aad-b4ec-e35982e7c315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.0.1+cu118\n",
            "Uninstalling torch-2.0.1+cu118:\n",
            "  Successfully uninstalled torch-2.0.1+cu118\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu116\n",
            "Collecting torch==1.13.1+cu116\n",
            "  Downloading https://download.pytorch.org/whl/cu116/torch-1.13.1%2Bcu116-cp310-cp310-linux_x86_64.whl (1977.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m902.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1+cu116) (4.5.0)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1+cu116 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1+cu116 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1+cu116 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.13.1+cu116 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.13.1+cu116\n",
            "Torch version:1.13.1+cu116\n",
            "cuda version: 11.6\n",
            "Cloning into 'KoChatGPT'...\n",
            "remote: Enumerating objects: 240, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 240 (delta 63), reused 84 (delta 45), pack-reused 129\u001b[K\n",
            "Receiving objects: 100% (240/240), 11.57 MiB | 16.76 MiB/s, done.\n",
            "Resolving deltas: 100% (93/93), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.4.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n",
            "/content/KoChatGPT/colossalai_ChatGPT_230319\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/KoChatGPT/colossalai_ChatGPT_230319\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers>=4.20.1 (from chatgpt==0.1.0)\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from chatgpt==0.1.0) (4.65.0)\n",
            "Collecting datasets (from chatgpt==0.1.0)\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting loralib (from chatgpt==0.1.0)\n",
            "  Downloading loralib-0.1.1-py3-none-any.whl (8.8 kB)\n",
            "Collecting colossalai>=0.2.4 (from chatgpt==0.1.0)\n",
            "  Downloading colossalai-0.3.0.tar.gz (782 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.5/782.5 kB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from chatgpt==0.1.0) (1.13.1+cu116)\n",
            "Collecting langchain (from chatgpt==0.1.0)\n",
            "  Downloading langchain-0.0.183-py3-none-any.whl (938 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m938.0/938.0 kB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (1.22.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (5.9.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (23.1)\n",
            "Collecting pre-commit (from colossalai>=0.2.4->chatgpt==0.1.0)\n",
            "  Downloading pre_commit-3.3.2-py2.py3-none-any.whl (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.8/202.8 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (13.3.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (8.1.3)\n",
            "Collecting fabric (from colossalai>=0.2.4->chatgpt==0.1.0)\n",
            "  Downloading fabric-3.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contexttimer (from colossalai>=0.2.4->chatgpt==0.1.0)\n",
            "  Downloading contexttimer-0.3.3.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ninja (from colossalai>=0.2.4->chatgpt==0.1.0)\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from colossalai>=0.2.4->chatgpt==0.1.0)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->chatgpt==0.1.0) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.20.1->chatgpt==0.1.0) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers>=4.20.1->chatgpt==0.1.0)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.20.1->chatgpt==0.1.0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.20.1->chatgpt==0.1.0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.20.1->chatgpt==0.1.0) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.20.1->chatgpt==0.1.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m122.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->chatgpt==0.1.0) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets->chatgpt==0.1.0)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->chatgpt==0.1.0) (1.5.3)\n",
            "Collecting xxhash (from datasets->chatgpt==0.1.0)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->chatgpt==0.1.0)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->chatgpt==0.1.0) (2023.4.0)\n",
            "Collecting aiohttp (from datasets->chatgpt==0.1.0)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19 (from datasets->chatgpt==0.1.0)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->chatgpt==0.1.0) (2.0.10)\n",
            "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain->chatgpt==0.1.0)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain->chatgpt==0.1.0)\n",
            "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain->chatgpt==0.1.0) (2.8.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain->chatgpt==0.1.0)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->chatgpt==0.1.0) (1.10.7)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->chatgpt==0.1.0) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->chatgpt==0.1.0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->chatgpt==0.1.0) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->chatgpt==0.1.0)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp->datasets->chatgpt==0.1.0)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets->chatgpt==0.1.0)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets->chatgpt==0.1.0)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain->chatgpt==0.1.0)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain->chatgpt==0.1.0)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain->chatgpt==0.1.0)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.20.1->chatgpt==0.1.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.20.1->chatgpt==0.1.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.20.1->chatgpt==0.1.0) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->chatgpt==0.1.0) (2.0.2)\n",
            "Collecting invoke>=2.0 (from fabric->colossalai>=0.2.4->chatgpt==0.1.0)\n",
            "  Downloading invoke-2.1.2-py3-none-any.whl (160 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting paramiko>=2.4 (from fabric->colossalai>=0.2.4->chatgpt==0.1.0)\n",
            "  Downloading paramiko-3.2.0-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.2/224.2 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator>=5 (from fabric->colossalai>=0.2.4->chatgpt==0.1.0)\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->chatgpt==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->chatgpt==0.1.0) (2022.7.1)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit->colossalai>=0.2.4->chatgpt==0.1.0)\n",
            "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit->colossalai>=0.2.4->chatgpt==0.1.0)\n",
            "  Downloading identify-2.5.24-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nodeenv>=0.11.1 (from pre-commit->colossalai>=0.2.4->chatgpt==0.1.0)\n",
            "  Downloading nodeenv-1.8.0-py2.py3-none-any.whl (22 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit->colossalai>=0.2.4->chatgpt==0.1.0)\n",
            "  Downloading virtualenv-20.23.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->colossalai>=0.2.4->chatgpt==0.1.0) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->colossalai>=0.2.4->chatgpt==0.1.0) (2.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->colossalai>=0.2.4->chatgpt==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nodeenv>=0.11.1->pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (67.7.2)\n",
            "Collecting bcrypt>=3.2 (from paramiko>=2.4->fabric->colossalai>=0.2.4->chatgpt==0.1.0)\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.4->fabric->colossalai>=0.2.4->chatgpt==0.1.0) (40.0.2)\n",
            "Collecting pynacl>=1.5 (from paramiko>=2.4->fabric->colossalai>=0.2.4->chatgpt==0.1.0)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->chatgpt==0.1.0) (1.16.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain->chatgpt==0.1.0)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting distlib<1,>=0.3.6 (from virtualenv>=20.10.0->pre-commit->colossalai>=0.2.4->chatgpt==0.1.0)\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs<4,>=3.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (3.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3->paramiko>=2.4->fabric->colossalai>=0.2.4->chatgpt==0.1.0) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.4->fabric->colossalai>=0.2.4->chatgpt==0.1.0) (2.21)\n",
            "Building wheels for collected packages: chatgpt, colossalai, contexttimer\n",
            "  Building wheel for chatgpt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chatgpt: filename=chatgpt-0.1.0-py3-none-any.whl size=46647 sha256=e48a0961e1495a2c97e46575ffe99c1b4a3c2bfa8530d5ec0420d9ca5ab0530b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3or8y89z/wheels/2b/0d/f8/b8f3ba4fd18f31a4096ee5bf83e4579cb54597f393eeae227c\n",
            "  Building wheel for colossalai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colossalai: filename=colossalai-0.3.0-py3-none-any.whl size=997646 sha256=222739e342e47bca00fc30e9472b78329e9d0e602a9538e4e9a6f6e4da22d222\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/86/2e/ae8c10fcd8c4515b205a6f570139b66ba7b55f19ea571043c2\n",
            "  Building wheel for contexttimer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contexttimer: filename=contexttimer-0.3.3-py3-none-any.whl size=5803 sha256=9ad08d567fb88a927ddf0720376567f343e7d081ada99b083d5edccf0df1c944\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/1c/da/cfd97201d88ccce214427fa84a5caeb91fef7c5a1b4c4312b4\n",
            "Successfully built chatgpt colossalai contexttimer\n",
            "Installing collected packages: tokenizers, safetensors, ninja, distlib, contexttimer, xxhash, virtualenv, nodeenv, mypy-extensions, multidict, marshmallow, loralib, invoke, identify, frozenlist, dill, decorator, cfgv, bcrypt, async-timeout, yarl, typing-inspect, responses, pynacl, pre-commit, openapi-schema-pydantic, multiprocess, marshmallow-enum, huggingface-hub, aiosignal, transformers, paramiko, dataclasses-json, aiohttp, langchain, fabric, datasets, colossalai, chatgpt\n",
            "  Attempting uninstall: decorator\n",
            "    Found existing installation: decorator 4.4.2\n",
            "    Uninstalling decorator-4.4.2:\n",
            "      Successfully uninstalled decorator-4.4.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 bcrypt-4.0.1 cfgv-3.3.1 chatgpt-0.1.0 colossalai-0.3.0 contexttimer-0.3.3 dataclasses-json-0.5.7 datasets-2.12.0 decorator-5.1.1 dill-0.3.6 distlib-0.3.6 fabric-3.1.0 frozenlist-1.3.3 huggingface-hub-0.14.1 identify-2.5.24 invoke-2.1.2 langchain-0.0.183 loralib-0.1.1 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 multiprocess-0.70.14 mypy-extensions-1.0.0 ninja-1.11.1 nodeenv-1.8.0 openapi-schema-pydantic-1.2.4 paramiko-3.2.0 pre-commit-3.3.2 pynacl-1.5.0 responses-0.18.0 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.29.2 typing-inspect-0.9.0 virtualenv-20.23.0 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "decorator"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "## setup(1min)\n",
        "# torch 버전 다운. torch>=2.0 에선 colosalai가 동작안함\n",
        "!pip uninstall torch -y\n",
        "!pip install torch==1.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "\n",
        "import torch\n",
        "\n",
        "print(\"Torch version:{}\".format(torch.__version__))\n",
        "print(\"cuda version: {}\".format(torch.version.cuda))\n",
        "# print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))\n",
        "\n",
        "# for ColossalAI\n",
        "# !pip install colossalai==0.2.7\n",
        "\n",
        "# setup data\n",
        "!git clone https://github.com/airobotlab/KoChatGPT\n",
        "!mv KoChatGPT/data_kochatgpt .\n",
        "!mv KoChatGPT/img .\n",
        "\n",
        "# for evaluation\n",
        "!pip install konlpy\n",
        "\n",
        "%cd KoChatGPT/colossalai_ChatGPT_230319/\n",
        "!pip install .\n",
        "%cd ../../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3Ytmwj-diQ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9afb5543-d8e9-43fc-d929-eea137e2be63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/library.py:130: UserWarning: Overriding a previously registered kernel for the same operator and the same dispatch key\n",
            "  operator: aten::index.Tensor(Tensor self, Tensor?[] indices) -> Tensor\n",
            "    registered at aten/src/ATen/RegisterSchema.cpp:6\n",
            "  dispatch key: Meta\n",
            "  previous kernel: registered at ../aten/src/ATen/functorch/BatchRulesScatterOps.cpp:1053\n",
            "       new kernel: registered at /dev/null:241 (Triggered internally at ../aten/src/ATen/core/dispatch/OperatorEntry.cpp:150.)\n",
            "  self.m.impl(name, dispatch_key, fn)\n"
          ]
        }
      ],
      "source": [
        "# import\n",
        "import argparse\n",
        "from copy import deepcopy\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "from chatgpt.models.base import RewardModel\n",
        "from chatgpt.models.bloom import BLOOMActor, BLOOMCritic\n",
        "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
        "from chatgpt.models.opt import OPTActor, OPTCritic\n",
        "from chatgpt.trainer import PPOTrainer\n",
        "from chatgpt.trainer.strategies import ColossalAIStrategy, DDPStrategy, NaiveStrategy\n",
        "from torch.optim import Adam\n",
        "from transformers import AutoTokenizer, BloomTokenizerFast\n",
        "from transformers.models.gpt2.tokenization_gpt2 import GPT2Tokenizer\n",
        "\n",
        "from colossalai.nn.optimizer import HybridAdam\n",
        "\n",
        "## wy 추가\n",
        "import json\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "\n",
        "## clossalAI error 해결\n",
        "os.environ['RANK'] = '0'\n",
        "os.environ['LOCAL_RANK'] = '0'\n",
        "os.environ['WORLD_SIZE'] = '2'\n",
        "os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
        "os.environ['MASTER_PORT'] = '42043'\n",
        "\n",
        "# data config\n",
        "IGNORE_INDEX = -100\n",
        "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
        "DEFAULT_EOS_TOKEN = \"</s>\"\n",
        "DEFAULT_BOS_TOKEN = \"</s>\"\n",
        "DEFAULT_UNK_TOKEN = \"</s>\"\n",
        "PROMPT_DICT = {\n",
        "    \"prompt_input\": (\n",
        "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Input(입력):\\n{input}\\n\\n### Response(응답):\"\n",
        "    ),\n",
        "    \"prompt_no_input\": (\n",
        "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
        "    ),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter 설정"
      ],
      "metadata": {
        "id": "E0najiqgYx_H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ctd5oDVCdiJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1ab64fb-368c-4b9e-d27d-83612af7299b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_path_3_PPO='./drive/MyDrive/Models/facebook_ppo.jsonl', output_dir='./drive/MyDrive/Models/final_PPO_light_F', strategy='naive', model='gpt2', pretrain='skt/kogpt2-base-v2', num_episodes=15, max_timesteps=80, steps=80, update_timesteps=2, max_epochs=1, train_batch_size=16, lora_rank=0, max_length=64, pretrain_actor='./drive/MyDrive/Models/final_SFT_F', pretrain_critic='./drive/MyDrive/Models/final_RM')\n"
          ]
        }
      ],
      "source": [
        "# define argment\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--data_path_3_PPO', type=str, default=PPO_DATASET_PATH)\n",
        "parser.add_argument('--output_dir', type=str, default=PPO_MODEL_OUTPUT_PATH)\n",
        "parser.add_argument('--strategy',\n",
        "                    choices=['naive', 'ddp', 'colossalai_gemini', 'colossalai_zero2'],\n",
        "                    default='naive')\n",
        "parser.add_argument('--model', type=str, default='gpt2', choices=['gpt2', 'bloom', 'opt'])\n",
        "parser.add_argument('--pretrain', type=str, default='skt/kogpt2-base-v2')\n",
        "parser.add_argument('--num_episodes', type=int, default=50)\n",
        "parser.add_argument('--max_timesteps', type=int, default=200)\n",
        "parser.add_argument('--steps', type=int, default=80)\n",
        "parser.add_argument('--update_timesteps', type=int, default=2)\n",
        "parser.add_argument('--max_epochs', type=int, default=2)\n",
        "parser.add_argument('--train_batch_size', type=int, default=16)\n",
        "parser.add_argument('--lora_rank', type=int, default=0, help=\"low-rank adaptation matrices rank\")\n",
        "parser.add_argument('--max_length', type=int, default=64)\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "## 이곳 수정!!\n",
        "args.pretrain_actor = SFT_MODEL_PATH  # SFT 모델 가져오기\n",
        "args.pretrain_critic = RM_MODEL_PATH  # RM 모델 가져오기\n",
        "# args.pretrain_actor = args.pretrain\n",
        "# args.pretrain_critic = args.pretrain\n",
        "\n",
        "args.num_episodes = 15\n",
        "args.max_timesteps = 80\n",
        "args.max_epochs   = 1\n",
        "\n",
        "print(args)\n",
        "if not os.path.exists(args.output_dir):\n",
        "    os.makedirs(args.output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5YEhGiIdiBQ"
      },
      "outputs": [],
      "source": [
        "# configure strategy\n",
        "if args.strategy == 'naive':\n",
        "    strategy = NaiveStrategy()\n",
        "elif args.strategy == 'ddp':\n",
        "    strategy = DDPStrategy()\n",
        "elif args.strategy == 'colossalai_gemini':\n",
        "    strategy = ColossalAIStrategy(stage=3, placement_policy='cuda')\n",
        "elif args.strategy == 'colossalai_zero2':\n",
        "    strategy = ColossalAIStrategy(stage=2, placement_policy='cuda')\n",
        "else:\n",
        "    raise ValueError(f'Unsupported strategy \"{args.strategy}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZJ4oN9BdnL6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "51f53054f35c43609fefbef62ee8ed92",
            "d1958146b06b4e29bb8794fabc775a5f",
            "ad4eb471a04748ff897d55cb60dfab4d",
            "98d1e8ee6204491e9e7f0462d84ff49c",
            "463dc4f821394b159e9432b480ea8b88",
            "891388bbcdcc45609401a21daaedf958",
            "45f977b115e74b27b29bfafdaacc12cf",
            "7a5354b120b14a3196ddb68d7eee6984",
            "49615a5471ec4dfaa680ce17bbdb0b20",
            "e09124830fe34f1188de39b032442e71",
            "c04152833afd4698a433b412e7cdaa34",
            "ae570e523488454db2e15497cb559193",
            "3aacfbe5cea742cb9c14b3fd7d83a22f",
            "b545ebc814c84849a3a4135b4e63eecc",
            "97e9d31cb0944577b8af3474ff4de4d0",
            "249beea318ff4a7c8a79c404e4eb396f",
            "bb64d32bee974a1e94a78b743e8edd8d",
            "9e35effea1de4071978b21429e35e101",
            "6a7738b9877e4446b94149ec5c10c720",
            "5908361288184762b6b783a15d0658b5",
            "0d70d737823f4ccfb761e3f53bef1e33",
            "9b11074f6edb4f899c10eb2764def0d5"
          ]
        },
        "outputId": "3751ed75-9ec3-4d06-830e-dd5281b30bab"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51f53054f35c43609fefbef62ee8ed92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae570e523488454db2e15497cb559193"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "# configure model, tokenizer\n",
        "with strategy.model_init_context():\n",
        "    actor = GPTActor(pretrained=args.pretrain_actor, lora_rank=args.lora_rank).to(torch.cuda.current_device())\n",
        "    critic = GPTCritic(pretrained=args.pretrain_critic, lora_rank=args.lora_rank).to(torch.cuda.current_device())\n",
        "    # tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "    # tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer = AutoTokenizer.from_pretrained(args.pretrain, padding_side=\"right\", model_max_length=512)\n",
        "    tokenizer.add_special_tokens(\n",
        "        {\n",
        "            \"eos_token\": DEFAULT_EOS_TOKEN,\n",
        "            \"bos_token\": DEFAULT_BOS_TOKEN,\n",
        "            \"unk_token\": DEFAULT_UNK_TOKEN,\n",
        "        }\n",
        "    )    \n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "    initial_model = deepcopy(actor)\n",
        "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OnJ76tgdnAr"
      },
      "outputs": [],
      "source": [
        "actor_optim = Adam(actor.parameters(), lr=5e-6)\n",
        "critic_optim = Adam(critic.parameters(), lr=5e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CPTGw5TeW9p"
      },
      "outputs": [],
      "source": [
        "# setting the models\n",
        "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = strategy.prepare(\n",
        "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jM3Tm4Lhdh5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73a13b99-42cd-4e4b-c040-95c9752113fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "119163\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "{'input_ids': tensor([[10054, 18896, 16740, 19490, 15949, 20938, 44696,   458, 46654, 13612,\n",
            "         13008,  9610, 30259, 10448, 36305,  9610,  9776,   389]],\n",
            "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0')}\n"
          ]
        }
      ],
      "source": [
        "# prepare data\n",
        "with open(args.data_path_3_PPO, \"r\", encoding='utf-8-sig') as json_file:\n",
        "    list_data_dict = json.load(json_file)\n",
        "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
        "\n",
        "def tokenize_fn(texts):\n",
        "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
        "    return {k: v.cuda() for k, v in batch.items()}\n",
        "\n",
        "print(len(list_prompt))\n",
        "print('\\n\\n\\n')\n",
        "print(tokenize_fn('I want you to act as a linux terminal.'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습"
      ],
      "metadata": {
        "id": "_xQRhhJwY1vn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAS01J_iedt5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bceffd26-7803-49af-c985-8d99b48c5847"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Episode [1/15]:   1%|▏         | 1/80 [00:03<04:10,  3.16s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.00116]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=0, critic_loss=0.00116]\n",
            "Episode [1/15]:   4%|▍         | 3/80 [00:08<03:22,  2.63s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0223, critic_loss=0.00197]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-.0223, critic_loss=0.00197]\n",
            "Episode [1/15]:   6%|▋         | 5/80 [00:13<03:09,  2.53s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.11, critic_loss=0.00529]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=0.11, critic_loss=0.00529]\n",
            "Episode [1/15]:   9%|▉         | 7/80 [00:18<03:03,  2.52s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0375, critic_loss=0.00274]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=0.0375, critic_loss=0.00274]\n",
            "Episode [1/15]:  11%|█▏        | 9/80 [00:23<02:57,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0238, critic_loss=0.00496]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-.0238, critic_loss=0.00496]\n",
            "Episode [1/15]:  14%|█▍        | 11/80 [00:28<02:48,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0272, critic_loss=0.00335]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, actor_loss=-.0272, critic_loss=0.00335]\n",
            "Episode [1/15]:  16%|█▋        | 13/80 [00:33<02:50,  2.54s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.00118, critic_loss=0.000889]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=0.00118, critic_loss=0.000889]\n",
            "Episode [1/15]:  19%|█▉        | 15/80 [00:38<02:48,  2.59s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0576, critic_loss=0.00222]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, actor_loss=0.0576, critic_loss=0.00222]\n",
            "Episode [1/15]:  21%|██▏       | 17/80 [00:43<02:40,  2.55s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0375, critic_loss=0.00228]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=0.0375, critic_loss=0.00228]\n",
            "Episode [1/15]:  24%|██▍       | 19/80 [00:48<02:33,  2.52s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0436, critic_loss=0.00356]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=0.0436, critic_loss=0.00356]\n",
            "Episode [1/15]:  26%|██▋       | 21/80 [00:53<02:27,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0817, critic_loss=0.00376]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=0.0817, critic_loss=0.00376]\n",
            "Episode [1/15]:  29%|██▉       | 23/80 [00:58<02:19,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0177, critic_loss=0.00153]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=0.0177, critic_loss=0.00153]\n",
            "Episode [1/15]:  31%|███▏      | 25/80 [01:03<02:13,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0011, critic_loss=0.00334]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-.0011, critic_loss=0.00334]\n",
            "Episode [1/15]:  34%|███▍      | 27/80 [01:08<02:11,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0397, critic_loss=0.00384]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.0397, critic_loss=0.00384]\n",
            "Episode [1/15]:  36%|███▋      | 29/80 [01:13<02:06,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0285, critic_loss=0.00225]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-.0285, critic_loss=0.00225]\n",
            "Episode [1/15]:  39%|███▉      | 31/80 [01:18<02:01,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0212, critic_loss=0.00886]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=0.0212, critic_loss=0.00886]\n",
            "Episode [1/15]:  41%|████▏     | 33/80 [01:23<01:57,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.00217, critic_loss=0.00179]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=0.00217, critic_loss=0.00179]\n",
            "Episode [1/15]:  44%|████▍     | 35/80 [01:28<01:51,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0195, critic_loss=0.00342]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=0.0195, critic_loss=0.00342]\n",
            "Episode [1/15]:  46%|████▋     | 37/80 [01:33<01:45,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0292, critic_loss=0.00304]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=0.0292, critic_loss=0.00304]\n",
            "Episode [1/15]:  49%|████▉     | 39/80 [01:38<01:40,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0919, critic_loss=0.0075]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=0.0919, critic_loss=0.0075]\n",
            "Episode [1/15]:  51%|█████▏    | 41/80 [01:43<01:35,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0619, critic_loss=0.021]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s, actor_loss=0.0619, critic_loss=0.021]\n",
            "Episode [1/15]:  54%|█████▍    | 43/80 [01:48<01:30,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0283, critic_loss=0.0345]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=0.0283, critic_loss=0.0345]\n",
            "Episode [1/15]:  56%|█████▋    | 45/80 [01:53<01:26,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0547, critic_loss=0.00733]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-.0547, critic_loss=0.00733]\n",
            "Episode [1/15]:  59%|█████▉    | 47/80 [01:58<01:21,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.00744, critic_loss=0.00776]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-.00744, critic_loss=0.00776]\n",
            "Episode [1/15]:  61%|██████▏   | 49/80 [02:03<01:15,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.475, critic_loss=4.38]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=0.475, critic_loss=4.38]\n",
            "Episode [1/15]:  64%|██████▍   | 51/80 [02:08<01:11,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.055, critic_loss=0.0178]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s, actor_loss=-.055, critic_loss=0.0178]\n",
            "Episode [1/15]:  66%|██████▋   | 53/80 [02:13<01:08,  2.52s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0476, critic_loss=0.0671]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-.0476, critic_loss=0.0671]\n",
            "Episode [1/15]:  69%|██████▉   | 55/80 [02:18<01:02,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0796, critic_loss=0.716]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=0.0796, critic_loss=0.716]\n",
            "Episode [1/15]:  71%|███████▏  | 57/80 [02:23<00:56,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.142, critic_loss=0.0382]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, actor_loss=-.142, critic_loss=0.0382]\n",
            "Episode [1/15]:  74%|███████▍  | 59/80 [02:28<00:52,  2.51s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=30.2, critic_loss=1.14e+4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=30.2, critic_loss=1.14e+4]\n",
            "Episode [1/15]:  76%|███████▋  | 61/80 [02:33<00:47,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.141, critic_loss=0.0613]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.141, critic_loss=0.0613]\n",
            "Episode [1/15]:  79%|███████▉  | 63/80 [02:38<00:41,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.206, critic_loss=0.093]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-.206, critic_loss=0.093]\n",
            "Episode [1/15]:  81%|████████▏ | 65/80 [02:43<00:37,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.715, critic_loss=2.11]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=0.715, critic_loss=2.11]\n",
            "Episode [1/15]:  84%|████████▍ | 67/80 [02:49<00:33,  2.58s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.195, critic_loss=0.152]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-.195, critic_loss=0.152]\n",
            "Episode [1/15]:  86%|████████▋ | 69/80 [02:54<00:27,  2.51s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=1.43, critic_loss=25.5]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=1.43, critic_loss=25.5]\n",
            "Episode [1/15]:  89%|████████▉ | 71/80 [02:58<00:22,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.786, critic_loss=7.73]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=0.786, critic_loss=7.73]\n",
            "Episode [1/15]:  91%|█████████▏| 73/80 [03:03<00:16,  2.40s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.361, critic_loss=0.245]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.361, critic_loss=0.245]\n",
            "Episode [1/15]:  94%|█████████▍| 75/80 [03:08<00:12,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0108, critic_loss=2.28]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=0.0108, critic_loss=2.28]\n",
            "Episode [1/15]:  96%|█████████▋| 77/80 [03:13<00:07,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.034, critic_loss=1.12]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=0.034, critic_loss=1.12]\n",
            "Episode [1/15]:  99%|█████████▉| 79/80 [03:18<00:02,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.042, critic_loss=3.48]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=0.042, critic_loss=3.48]\n",
            "Episode [1/15]: 100%|██████████| 80/80 [03:21<00:00,  2.52s/it]\n",
            "Episode [2/15]:   1%|▏         | 1/80 [00:02<02:59,  2.28s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.553, critic_loss=13.8]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=0.553, critic_loss=13.8]\n",
            "Episode [2/15]:   4%|▍         | 3/80 [00:07<03:03,  2.38s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=1.67, critic_loss=38.7]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=1.67, critic_loss=38.7]\n",
            "Episode [2/15]:   6%|▋         | 5/80 [00:12<03:04,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.311, critic_loss=0.919]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.311, critic_loss=0.919]\n",
            "Episode [2/15]:   9%|▉         | 7/80 [00:17<02:58,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.443, critic_loss=0.461]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.443, critic_loss=0.461]\n",
            "Episode [2/15]:  11%|█▏        | 9/80 [00:21<02:50,  2.40s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.323, critic_loss=0.84]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.323, critic_loss=0.84]\n",
            "Episode [2/15]:  14%|█▍        | 11/80 [00:27<02:50,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.381, critic_loss=0.504]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-.381, critic_loss=0.504]\n",
            "Episode [2/15]:  16%|█▋        | 13/80 [00:32<02:45,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0587, critic_loss=1.36]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-.0587, critic_loss=1.36]\n",
            "Episode [2/15]:  19%|█▉        | 15/80 [00:37<02:40,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.683, critic_loss=0.729]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.683, critic_loss=0.729]\n",
            "Episode [2/15]:  21%|██▏       | 17/80 [00:42<02:37,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0741, critic_loss=1.11]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-.0741, critic_loss=1.11]\n",
            "Episode [2/15]:  24%|██▍       | 19/80 [00:47<02:32,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=1.08, critic_loss=11.6]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=1.08, critic_loss=11.6]\n",
            "Episode [2/15]:  26%|██▋       | 21/80 [00:52<02:24,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.451, critic_loss=0.525]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.451, critic_loss=0.525]\n",
            "Episode [2/15]:  29%|██▉       | 23/80 [00:57<02:19,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.3, critic_loss=1.86]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-.3, critic_loss=1.86]\n",
            "Episode [2/15]:  31%|███▏      | 25/80 [01:01<02:14,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=3.87, critic_loss=184]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=3.87, critic_loss=184]\n",
            "Episode [2/15]:  34%|███▍      | 27/80 [01:06<02:09,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.72, critic_loss=15.3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, actor_loss=0.72, critic_loss=15.3]\n",
            "Episode [2/15]:  36%|███▋      | 29/80 [01:11<02:05,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.565, critic_loss=0.623]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-.565, critic_loss=0.623]\n",
            "Episode [2/15]:  39%|███▉      | 31/80 [01:16<02:00,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.192, critic_loss=1.08]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.192, critic_loss=1.08]\n",
            "Episode [2/15]:  41%|████▏     | 33/80 [01:21<01:53,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=1.67, critic_loss=38.6]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=1.67, critic_loss=38.6]\n",
            "Episode [2/15]:  44%|████▍     | 35/80 [01:26<01:49,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.639, critic_loss=2.51]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=0.639, critic_loss=2.51]\n",
            "Episode [2/15]:  46%|████▋     | 37/80 [01:31<01:46,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.248, critic_loss=0.976]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.248, critic_loss=0.976]\n",
            "Episode [2/15]:  49%|████▉     | 39/80 [01:36<01:40,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.603, critic_loss=0.609]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-.603, critic_loss=0.609]\n",
            "Episode [2/15]:  51%|█████▏    | 41/80 [01:41<01:37,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.551, critic_loss=0.617]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-.551, critic_loss=0.617]\n",
            "Episode [2/15]:  54%|█████▍    | 43/80 [01:46<01:31,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.331, critic_loss=1.09]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-.331, critic_loss=1.09]\n",
            "Episode [2/15]:  56%|█████▋    | 45/80 [01:51<01:25,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.364, critic_loss=1.05]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.364, critic_loss=1.05]\n",
            "Episode [2/15]:  59%|█████▉    | 47/80 [01:56<01:20,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.624, critic_loss=0.585]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-.624, critic_loss=0.585]\n",
            "Episode [2/15]:  61%|██████▏   | 49/80 [02:01<01:16,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=1.05, critic_loss=21.2]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=1.05, critic_loss=21.2]\n",
            "Episode [2/15]:  64%|██████▍   | 51/80 [02:06<01:11,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.192, critic_loss=1.12]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.192, critic_loss=1.12]\n",
            "Episode [2/15]:  66%|██████▋   | 53/80 [02:11<01:06,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.119, critic_loss=0.964]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.119, critic_loss=0.964]\n",
            "Episode [2/15]:  69%|██████▉   | 55/80 [02:16<01:01,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0515, critic_loss=1.58]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.0515, critic_loss=1.58]\n",
            "Episode [2/15]:  71%|███████▏  | 57/80 [02:21<00:56,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.417, critic_loss=11.1]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=0.417, critic_loss=11.1]\n",
            "Episode [2/15]:  74%|███████▍  | 59/80 [02:26<00:51,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.61, critic_loss=0.634]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.61, critic_loss=0.634]\n",
            "Episode [2/15]:  76%|███████▋  | 61/80 [02:31<00:46,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.202, critic_loss=1.63]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, actor_loss=-.202, critic_loss=1.63]\n",
            "Episode [2/15]:  79%|███████▉  | 63/80 [02:36<00:42,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.511, critic_loss=0.443]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-.511, critic_loss=0.443]\n",
            "Episode [2/15]:  81%|████████▏ | 65/80 [02:41<00:36,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.517, critic_loss=0.528]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-.517, critic_loss=0.528]\n",
            "Episode [2/15]:  84%|████████▍ | 67/80 [02:46<00:31,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.882, critic_loss=4.22]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=0.882, critic_loss=4.22]\n",
            "Episode [2/15]:  86%|████████▋ | 69/80 [02:51<00:27,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0536, critic_loss=3.49]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=0.0536, critic_loss=3.49]\n",
            "Episode [2/15]:  89%|████████▉ | 71/80 [02:56<00:22,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.633, critic_loss=16.3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s, actor_loss=0.633, critic_loss=16.3]\n",
            "Episode [2/15]:  91%|█████████▏| 73/80 [03:01<00:17,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.00458, critic_loss=5.13]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, actor_loss=0.00458, critic_loss=5.13]\n",
            "Episode [2/15]:  94%|█████████▍| 75/80 [03:06<00:12,  2.51s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.381, critic_loss=0.339]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-.381, critic_loss=0.339]\n",
            "Episode [2/15]:  96%|█████████▋| 77/80 [03:11<00:07,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.296, critic_loss=0.459]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-.296, critic_loss=0.459]\n",
            "Episode [2/15]:  99%|█████████▉| 79/80 [03:16<00:02,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=1.55, critic_loss=9.37]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=1.55, critic_loss=9.37]\n",
            "Episode [2/15]: 100%|██████████| 80/80 [03:19<00:00,  2.49s/it]\n",
            "Episode [3/15]:   1%|▏         | 1/80 [00:02<03:11,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.138, critic_loss=2.09]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=0.138, critic_loss=2.09]\n",
            "Episode [3/15]:   4%|▍         | 3/80 [00:07<03:09,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.368, critic_loss=0.309]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-.368, critic_loss=0.309]\n",
            "Episode [3/15]:   6%|▋         | 5/80 [00:12<03:03,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.107, critic_loss=0.836]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-.107, critic_loss=0.836]\n",
            "Episode [3/15]:   9%|▉         | 7/80 [00:17<03:01,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.407, critic_loss=0.359]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.407, critic_loss=0.359]\n",
            "Episode [3/15]:  11%|█▏        | 9/80 [00:22<02:56,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.295, critic_loss=0.208]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-.295, critic_loss=0.208]\n",
            "Episode [3/15]:  14%|█▍        | 11/80 [00:27<02:50,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.115, critic_loss=0.722]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.115, critic_loss=0.722]\n",
            "Episode [3/15]:  16%|█▋        | 13/80 [00:32<02:51,  2.56s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0725, critic_loss=0.774]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-.0725, critic_loss=0.774]\n",
            "Episode [3/15]:  19%|█▉        | 15/80 [00:38<02:49,  2.61s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=2.19, critic_loss=66.1]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=2.19, critic_loss=66.1]\n",
            "Episode [3/15]:  21%|██▏       | 17/80 [00:43<02:38,  2.51s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=23.6, critic_loss=6.85e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=23.6, critic_loss=6.85e+3]\n",
            "Episode [3/15]:  24%|██▍       | 19/80 [00:47<02:28,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.348, critic_loss=0.391]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-.348, critic_loss=0.391]\n",
            "Episode [3/15]:  26%|██▋       | 21/80 [00:52<02:24,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.392, critic_loss=0.524]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.392, critic_loss=0.524]\n",
            "Episode [3/15]:  29%|██▉       | 23/80 [00:57<02:18,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0436, critic_loss=2.75]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=0.0436, critic_loss=2.75]\n",
            "Episode [3/15]:  31%|███▏      | 25/80 [01:02<02:15,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.803, critic_loss=13.7]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s, actor_loss=0.803, critic_loss=13.7]\n",
            "Episode [3/15]:  34%|███▍      | 27/80 [01:07<02:12,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.676, critic_loss=0.88]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-.676, critic_loss=0.88]\n",
            "Episode [3/15]:  36%|███▋      | 29/80 [01:12<02:06,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.67, critic_loss=0.958]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-.67, critic_loss=0.958]\n",
            "Episode [3/15]:  39%|███▉      | 31/80 [01:17<02:02,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.743, critic_loss=1.09]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-.743, critic_loss=1.09]\n",
            "Episode [3/15]:  41%|████▏     | 33/80 [01:22<01:58,  2.52s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.752, critic_loss=1.14]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-.752, critic_loss=1.14]\n",
            "Episode [3/15]:  44%|████▍     | 35/80 [01:27<01:52,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.806, critic_loss=1.17]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-.806, critic_loss=1.17]\n",
            "Episode [3/15]:  46%|████▋     | 37/80 [01:32<01:45,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.66, critic_loss=0.907]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-.66, critic_loss=0.907]\n",
            "Episode [3/15]:  49%|████▉     | 39/80 [01:37<01:41,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.965, critic_loss=1.37]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s, actor_loss=-.965, critic_loss=1.37]\n",
            "Episode [3/15]:  51%|█████▏    | 41/80 [01:42<01:35,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.769, critic_loss=1.05]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-.769, critic_loss=1.05]\n",
            "Episode [3/15]:  54%|█████▍    | 43/80 [01:47<01:29,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.765, critic_loss=1.18]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-.765, critic_loss=1.18]\n",
            "Episode [3/15]:  56%|█████▋    | 45/80 [01:52<01:26,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.77, critic_loss=1.18]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.77, critic_loss=1.18]\n",
            "Episode [3/15]:  59%|█████▉    | 47/80 [01:57<01:19,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.754, critic_loss=1.05]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.754, critic_loss=1.05]\n",
            "Episode [3/15]:  61%|██████▏   | 49/80 [02:02<01:15,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.707, critic_loss=0.836]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, actor_loss=-.707, critic_loss=0.836]\n",
            "Episode [3/15]:  64%|██████▍   | 51/80 [02:07<01:11,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.671, critic_loss=0.802]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-.671, critic_loss=0.802]\n",
            "Episode [3/15]:  66%|██████▋   | 53/80 [02:12<01:06,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.695, critic_loss=1.04]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-.695, critic_loss=1.04]\n",
            "Episode [3/15]:  69%|██████▉   | 55/80 [02:17<00:59,  2.39s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.582, critic_loss=0.823]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-.582, critic_loss=0.823]\n",
            "Episode [3/15]:  71%|███████▏  | 57/80 [02:22<00:55,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.641, critic_loss=0.807]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-.641, critic_loss=0.807]\n",
            "Episode [3/15]:  74%|███████▍  | 59/80 [02:27<00:51,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.631, critic_loss=0.757]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.631, critic_loss=0.757]\n",
            "Episode [3/15]:  76%|███████▋  | 61/80 [02:31<00:45,  2.39s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.567, critic_loss=0.733]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s, actor_loss=-.567, critic_loss=0.733]\n",
            "Episode [3/15]:  79%|███████▉  | 63/80 [02:36<00:40,  2.39s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.487, critic_loss=0.561]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-.487, critic_loss=0.561]\n",
            "Episode [3/15]:  81%|████████▏ | 65/80 [02:41<00:36,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.602, critic_loss=0.756]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-.602, critic_loss=0.756]\n",
            "Episode [3/15]:  84%|████████▍ | 67/80 [02:46<00:32,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.56, critic_loss=0.622]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-.56, critic_loss=0.622]\n",
            "Episode [3/15]:  86%|████████▋ | 69/80 [02:51<00:27,  2.51s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.575, critic_loss=0.657]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-.575, critic_loss=0.657]\n",
            "Episode [3/15]:  89%|████████▉ | 71/80 [02:56<00:22,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.451, critic_loss=0.429]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.451, critic_loss=0.429]\n",
            "Episode [3/15]:  91%|█████████▏| 73/80 [03:02<00:17,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.53, critic_loss=0.602]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.53, critic_loss=0.602]\n",
            "Episode [3/15]:  94%|█████████▍| 75/80 [03:06<00:12,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.398, critic_loss=0.36]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-.398, critic_loss=0.36]\n",
            "Episode [3/15]:  96%|█████████▋| 77/80 [03:12<00:07,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.534, critic_loss=0.561]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-.534, critic_loss=0.561]\n",
            "Episode [3/15]:  99%|█████████▉| 79/80 [03:16<00:02,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.273, critic_loss=0.251]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.273, critic_loss=0.251]\n",
            "Episode [3/15]: 100%|██████████| 80/80 [03:19<00:00,  2.50s/it]\n",
            "Episode [4/15]:   1%|▏         | 1/80 [00:02<02:53,  2.20s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.489, critic_loss=0.484]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, actor_loss=-.489, critic_loss=0.484]\n",
            "Episode [4/15]:   4%|▍         | 3/80 [00:07<03:06,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.224, critic_loss=0.208]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.224, critic_loss=0.208]\n",
            "Episode [4/15]:   6%|▋         | 5/80 [00:12<03:03,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.256, critic_loss=0.225]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.256, critic_loss=0.225]\n",
            "Episode [4/15]:   9%|▉         | 7/80 [00:17<02:58,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0298, critic_loss=0.876]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s, actor_loss=-.0298, critic_loss=0.876]\n",
            "Episode [4/15]:  11%|█▏        | 9/80 [00:22<02:54,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.173, critic_loss=0.124]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-.173, critic_loss=0.124]\n",
            "Episode [4/15]:  14%|█▍        | 11/80 [00:27<02:50,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.326, critic_loss=0.316]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-.326, critic_loss=0.316]\n",
            "Episode [4/15]:  16%|█▋        | 13/80 [00:32<02:44,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.145, critic_loss=0.141]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-.145, critic_loss=0.141]\n",
            "Episode [4/15]:  19%|█▉        | 15/80 [00:37<02:39,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.115, critic_loss=0.175]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-.115, critic_loss=0.175]\n",
            "Episode [4/15]:  21%|██▏       | 17/80 [00:42<02:37,  2.51s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.037, critic_loss=0.165]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-.037, critic_loss=0.165]\n",
            "Episode [4/15]:  24%|██▍       | 19/80 [00:47<02:30,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0444, critic_loss=0.119]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=0.0444, critic_loss=0.119]\n",
            "Episode [4/15]:  26%|██▋       | 21/80 [00:52<02:23,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0141, critic_loss=0.2]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-.0141, critic_loss=0.2]\n",
            "Episode [4/15]:  29%|██▉       | 23/80 [00:57<02:19,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0545, critic_loss=0.136]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-.0545, critic_loss=0.136]\n",
            "Episode [4/15]:  31%|███▏      | 25/80 [01:02<02:15,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.182, critic_loss=0.165]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.182, critic_loss=0.165]\n",
            "Episode [4/15]:  34%|███▍      | 27/80 [01:07<02:10,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.239, critic_loss=0.13]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-.239, critic_loss=0.13]\n",
            "Episode [4/15]:  36%|███▋      | 29/80 [01:11<02:04,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.278, critic_loss=0.326]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=0.278, critic_loss=0.326]\n",
            "Episode [4/15]:  39%|███▉      | 31/80 [01:16<02:00,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0019, critic_loss=0.163]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.22it/s, actor_loss=0.0019, critic_loss=0.163]\n",
            "Episode [4/15]:  41%|████▏     | 33/80 [01:21<01:55,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0838, critic_loss=0.0943]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-.0838, critic_loss=0.0943]\n",
            "Episode [4/15]:  44%|████▍     | 35/80 [01:26<01:50,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.196, critic_loss=0.142]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=0.196, critic_loss=0.142]\n",
            "Episode [4/15]:  46%|████▋     | 37/80 [01:31<01:46,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.114, critic_loss=0.12]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-.114, critic_loss=0.12]\n",
            "Episode [4/15]:  49%|████▉     | 39/80 [01:36<01:40,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.218, critic_loss=0.26]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=0.218, critic_loss=0.26]\n",
            "Episode [4/15]:  51%|█████▏    | 41/80 [01:41<01:37,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.11, critic_loss=0.148]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s, actor_loss=0.11, critic_loss=0.148]\n",
            "Episode [4/15]:  54%|█████▍    | 43/80 [01:47<01:35,  2.57s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0569, critic_loss=0.135]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=0.0569, critic_loss=0.135]\n",
            "Episode [4/15]:  56%|█████▋    | 45/80 [01:52<01:26,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0368, critic_loss=0.0952]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=0.0368, critic_loss=0.0952]\n",
            "Episode [4/15]:  59%|█████▉    | 47/80 [01:57<01:21,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0545, critic_loss=0.0994]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=0.0545, critic_loss=0.0994]\n",
            "Episode [4/15]:  61%|██████▏   | 49/80 [02:02<01:17,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.105, critic_loss=0.106]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=0.105, critic_loss=0.106]\n",
            "Episode [4/15]:  64%|██████▍   | 51/80 [02:07<01:10,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.172, critic_loss=0.099]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=0.172, critic_loss=0.099]\n",
            "Episode [4/15]:  66%|██████▋   | 53/80 [02:11<01:06,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.00605, critic_loss=0.176]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-.00605, critic_loss=0.176]\n",
            "Episode [4/15]:  69%|██████▉   | 55/80 [02:17<01:02,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0289, critic_loss=0.057]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=0.0289, critic_loss=0.057]\n",
            "Episode [4/15]:  71%|███████▏  | 57/80 [02:22<00:57,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=7.05, critic_loss=0.116]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=7.05, critic_loss=0.116]\n",
            "Episode [4/15]:  74%|███████▍  | 59/80 [02:26<00:51,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.128, critic_loss=0.125]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=0.128, critic_loss=0.125]\n",
            "Episode [4/15]:  76%|███████▋  | 61/80 [02:32<00:47,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.134, critic_loss=0.0723]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=0.134, critic_loss=0.0723]\n",
            "Episode [4/15]:  79%|███████▉  | 63/80 [02:37<00:41,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0493, critic_loss=0.121]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=0.0493, critic_loss=0.121]\n",
            "Episode [4/15]:  81%|████████▏ | 65/80 [02:41<00:36,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.00467, critic_loss=0.0569]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.00467, critic_loss=0.0569]\n",
            "Episode [4/15]:  84%|████████▍ | 67/80 [02:46<00:31,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0496, critic_loss=0.174]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=0.0496, critic_loss=0.174]\n",
            "Episode [4/15]:  86%|████████▋ | 69/80 [02:51<00:27,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0683, critic_loss=0.0801]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=0.0683, critic_loss=0.0801]\n",
            "Episode [4/15]:  89%|████████▉ | 71/80 [02:56<00:22,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.113, critic_loss=0.0899]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=0.113, critic_loss=0.0899]\n",
            "Episode [4/15]:  91%|█████████▏| 73/80 [03:01<00:17,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.155, critic_loss=0.058]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=0.155, critic_loss=0.058]\n",
            "Episode [4/15]:  94%|█████████▍| 75/80 [03:06<00:12,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.103, critic_loss=0.0552]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=0.103, critic_loss=0.0552]\n",
            "Episode [4/15]:  96%|█████████▋| 77/80 [03:11<00:07,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.109, critic_loss=0.14]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=0.109, critic_loss=0.14]\n",
            "Episode [4/15]:  99%|█████████▉| 79/80 [03:16<00:02,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.25, critic_loss=0.104]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=0.25, critic_loss=0.104]\n",
            "Episode [4/15]: 100%|██████████| 80/80 [03:19<00:00,  2.49s/it]\n",
            "Episode [5/15]:   1%|▏         | 1/80 [00:02<03:06,  2.36s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.119, critic_loss=0.1]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.119, critic_loss=0.1]\n",
            "Episode [5/15]:   4%|▍         | 3/80 [00:07<02:59,  2.34s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.348, critic_loss=0.482]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=0.348, critic_loss=0.482]\n",
            "Episode [5/15]:   6%|▋         | 5/80 [00:11<02:57,  2.37s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0315, critic_loss=0.0968]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-.0315, critic_loss=0.0968]\n",
            "Episode [5/15]:   9%|▉         | 7/80 [00:17<02:58,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.063, critic_loss=0.0896]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=0.063, critic_loss=0.0896]\n",
            "Episode [5/15]:  11%|█▏        | 9/80 [00:21<02:51,  2.41s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.205, critic_loss=0.128]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=0.205, critic_loss=0.128]\n",
            "Episode [5/15]:  14%|█▍        | 11/80 [00:26<02:44,  2.39s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0374, critic_loss=0.122]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.0374, critic_loss=0.122]\n",
            "Episode [5/15]:  16%|█▋        | 13/80 [00:31<02:46,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0916, critic_loss=0.108]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s, actor_loss=0.0916, critic_loss=0.108]\n",
            "Episode [5/15]:  19%|█▉        | 15/80 [00:36<02:37,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.947, critic_loss=2.26]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=0.947, critic_loss=2.26]\n",
            "Episode [5/15]:  21%|██▏       | 17/80 [00:41<02:35,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.156, critic_loss=0.298]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=0.156, critic_loss=0.298]\n",
            "Episode [5/15]:  24%|██▍       | 19/80 [00:46<02:32,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.697, critic_loss=0.332]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=0.697, critic_loss=0.332]\n",
            "Episode [5/15]:  26%|██▋       | 21/80 [00:51<02:27,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0107, critic_loss=0.0726]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.0107, critic_loss=0.0726]\n",
            "Episode [5/15]:  29%|██▉       | 23/80 [00:56<02:20,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.00631, critic_loss=0.0771]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-.00631, critic_loss=0.0771]\n",
            "Episode [5/15]:  31%|███▏      | 25/80 [01:01<02:17,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0212, critic_loss=0.0481]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s, actor_loss=0.0212, critic_loss=0.0481]\n",
            "Episode [5/15]:  34%|███▍      | 27/80 [01:06<02:11,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0442, critic_loss=0.0956]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.0442, critic_loss=0.0956]\n",
            "Episode [5/15]:  36%|███▋      | 29/80 [01:11<02:05,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.4, critic_loss=0.498]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=0.4, critic_loss=0.498]\n",
            "Episode [5/15]:  39%|███▉      | 31/80 [01:16<02:01,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0151, critic_loss=0.0648]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=0.0151, critic_loss=0.0648]\n",
            "Episode [5/15]:  41%|████▏     | 33/80 [01:21<01:56,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0968, critic_loss=0.0565]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.0968, critic_loss=0.0565]\n",
            "Episode [5/15]:  44%|████▍     | 35/80 [01:26<01:49,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0368, critic_loss=0.0866]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=0.0368, critic_loss=0.0866]\n",
            "Episode [5/15]:  46%|████▋     | 37/80 [01:31<01:44,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.177, critic_loss=0.155]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=0.177, critic_loss=0.155]\n",
            "Episode [5/15]:  49%|████▉     | 39/80 [01:36<01:38,  2.39s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.534, critic_loss=0.116]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=0.534, critic_loss=0.116]\n",
            "Episode [5/15]:  51%|█████▏    | 41/80 [01:41<01:34,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.147, critic_loss=0.0902]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-.147, critic_loss=0.0902]\n",
            "Episode [5/15]:  54%|█████▍    | 43/80 [01:46<01:29,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0585, critic_loss=0.12]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, actor_loss=-.0585, critic_loss=0.12]\n",
            "Episode [5/15]:  56%|█████▋    | 45/80 [01:51<01:25,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.063, critic_loss=0.052]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-.063, critic_loss=0.052]\n",
            "Episode [5/15]:  59%|█████▉    | 47/80 [01:56<01:20,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.448, critic_loss=0.218]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=0.448, critic_loss=0.218]\n",
            "Episode [5/15]:  61%|██████▏   | 49/80 [02:01<01:15,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.00283, critic_loss=0.0287]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=0.00283, critic_loss=0.0287]\n",
            "Episode [5/15]:  64%|██████▍   | 51/80 [02:06<01:11,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0178, critic_loss=0.0478]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.0178, critic_loss=0.0478]\n",
            "Episode [5/15]:  66%|██████▋   | 53/80 [02:10<01:06,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0364, critic_loss=0.0398]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.0364, critic_loss=0.0398]\n",
            "Episode [5/15]:  69%|██████▉   | 55/80 [02:15<00:59,  2.39s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0588, critic_loss=0.0571]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-.0588, critic_loss=0.0571]\n",
            "Episode [5/15]:  71%|███████▏  | 57/80 [02:20<00:56,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0545, critic_loss=0.194]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=0.0545, critic_loss=0.194]\n",
            "Episode [5/15]:  74%|███████▍  | 59/80 [02:25<00:51,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.00232, critic_loss=0.0581]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-.00232, critic_loss=0.0581]\n",
            "Episode [5/15]:  76%|███████▋  | 61/80 [02:30<00:45,  2.39s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.476, critic_loss=0.409]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=0.476, critic_loss=0.409]\n",
            "Episode [5/15]:  79%|███████▉  | 63/80 [02:35<00:40,  2.41s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.614, critic_loss=4.64]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=0.614, critic_loss=4.64]\n",
            "Episode [5/15]:  81%|████████▏ | 65/80 [02:40<00:36,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0951, critic_loss=0.0654]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s, actor_loss=0.0951, critic_loss=0.0654]\n",
            "Episode [5/15]:  84%|████████▍ | 67/80 [02:45<00:31,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0693, critic_loss=0.0809]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s, actor_loss=-.0693, critic_loss=0.0809]\n",
            "Episode [5/15]:  86%|████████▋ | 69/80 [02:50<00:26,  2.39s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.585, critic_loss=0.147]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=0.585, critic_loss=0.147]\n",
            "Episode [5/15]:  89%|████████▉ | 71/80 [02:55<00:23,  2.58s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=8.96, critic_loss=1.34]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=8.96, critic_loss=1.34]\n",
            "Episode [5/15]:  91%|█████████▏| 73/80 [03:00<00:17,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0256, critic_loss=0.0637]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s, actor_loss=0.0256, critic_loss=0.0637]\n",
            "Episode [5/15]:  94%|█████████▍| 75/80 [03:05<00:12,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=1.46, critic_loss=13.7]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s, actor_loss=1.46, critic_loss=13.7]\n",
            "Episode [5/15]:  96%|█████████▋| 77/80 [03:10<00:07,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=2.97, critic_loss=48.3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=2.97, critic_loss=48.3]\n",
            "Episode [5/15]:  99%|█████████▉| 79/80 [03:15<00:02,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0358, critic_loss=0.043]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.0358, critic_loss=0.043]\n",
            "Episode [5/15]: 100%|██████████| 80/80 [03:17<00:00,  2.47s/it]\n",
            "Episode [6/15]:   1%|▏         | 1/80 [00:02<03:05,  2.35s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=6.09, critic_loss=434]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=6.09, critic_loss=434]\n",
            "Episode [6/15]:   4%|▍         | 3/80 [00:07<03:10,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.219, critic_loss=2.27]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=0.219, critic_loss=2.27]\n",
            "Episode [6/15]:   6%|▋         | 5/80 [00:12<03:03,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0489, critic_loss=0.613]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=0.0489, critic_loss=0.613]\n",
            "Episode [6/15]:   9%|▉         | 7/80 [00:17<02:56,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.218, critic_loss=1.64]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=0.218, critic_loss=1.64]\n",
            "Episode [6/15]:  11%|█▏        | 9/80 [00:22<02:53,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.972, critic_loss=16.1]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=0.972, critic_loss=16.1]\n",
            "Episode [6/15]:  14%|█▍        | 11/80 [00:27<02:49,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.00337, critic_loss=0.325]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.00337, critic_loss=0.325]\n",
            "Episode [6/15]:  16%|█▋        | 13/80 [00:32<02:44,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0478, critic_loss=0.266]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-.0478, critic_loss=0.266]\n",
            "Episode [6/15]:  19%|█▉        | 15/80 [00:37<02:39,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.493, critic_loss=5.59]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=0.493, critic_loss=5.59]\n",
            "Episode [6/15]:  21%|██▏       | 17/80 [00:42<02:34,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.317, critic_loss=0.209]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-.317, critic_loss=0.209]\n",
            "Episode [6/15]:  24%|██▍       | 19/80 [00:46<02:28,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.184, critic_loss=0.349]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.184, critic_loss=0.349]\n",
            "Episode [6/15]:  26%|██▋       | 21/80 [00:51<02:24,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.254, critic_loss=0.29]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-.254, critic_loss=0.29]\n",
            "Episode [6/15]:  29%|██▉       | 23/80 [00:56<02:20,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=2.89, critic_loss=43]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=2.89, critic_loss=43]\n",
            "Episode [6/15]:  31%|███▏      | 25/80 [01:01<02:14,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=11.2, critic_loss=1.51e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=11.2, critic_loss=1.51e+3]\n",
            "Episode [6/15]:  34%|███▍      | 27/80 [01:06<02:08,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=25.3, critic_loss=4.65e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=25.3, critic_loss=4.65e+3]\n",
            "Episode [6/15]:  36%|███▋      | 29/80 [01:11<02:04,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=265, critic_loss=8.33e+5]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=265, critic_loss=8.33e+5]\n",
            "Episode [6/15]:  39%|███▉      | 31/80 [01:16<01:59,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=1.39, critic_loss=13.8]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=1.39, critic_loss=13.8]\n",
            "Episode [6/15]:  41%|████▏     | 33/80 [01:21<01:54,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.296, critic_loss=3.3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.296, critic_loss=3.3]\n",
            "Episode [6/15]:  44%|████▍     | 35/80 [01:26<01:47,  2.39s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=6.98, critic_loss=933]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=6.98, critic_loss=933]\n",
            "Episode [6/15]:  46%|████▋     | 37/80 [01:30<01:38,  2.30s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.509, critic_loss=2.22]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s, actor_loss=-.509, critic_loss=2.22]\n",
            "Episode [6/15]:  49%|████▉     | 39/80 [01:35<01:36,  2.36s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=14.8, critic_loss=2.93e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=14.8, critic_loss=2.93e+3]\n",
            "Episode [6/15]:  51%|█████▏    | 41/80 [01:40<01:34,  2.41s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.105, critic_loss=10.5]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=0.105, critic_loss=10.5]\n",
            "Episode [6/15]:  54%|█████▍    | 43/80 [01:45<01:29,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=82.2, critic_loss=4.32e+4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=82.2, critic_loss=4.32e+4]\n",
            "Episode [6/15]:  56%|█████▋    | 45/80 [01:50<01:24,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=4.55, critic_loss=141]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, actor_loss=4.55, critic_loss=141]\n",
            "Episode [6/15]:  59%|█████▉    | 47/80 [01:55<01:21,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-1.4, critic_loss=3.93]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-1.4, critic_loss=3.93]\n",
            "Episode [6/15]:  61%|██████▏   | 49/80 [02:00<01:16,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.95, critic_loss=5.19]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.95, critic_loss=5.19]\n",
            "Episode [6/15]:  64%|██████▍   | 51/80 [02:05<01:10,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-1.02, critic_loss=6.44]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-1.02, critic_loss=6.44]\n",
            "Episode [6/15]:  66%|██████▋   | 53/80 [02:10<01:06,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-1.92, critic_loss=5.86]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-1.92, critic_loss=5.86]\n",
            "Episode [6/15]:  69%|██████▉   | 55/80 [02:15<01:00,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.45, critic_loss=47.7]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-.45, critic_loss=47.7]\n",
            "Episode [6/15]:  71%|███████▏  | 57/80 [02:20<00:55,  2.41s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.0734, critic_loss=31]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.0734, critic_loss=31]\n",
            "Episode [6/15]:  74%|███████▍  | 59/80 [02:25<00:50,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=3.51, critic_loss=106]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, actor_loss=3.51, critic_loss=106]\n",
            "Episode [6/15]:  76%|███████▋  | 61/80 [02:30<00:46,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-1.76, critic_loss=7.38]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-1.76, critic_loss=7.38]\n",
            "Episode [6/15]:  79%|███████▉  | 63/80 [02:35<00:41,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=6, critic_loss=1.12e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=6, critic_loss=1.12e+3]\n",
            "Episode [6/15]:  81%|████████▏ | 65/80 [02:40<00:36,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-1.99, critic_loss=8.12]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-1.99, critic_loss=8.12]\n",
            "Episode [6/15]:  84%|████████▍ | 67/80 [02:45<00:32,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.766, critic_loss=63]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=0.766, critic_loss=63]\n",
            "Episode [6/15]:  86%|████████▋ | 69/80 [02:49<00:25,  2.34s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.05, critic_loss=7.5]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-2.05, critic_loss=7.5]\n",
            "Episode [6/15]:  89%|████████▉ | 71/80 [02:54<00:21,  2.40s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-1.58, critic_loss=7.98]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-1.58, critic_loss=7.98]\n",
            "Episode [6/15]:  91%|█████████▏| 73/80 [02:59<00:17,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-1.73, critic_loss=12.1]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-1.73, critic_loss=12.1]\n",
            "Episode [6/15]:  94%|█████████▍| 75/80 [03:04<00:12,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=56.2, critic_loss=1.96e+4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=56.2, critic_loss=1.96e+4]\n",
            "Episode [6/15]:  96%|█████████▋| 77/80 [03:09<00:07,  2.35s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.39, critic_loss=9.77]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-2.39, critic_loss=9.77]\n",
            "Episode [6/15]:  99%|█████████▉| 79/80 [03:14<00:02,  2.40s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-1.38, critic_loss=7.48]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s, actor_loss=-1.38, critic_loss=7.48]\n",
            "Episode [6/15]: 100%|██████████| 80/80 [03:16<00:00,  2.46s/it]\n",
            "Episode [7/15]:   1%|▏         | 1/80 [00:02<02:55,  2.22s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=26.8, critic_loss=1.07e+4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s, actor_loss=26.8, critic_loss=1.07e+4]\n",
            "Episode [7/15]:   4%|▍         | 3/80 [00:07<03:03,  2.38s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=12, critic_loss=2.33e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=12, critic_loss=2.33e+3]\n",
            "Episode [7/15]:   6%|▋         | 5/80 [00:12<03:03,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.391, critic_loss=32.9]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, actor_loss=0.391, critic_loss=32.9]\n",
            "Episode [7/15]:   9%|▉         | 7/80 [00:17<02:59,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=6.88, critic_loss=1.7e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s, actor_loss=6.88, critic_loss=1.7e+3]\n",
            "Episode [7/15]:  11%|█▏        | 9/80 [00:21<02:50,  2.41s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.2, critic_loss=11.3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-2.2, critic_loss=11.3]\n",
            "Episode [7/15]:  14%|█▍        | 11/80 [00:26<02:40,  2.32s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.29, critic_loss=9.37]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-2.29, critic_loss=9.37]\n",
            "Episode [7/15]:  16%|█▋        | 13/80 [00:31<02:40,  2.39s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.38, critic_loss=11.4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-2.38, critic_loss=11.4]\n",
            "Episode [7/15]:  19%|█▉        | 15/80 [00:36<02:34,  2.38s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=2.42, critic_loss=39.2]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=2.42, critic_loss=39.2]\n",
            "Episode [7/15]:  21%|██▏       | 17/80 [00:41<02:31,  2.41s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=1.52, critic_loss=169]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=1.52, critic_loss=169]\n",
            "Episode [7/15]:  24%|██▍       | 19/80 [00:46<02:28,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=1.55, critic_loss=269]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=1.55, critic_loss=269]\n",
            "Episode [7/15]:  26%|██▋       | 21/80 [00:51<02:24,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=177, critic_loss=2.48e+5]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=177, critic_loss=2.48e+5]\n",
            "Episode [7/15]:  29%|██▉       | 23/80 [00:56<02:19,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.95, critic_loss=16.5]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-2.95, critic_loss=16.5]\n",
            "Episode [7/15]:  31%|███▏      | 25/80 [01:01<02:14,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=23.4, critic_loss=6.89e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=23.4, critic_loss=6.89e+3]\n",
            "Episode [7/15]:  34%|███▍      | 27/80 [01:06<02:10,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-1.46, critic_loss=27.4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-1.46, critic_loss=27.4]\n",
            "Episode [7/15]:  36%|███▋      | 29/80 [01:10<02:04,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=11.4, critic_loss=1.36e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=11.4, critic_loss=1.36e+3]\n",
            "Episode [7/15]:  39%|███▉      | 31/80 [01:15<01:58,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=28.3, critic_loss=1.36e+4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=28.3, critic_loss=1.36e+4]\n",
            "Episode [7/15]:  41%|████▏     | 33/80 [01:20<01:53,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.12, critic_loss=18.2]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-3.12, critic_loss=18.2]\n",
            "Episode [7/15]:  44%|████▍     | 35/80 [01:25<01:46,  2.38s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.11, critic_loss=20.2]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-3.11, critic_loss=20.2]\n",
            "Episode [7/15]:  46%|████▋     | 37/80 [01:30<01:44,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=1.98e+3, critic_loss=6.34e+7]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=1.98e+3, critic_loss=6.34e+7]\n",
            "Episode [7/15]:  49%|████▉     | 39/80 [01:35<01:41,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-1.79, critic_loss=38.8]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s, actor_loss=-1.79, critic_loss=38.8]\n",
            "Episode [7/15]:  51%|█████▏    | 41/80 [01:40<01:35,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.42, critic_loss=23.2]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-3.42, critic_loss=23.2]\n",
            "Episode [7/15]:  54%|█████▍    | 43/80 [01:45<01:30,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.66, critic_loss=22.9]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-3.66, critic_loss=22.9]\n",
            "Episode [7/15]:  56%|█████▋    | 45/80 [01:50<01:24,  2.40s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.66, critic_loss=22.3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-2.66, critic_loss=22.3]\n",
            "Episode [7/15]:  59%|█████▉    | 47/80 [01:55<01:20,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.91, critic_loss=33]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.21it/s, actor_loss=-2.91, critic_loss=33]\n",
            "Episode [7/15]:  61%|██████▏   | 49/80 [02:00<01:15,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.11, critic_loss=26.5]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-4.11, critic_loss=26.5]\n",
            "Episode [7/15]:  64%|██████▍   | 51/80 [02:05<01:11,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.714, critic_loss=81.2]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-.714, critic_loss=81.2]\n",
            "Episode [7/15]:  66%|██████▋   | 53/80 [02:10<01:05,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.62, critic_loss=23.5]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s, actor_loss=-3.62, critic_loss=23.5]\n",
            "Episode [7/15]:  69%|██████▉   | 55/80 [02:14<01:00,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.74, critic_loss=27.8]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-3.74, critic_loss=27.8]\n",
            "Episode [7/15]:  71%|███████▏  | 57/80 [02:19<00:56,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.63, critic_loss=31.1]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-4.63, critic_loss=31.1]\n",
            "Episode [7/15]:  74%|███████▍  | 59/80 [02:24<00:51,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=7.6, critic_loss=2.54e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=7.6, critic_loss=2.54e+3]\n",
            "Episode [7/15]:  76%|███████▋  | 61/80 [02:29<00:46,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.05, critic_loss=31.1]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-4.05, critic_loss=31.1]\n",
            "Episode [7/15]:  79%|███████▉  | 63/80 [02:34<00:41,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.08, critic_loss=32.2]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-4.08, critic_loss=32.2]\n",
            "Episode [7/15]:  81%|████████▏ | 65/80 [02:39<00:36,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.19, critic_loss=36.3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-4.19, critic_loss=36.3]\n",
            "Episode [7/15]:  84%|████████▍ | 67/80 [02:44<00:31,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=12.2, critic_loss=3.6e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s, actor_loss=12.2, critic_loss=3.6e+3]\n",
            "Episode [7/15]:  86%|████████▋ | 69/80 [02:49<00:27,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.45, critic_loss=37.3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-2.45, critic_loss=37.3]\n",
            "Episode [7/15]:  89%|████████▉ | 71/80 [02:54<00:22,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.34, critic_loss=29.4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-3.34, critic_loss=29.4]\n",
            "Episode [7/15]:  91%|█████████▏| 73/80 [02:59<00:17,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.97, critic_loss=32.5]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-3.97, critic_loss=32.5]\n",
            "Episode [7/15]:  94%|█████████▍| 75/80 [03:05<00:12,  2.59s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-5.07, critic_loss=36.9]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-5.07, critic_loss=36.9]\n",
            "Episode [7/15]:  96%|█████████▋| 77/80 [03:10<00:07,  2.58s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.218, critic_loss=223]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-.218, critic_loss=223]\n",
            "Episode [7/15]:  99%|█████████▉| 79/80 [03:15<00:02,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.16, critic_loss=55.1]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, actor_loss=-2.16, critic_loss=55.1]\n",
            "Episode [7/15]: 100%|██████████| 80/80 [03:18<00:00,  2.48s/it]\n",
            "Episode [8/15]:   1%|▏         | 1/80 [00:02<03:04,  2.33s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.84, critic_loss=36.6]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-4.84, critic_loss=36.6]\n",
            "Episode [8/15]:   4%|▍         | 3/80 [00:07<03:11,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-1.05, critic_loss=217]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-1.05, critic_loss=217]\n",
            "Episode [8/15]:   6%|▋         | 5/80 [00:12<03:04,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.82, critic_loss=37.6]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-4.82, critic_loss=37.6]\n",
            "Episode [8/15]:   9%|▉         | 7/80 [00:17<02:59,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=822, critic_loss=1.22e+7]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=822, critic_loss=1.22e+7]\n",
            "Episode [8/15]:  11%|█▏        | 9/80 [00:22<02:57,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.51, critic_loss=29]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-2.51, critic_loss=29]\n",
            "Episode [8/15]:  14%|█▍        | 11/80 [00:27<02:51,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.579, critic_loss=223]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.579, critic_loss=223]\n",
            "Episode [8/15]:  16%|█▋        | 13/80 [00:32<02:44,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-5, critic_loss=40.7]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-5, critic_loss=40.7]\n",
            "Episode [8/15]:  19%|█▉        | 15/80 [00:37<02:41,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.56, critic_loss=48.5]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-2.56, critic_loss=48.5]\n",
            "Episode [8/15]:  21%|██▏       | 17/80 [00:42<02:35,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.11, critic_loss=71.7]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-2.11, critic_loss=71.7]\n",
            "Episode [8/15]:  24%|██▍       | 19/80 [00:47<02:28,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-1.98, critic_loss=67.1]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-1.98, critic_loss=67.1]\n",
            "Episode [8/15]:  26%|██▋       | 21/80 [00:52<02:27,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.15, critic_loss=43.6]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-2.15, critic_loss=43.6]\n",
            "Episode [8/15]:  29%|██▉       | 23/80 [00:57<02:20,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=1.31, critic_loss=150]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=1.31, critic_loss=150]\n",
            "Episode [8/15]:  31%|███▏      | 25/80 [01:02<02:14,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-5.51, critic_loss=49.5]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-5.51, critic_loss=49.5]\n",
            "Episode [8/15]:  34%|███▍      | 27/80 [01:07<02:08,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.682, critic_loss=186]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=0.682, critic_loss=186]\n",
            "Episode [8/15]:  36%|███▋      | 29/80 [01:12<02:05,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=38.5, critic_loss=2.56e+4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=38.5, critic_loss=2.56e+4]\n",
            "Episode [8/15]:  39%|███▉      | 31/80 [01:17<01:58,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=13.3, critic_loss=1.87e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=13.3, critic_loss=1.87e+3]\n",
            "Episode [8/15]:  41%|████▏     | 33/80 [01:22<01:55,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.338, critic_loss=113]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.338, critic_loss=113]\n",
            "Episode [8/15]:  44%|████▍     | 35/80 [01:27<01:51,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.922, critic_loss=88]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=0.922, critic_loss=88]\n",
            "Episode [8/15]:  46%|████▋     | 37/80 [01:31<01:44,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=6.24, critic_loss=144]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=6.24, critic_loss=144]\n",
            "Episode [8/15]:  49%|████▉     | 39/80 [01:36<01:39,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=19.6, critic_loss=4.81e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=19.6, critic_loss=4.81e+3]\n",
            "Episode [8/15]:  51%|█████▏    | 41/80 [01:41<01:35,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.89, critic_loss=57.7]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-2.89, critic_loss=57.7]\n",
            "Episode [8/15]:  54%|█████▍    | 43/80 [01:46<01:31,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=47.5, critic_loss=2.44e+4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=47.5, critic_loss=2.44e+4]\n",
            "Episode [8/15]:  56%|█████▋    | 45/80 [01:51<01:26,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=2.18, critic_loss=587]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=2.18, critic_loss=587]\n",
            "Episode [8/15]:  59%|█████▉    | 47/80 [01:56<01:21,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.576, critic_loss=219]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=0.576, critic_loss=219]\n",
            "Episode [8/15]:  61%|██████▏   | 49/80 [02:01<01:16,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.1, critic_loss=101]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-2.1, critic_loss=101]\n",
            "Episode [8/15]:  64%|██████▍   | 51/80 [02:06<01:11,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=4.28, critic_loss=555]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=4.28, critic_loss=555]\n",
            "Episode [8/15]:  66%|██████▋   | 53/80 [02:11<01:06,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-5.34, critic_loss=36.9]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-5.34, critic_loss=36.9]\n",
            "Episode [8/15]:  69%|██████▉   | 55/80 [02:16<01:01,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=81.7, critic_loss=6.33e+4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=81.7, critic_loss=6.33e+4]\n",
            "Episode [8/15]:  71%|███████▏  | 57/80 [02:21<00:56,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=40.6, critic_loss=457]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=40.6, critic_loss=457]\n",
            "Episode [8/15]:  74%|███████▍  | 59/80 [02:26<00:50,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=62.9, critic_loss=6.43e+4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=62.9, critic_loss=6.43e+4]\n",
            "Episode [8/15]:  76%|███████▋  | 61/80 [02:31<00:46,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=303, critic_loss=1.76e+4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=303, critic_loss=1.76e+4]\n",
            "Episode [8/15]:  79%|███████▉  | 63/80 [02:36<00:41,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.31, critic_loss=44.8]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-4.31, critic_loss=44.8]\n",
            "Episode [8/15]:  81%|████████▏ | 65/80 [02:41<00:36,  2.40s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.87, critic_loss=85.7]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-3.87, critic_loss=85.7]\n",
            "Episode [8/15]:  84%|████████▍ | 67/80 [02:46<00:31,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.51, critic_loss=61.7]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, actor_loss=-2.51, critic_loss=61.7]\n",
            "Episode [8/15]:  86%|████████▋ | 69/80 [02:51<00:26,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.21, critic_loss=42.2]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-4.21, critic_loss=42.2]\n",
            "Episode [8/15]:  89%|████████▉ | 71/80 [02:56<00:22,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.855, critic_loss=749]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=0.855, critic_loss=749]\n",
            "Episode [8/15]:  91%|█████████▏| 73/80 [03:01<00:17,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-1.22, critic_loss=282]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-1.22, critic_loss=282]\n",
            "Episode [8/15]:  94%|█████████▍| 75/80 [03:06<00:12,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=1.56, critic_loss=748]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=1.56, critic_loss=748]\n",
            "Episode [8/15]:  96%|█████████▋| 77/80 [03:11<00:07,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.41, critic_loss=40.8]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-3.41, critic_loss=40.8]\n",
            "Episode [8/15]:  99%|█████████▉| 79/80 [03:16<00:02,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.31, critic_loss=51.2]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-2.31, critic_loss=51.2]\n",
            "Episode [8/15]: 100%|██████████| 80/80 [03:18<00:00,  2.49s/it]\n",
            "Episode [9/15]:   1%|▏         | 1/80 [00:02<03:02,  2.31s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=11.2, critic_loss=1.09e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=11.2, critic_loss=1.09e+3]\n",
            "Episode [9/15]:   4%|▍         | 3/80 [00:07<03:03,  2.39s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.04, critic_loss=47.3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-4.04, critic_loss=47.3]\n",
            "Episode [9/15]:   6%|▋         | 5/80 [00:12<03:03,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.359, critic_loss=500]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=0.359, critic_loss=500]\n",
            "Episode [9/15]:   9%|▉         | 7/80 [00:17<02:57,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=3.99, critic_loss=265]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=3.99, critic_loss=265]\n",
            "Episode [9/15]:  11%|█▏        | 9/80 [00:21<02:51,  2.41s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.951, critic_loss=87.3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.951, critic_loss=87.3]\n",
            "Episode [9/15]:  14%|█▍        | 11/80 [00:26<02:47,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=37.1, critic_loss=3.39e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=37.1, critic_loss=3.39e+3]\n",
            "Episode [9/15]:  16%|█▋        | 13/80 [00:31<02:44,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.09, critic_loss=61.9]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-3.09, critic_loss=61.9]\n",
            "Episode [9/15]:  19%|█▉        | 15/80 [00:36<02:37,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-1.1, critic_loss=115]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-1.1, critic_loss=115]\n",
            "Episode [9/15]:  21%|██▏       | 17/80 [00:41<02:33,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=5.26, critic_loss=585]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=5.26, critic_loss=585]\n",
            "Episode [9/15]:  24%|██▍       | 19/80 [00:46<02:29,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.82, critic_loss=70.3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-3.82, critic_loss=70.3]\n",
            "Episode [9/15]:  26%|██▋       | 21/80 [00:51<02:23,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.07, critic_loss=67.7]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-3.07, critic_loss=67.7]\n",
            "Episode [9/15]:  29%|██▉       | 23/80 [00:56<02:22,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=21.5, critic_loss=8.64e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=21.5, critic_loss=8.64e+3]\n",
            "Episode [9/15]:  31%|███▏      | 25/80 [01:01<02:17,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-5.77, critic_loss=60.5]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-5.77, critic_loss=60.5]\n",
            "Episode [9/15]:  34%|███▍      | 27/80 [01:06<02:10,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=7.45, critic_loss=1.51e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=7.45, critic_loss=1.51e+3]\n",
            "Episode [9/15]:  36%|███▋      | 29/80 [01:11<02:04,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-1.2, critic_loss=325]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-1.2, critic_loss=325]\n",
            "Episode [9/15]:  39%|███▉      | 31/80 [01:16<02:00,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.91, critic_loss=84.3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-2.91, critic_loss=84.3]\n",
            "Episode [9/15]:  41%|████▏     | 33/80 [01:21<01:55,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-1.72, critic_loss=105]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-1.72, critic_loss=105]\n",
            "Episode [9/15]:  44%|████▍     | 35/80 [01:26<01:51,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=9.42, critic_loss=1.27e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=9.42, critic_loss=1.27e+3]\n",
            "Episode [9/15]:  46%|████▋     | 37/80 [01:31<01:47,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.342, critic_loss=135]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.342, critic_loss=135]\n",
            "Episode [9/15]:  49%|████▉     | 39/80 [01:36<01:41,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.654, critic_loss=248]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.654, critic_loss=248]\n",
            "Episode [9/15]:  51%|█████▏    | 41/80 [01:41<01:36,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=179, critic_loss=2.57e+5]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=179, critic_loss=2.57e+5]\n",
            "Episode [9/15]:  54%|█████▍    | 43/80 [01:46<01:31,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=13.3, critic_loss=1.21e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=13.3, critic_loss=1.21e+3]\n",
            "Episode [9/15]:  56%|█████▋    | 45/80 [01:51<01:26,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=150, critic_loss=1.94e+5]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=150, critic_loss=1.94e+5]\n",
            "Episode [9/15]:  59%|█████▉    | 47/80 [01:56<01:21,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=27.4, critic_loss=1.65e+4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=27.4, critic_loss=1.65e+4]\n",
            "Episode [9/15]:  61%|██████▏   | 49/80 [02:01<01:15,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=20.6, critic_loss=1.3e+4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=20.6, critic_loss=1.3e+4]\n",
            "Episode [9/15]:  64%|██████▍   | 51/80 [02:06<01:11,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=77.2, critic_loss=5.32e+4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=77.2, critic_loss=5.32e+4]\n",
            "Episode [9/15]:  66%|██████▋   | 53/80 [02:11<01:05,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.169, critic_loss=148]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.169, critic_loss=148]\n",
            "Episode [9/15]:  69%|██████▉   | 55/80 [02:16<01:01,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.365, critic_loss=512]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=0.365, critic_loss=512]\n",
            "Episode [9/15]:  71%|███████▏  | 57/80 [02:21<00:56,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.368, critic_loss=283]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.368, critic_loss=283]\n",
            "Episode [9/15]:  74%|███████▍  | 59/80 [02:26<00:51,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=7.48, critic_loss=4.43e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=7.48, critic_loss=4.43e+3]\n",
            "Episode [9/15]:  76%|███████▋  | 61/80 [02:31<00:46,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=4.53, critic_loss=1.2e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=4.53, critic_loss=1.2e+3]\n",
            "Episode [9/15]:  79%|███████▉  | 63/80 [02:36<00:42,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=33.9, critic_loss=571]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=33.9, critic_loss=571]\n",
            "Episode [9/15]:  81%|████████▏ | 65/80 [02:41<00:37,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.965, critic_loss=419]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-.965, critic_loss=419]\n",
            "Episode [9/15]:  84%|████████▍ | 67/80 [02:45<00:31,  2.39s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.54, critic_loss=113]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-4.54, critic_loss=113]\n",
            "Episode [9/15]:  86%|████████▋ | 69/80 [02:51<00:26,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=11.5, critic_loss=2.1e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=11.5, critic_loss=2.1e+3]\n",
            "Episode [9/15]:  89%|████████▉ | 71/80 [02:55<00:21,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.01, critic_loss=67.2]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-6.01, critic_loss=67.2]\n",
            "Episode [9/15]:  91%|█████████▏| 73/80 [03:00<00:16,  2.41s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-5.34, critic_loss=62.2]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-5.34, critic_loss=62.2]\n",
            "Episode [9/15]:  94%|█████████▍| 75/80 [03:05<00:12,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.23, critic_loss=84.8]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.06it/s, actor_loss=-7.23, critic_loss=84.8]\n",
            "Episode [9/15]:  96%|█████████▋| 77/80 [03:11<00:07,  2.56s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.84, critic_loss=81]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-7.84, critic_loss=81]\n",
            "Episode [9/15]:  99%|█████████▉| 79/80 [03:16<00:02,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.49, critic_loss=72.6]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-6.49, critic_loss=72.6]\n",
            "Episode [9/15]: 100%|██████████| 80/80 [03:18<00:00,  2.49s/it]\n",
            "Episode [10/15]:   1%|▏         | 1/80 [00:02<03:07,  2.37s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.33, critic_loss=84.2]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-7.33, critic_loss=84.2]\n",
            "Episode [10/15]:   4%|▍         | 3/80 [00:07<03:10,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.86, critic_loss=76.9]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-6.86, critic_loss=76.9]\n",
            "Episode [10/15]:   6%|▋         | 5/80 [00:12<03:02,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-5.25, critic_loss=106]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-5.25, critic_loss=106]\n",
            "Episode [10/15]:   9%|▉         | 7/80 [00:17<02:52,  2.36s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.52, critic_loss=77.2]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-7.52, critic_loss=77.2]\n",
            "Episode [10/15]:  11%|█▏        | 9/80 [00:22<02:52,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=87.9, critic_loss=9.48e+4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=87.9, critic_loss=9.48e+4]\n",
            "Episode [10/15]:  14%|█▍        | 11/80 [00:27<02:48,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=2.06, critic_loss=569]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=2.06, critic_loss=569]\n",
            "Episode [10/15]:  16%|█▋        | 13/80 [00:32<02:44,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-5.85, critic_loss=112]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-5.85, critic_loss=112]\n",
            "Episode [10/15]:  19%|█▉        | 15/80 [00:36<02:38,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.55, critic_loss=88.3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-6.55, critic_loss=88.3]\n",
            "Episode [10/15]:  21%|██▏       | 17/80 [00:41<02:34,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.73, critic_loss=67.4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-6.73, critic_loss=67.4]\n",
            "Episode [10/15]:  24%|██▍       | 19/80 [00:46<02:28,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=212, critic_loss=3.79e+5]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=212, critic_loss=3.79e+5]\n",
            "Episode [10/15]:  26%|██▋       | 21/80 [00:51<02:23,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.61, critic_loss=77.7]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-6.61, critic_loss=77.7]\n",
            "Episode [10/15]:  29%|██▉       | 23/80 [00:56<02:19,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.82, critic_loss=90]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-7.82, critic_loss=90]\n",
            "Episode [10/15]:  31%|███▏      | 25/80 [01:01<02:15,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=4.86, critic_loss=679]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, actor_loss=4.86, critic_loss=679]\n",
            "Episode [10/15]:  34%|███▍      | 27/80 [01:06<02:11,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.71, critic_loss=81.2]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-6.71, critic_loss=81.2]\n",
            "Episode [10/15]:  36%|███▋      | 29/80 [01:11<02:03,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.62, critic_loss=79.3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-6.62, critic_loss=79.3]\n",
            "Episode [10/15]:  39%|███▉      | 31/80 [01:16<01:59,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-1.2, critic_loss=276]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s, actor_loss=-1.2, critic_loss=276]\n",
            "Episode [10/15]:  41%|████▏     | 33/80 [01:21<01:55,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.2, critic_loss=90.9]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-6.2, critic_loss=90.9]\n",
            "Episode [10/15]:  44%|████▍     | 35/80 [01:26<01:51,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.98, critic_loss=73.1]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-6.98, critic_loss=73.1]\n",
            "Episode [10/15]:  46%|████▋     | 37/80 [01:31<01:44,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.77, critic_loss=84.3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-7.77, critic_loss=84.3]\n",
            "Episode [10/15]:  49%|████▉     | 39/80 [01:36<01:40,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.99, critic_loss=92.1]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-7.99, critic_loss=92.1]\n",
            "Episode [10/15]:  51%|█████▏    | 41/80 [01:41<01:34,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.43, critic_loss=87.1]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-6.43, critic_loss=87.1]\n",
            "Episode [10/15]:  54%|█████▍    | 43/80 [01:45<01:26,  2.34s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.77, critic_loss=132]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-4.77, critic_loss=132]\n",
            "Episode [10/15]:  56%|█████▋    | 45/80 [01:50<01:23,  2.39s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.41, critic_loss=238]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-4.41, critic_loss=238]\n",
            "Episode [10/15]:  59%|█████▉    | 47/80 [01:55<01:20,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.28, critic_loss=149]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-3.28, critic_loss=149]\n",
            "Episode [10/15]:  61%|██████▏   | 49/80 [02:00<01:14,  2.41s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=41, critic_loss=6.04e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=41, critic_loss=6.04e+3]\n",
            "Episode [10/15]:  64%|██████▍   | 51/80 [02:05<01:10,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.24, critic_loss=89.5]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-6.24, critic_loss=89.5]\n",
            "Episode [10/15]:  66%|██████▋   | 53/80 [02:10<01:06,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.105, critic_loss=452]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=0.105, critic_loss=452]\n",
            "Episode [10/15]:  69%|██████▉   | 55/80 [02:15<01:01,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.34, critic_loss=84.3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.21it/s, actor_loss=-6.34, critic_loss=84.3]\n",
            "Episode [10/15]:  71%|███████▏  | 57/80 [02:20<00:56,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.48, critic_loss=75.7]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-6.48, critic_loss=75.7]\n",
            "Episode [10/15]:  74%|███████▍  | 59/80 [02:25<00:50,  2.40s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=718, critic_loss=1.17e+7]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=718, critic_loss=1.17e+7]\n",
            "Episode [10/15]:  76%|███████▋  | 61/80 [02:30<00:46,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.45, critic_loss=82.6]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-6.45, critic_loss=82.6]\n",
            "Episode [10/15]:  79%|███████▉  | 63/80 [02:35<00:41,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.27, critic_loss=124]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-4.27, critic_loss=124]\n",
            "Episode [10/15]:  81%|████████▏ | 65/80 [02:40<00:37,  2.52s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.41, critic_loss=230]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-2.41, critic_loss=230]\n",
            "Episode [10/15]:  84%|████████▍ | 67/80 [02:45<00:32,  2.53s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.84, critic_loss=79.1]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-6.84, critic_loss=79.1]\n",
            "Episode [10/15]:  86%|████████▋ | 69/80 [02:50<00:27,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.61, critic_loss=109]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-7.61, critic_loss=109]\n",
            "Episode [10/15]:  89%|████████▉ | 71/80 [02:55<00:22,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=13.3, critic_loss=6.52e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=13.3, critic_loss=6.52e+3]\n",
            "Episode [10/15]:  91%|█████████▏| 73/80 [03:00<00:17,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=54.8, critic_loss=9.19e+4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=54.8, critic_loss=9.19e+4]\n",
            "Episode [10/15]:  94%|█████████▍| 75/80 [03:05<00:12,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.86, critic_loss=114]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-7.86, critic_loss=114]\n",
            "Episode [10/15]:  96%|█████████▋| 77/80 [03:10<00:07,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.32, critic_loss=137]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s, actor_loss=-4.32, critic_loss=137]\n",
            "Episode [10/15]:  99%|█████████▉| 79/80 [03:15<00:02,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.81, critic_loss=172]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-3.81, critic_loss=172]\n",
            "Episode [10/15]: 100%|██████████| 80/80 [03:17<00:00,  2.47s/it]\n",
            "Episode [11/15]:   1%|▏         | 1/80 [00:02<03:02,  2.31s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-5.21, critic_loss=94.8]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-5.21, critic_loss=94.8]\n",
            "Episode [11/15]:   4%|▍         | 3/80 [00:07<03:07,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.14, critic_loss=101]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-7.14, critic_loss=101]\n",
            "Episode [11/15]:   6%|▋         | 5/80 [00:12<03:06,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.74, critic_loss=102]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-8.74, critic_loss=102]\n",
            "Episode [11/15]:   9%|▉         | 7/80 [00:17<02:59,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.86, critic_loss=112]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-8.86, critic_loss=112]\n",
            "Episode [11/15]:  11%|█▏        | 9/80 [00:22<02:55,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.52, critic_loss=119]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, actor_loss=-6.52, critic_loss=119]\n",
            "Episode [11/15]:  14%|█▍        | 11/80 [00:27<02:49,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.03, critic_loss=115]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-8.03, critic_loss=115]\n",
            "Episode [11/15]:  16%|█▋        | 13/80 [00:32<02:43,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.99, critic_loss=103]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-6.99, critic_loss=103]\n",
            "Episode [11/15]:  19%|█▉        | 15/80 [00:37<02:37,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.03, critic_loss=112]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-8.03, critic_loss=112]\n",
            "Episode [11/15]:  21%|██▏       | 17/80 [00:41<02:30,  2.39s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.16, critic_loss=366]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-3.16, critic_loss=366]\n",
            "Episode [11/15]:  24%|██▍       | 19/80 [00:46<02:29,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.91, critic_loss=114]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-8.91, critic_loss=114]\n",
            "Episode [11/15]:  26%|██▋       | 21/80 [00:51<02:23,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=4.71, critic_loss=960]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=4.71, critic_loss=960]\n",
            "Episode [11/15]:  29%|██▉       | 23/80 [00:56<02:18,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.43, critic_loss=94.9]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, actor_loss=-6.43, critic_loss=94.9]\n",
            "Episode [11/15]:  31%|███▏      | 25/80 [01:02<02:22,  2.59s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.08, critic_loss=107]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-7.08, critic_loss=107]\n",
            "Episode [11/15]:  34%|███▍      | 27/80 [01:07<02:14,  2.55s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=8.92, critic_loss=915]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=8.92, critic_loss=915]\n",
            "Episode [11/15]:  36%|███▋      | 29/80 [01:12<02:06,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.93, critic_loss=115]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-7.93, critic_loss=115]\n",
            "Episode [11/15]:  39%|███▉      | 31/80 [01:17<02:03,  2.51s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.06, critic_loss=114]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-8.06, critic_loss=114]\n",
            "Episode [11/15]:  41%|████▏     | 33/80 [01:22<01:58,  2.52s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.2, critic_loss=97.4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-7.2, critic_loss=97.4]\n",
            "Episode [11/15]:  44%|████▍     | 35/80 [01:27<01:50,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.08, critic_loss=101]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-7.08, critic_loss=101]\n",
            "Episode [11/15]:  46%|████▋     | 37/80 [01:32<01:45,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.25, critic_loss=106]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-8.25, critic_loss=106]\n",
            "Episode [11/15]:  49%|████▉     | 39/80 [01:37<01:40,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-5.67, critic_loss=221]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s, actor_loss=-5.67, critic_loss=221]\n",
            "Episode [11/15]:  51%|█████▏    | 41/80 [01:42<01:36,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.26, critic_loss=218]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-4.26, critic_loss=218]\n",
            "Episode [11/15]:  54%|█████▍    | 43/80 [01:47<01:31,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.94, critic_loss=106]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-7.94, critic_loss=106]\n",
            "Episode [11/15]:  56%|█████▋    | 45/80 [01:51<01:25,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=28.8, critic_loss=1.34e+4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=28.8, critic_loss=1.34e+4]\n",
            "Episode [11/15]:  59%|█████▉    | 47/80 [01:56<01:21,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=21.9, critic_loss=9.95e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=21.9, critic_loss=9.95e+3]\n",
            "Episode [11/15]:  61%|██████▏   | 49/80 [02:01<01:16,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.96, critic_loss=97.6]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-7.96, critic_loss=97.6]\n",
            "Episode [11/15]:  64%|██████▍   | 51/80 [02:07<01:12,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.46, critic_loss=110]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-7.46, critic_loss=110]\n",
            "Episode [11/15]:  66%|██████▋   | 53/80 [02:11<01:06,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.25, critic_loss=105]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-8.25, critic_loss=105]\n",
            "Episode [11/15]:  69%|██████▉   | 55/80 [02:17<01:02,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.57, critic_loss=91.7]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, actor_loss=-7.57, critic_loss=91.7]\n",
            "Episode [11/15]:  71%|███████▏  | 57/80 [02:22<00:57,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-9.09, critic_loss=109]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-9.09, critic_loss=109]\n",
            "Episode [11/15]:  74%|███████▍  | 59/80 [02:26<00:51,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.77, critic_loss=142]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s, actor_loss=-6.77, critic_loss=142]\n",
            "Episode [11/15]:  76%|███████▋  | 61/80 [02:31<00:46,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.24, critic_loss=99.9]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-7.24, critic_loss=99.9]\n",
            "Episode [11/15]:  79%|███████▉  | 63/80 [02:36<00:41,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.33, critic_loss=118]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-8.33, critic_loss=118]\n",
            "Episode [11/15]:  81%|████████▏ | 65/80 [02:41<00:36,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-9.14, critic_loss=116]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-9.14, critic_loss=116]\n",
            "Episode [11/15]:  84%|████████▍ | 67/80 [02:46<00:31,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.76, critic_loss=101]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-8.76, critic_loss=101]\n",
            "Episode [11/15]:  86%|████████▋ | 69/80 [02:51<00:27,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-5.01, critic_loss=154]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-5.01, critic_loss=154]\n",
            "Episode [11/15]:  89%|████████▉ | 71/80 [02:56<00:21,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.85, critic_loss=118]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-7.85, critic_loss=118]\n",
            "Episode [11/15]:  91%|█████████▏| 73/80 [03:01<00:17,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.02, critic_loss=92.1]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-6.02, critic_loss=92.1]\n",
            "Episode [11/15]:  94%|█████████▍| 75/80 [03:06<00:12,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.44, critic_loss=106]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-6.44, critic_loss=106]\n",
            "Episode [11/15]:  96%|█████████▋| 77/80 [03:11<00:07,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=2.29e+3, critic_loss=6.47e+7]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=2.29e+3, critic_loss=6.47e+7]\n",
            "Episode [11/15]:  99%|█████████▉| 79/80 [03:16<00:02,  2.52s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.79, critic_loss=122]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-8.79, critic_loss=122]\n",
            "Episode [11/15]: 100%|██████████| 80/80 [03:19<00:00,  2.49s/it]\n",
            "Episode [12/15]:   1%|▏         | 1/80 [00:02<03:11,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.98, critic_loss=110]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-6.98, critic_loss=110]\n",
            "Episode [12/15]:   4%|▍         | 3/80 [00:07<03:07,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.18, critic_loss=129]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-6.18, critic_loss=129]\n",
            "Episode [12/15]:   6%|▋         | 5/80 [00:12<03:00,  2.41s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.34, critic_loss=115]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-8.34, critic_loss=115]\n",
            "Episode [12/15]:   9%|▉         | 7/80 [00:16<02:54,  2.39s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.37, critic_loss=123]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-8.37, critic_loss=123]\n",
            "Episode [12/15]:  11%|█▏        | 9/80 [00:22<02:52,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.77, critic_loss=194]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-7.77, critic_loss=194]\n",
            "Episode [12/15]:  14%|█▍        | 11/80 [00:26<02:46,  2.41s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-9.23, critic_loss=128]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-9.23, critic_loss=128]\n",
            "Episode [12/15]:  16%|█▋        | 13/80 [00:31<02:43,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-9.77, critic_loss=127]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-9.77, critic_loss=127]\n",
            "Episode [12/15]:  19%|█▉        | 15/80 [00:36<02:39,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.92, critic_loss=132]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, actor_loss=-8.92, critic_loss=132]\n",
            "Episode [12/15]:  21%|██▏       | 17/80 [00:41<02:35,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.7, critic_loss=109]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-7.7, critic_loss=109]\n",
            "Episode [12/15]:  24%|██▍       | 19/80 [00:46<02:27,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.43, critic_loss=119]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-7.43, critic_loss=119]\n",
            "Episode [12/15]:  26%|██▋       | 21/80 [00:51<02:26,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.23, critic_loss=156]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-8.23, critic_loss=156]\n",
            "Episode [12/15]:  29%|██▉       | 23/80 [00:56<02:20,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.88, critic_loss=136]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-7.88, critic_loss=136]\n",
            "Episode [12/15]:  31%|███▏      | 25/80 [01:01<02:13,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.04, critic_loss=287]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s, actor_loss=-3.04, critic_loss=287]\n",
            "Episode [12/15]:  34%|███▍      | 27/80 [01:06<02:11,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.28, critic_loss=284]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-4.28, critic_loss=284]\n",
            "Episode [12/15]:  36%|███▋      | 29/80 [01:11<02:03,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.24, critic_loss=146]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s, actor_loss=-7.24, critic_loss=146]\n",
            "Episode [12/15]:  39%|███▉      | 31/80 [01:16<01:59,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.442, critic_loss=123]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-.442, critic_loss=123]\n",
            "Episode [12/15]:  41%|████▏     | 33/80 [01:21<01:55,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=85.2, critic_loss=1.75e+5]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=85.2, critic_loss=1.75e+5]\n",
            "Episode [12/15]:  44%|████▍     | 35/80 [01:26<01:48,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.23, critic_loss=432]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-3.23, critic_loss=432]\n",
            "Episode [12/15]:  46%|████▋     | 37/80 [01:31<01:43,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.7, critic_loss=102]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-7.7, critic_loss=102]\n",
            "Episode [12/15]:  49%|████▉     | 39/80 [01:36<01:39,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=165, critic_loss=7.05e+5]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=165, critic_loss=7.05e+5]\n",
            "Episode [12/15]:  51%|█████▏    | 41/80 [01:41<01:36,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.99, critic_loss=133]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-8.99, critic_loss=133]\n",
            "Episode [12/15]:  54%|█████▍    | 43/80 [01:46<01:31,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-9.69, critic_loss=131]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-9.69, critic_loss=131]\n",
            "Episode [12/15]:  56%|█████▋    | 45/80 [01:51<01:27,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=11.4, critic_loss=814]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=11.4, critic_loss=814]\n",
            "Episode [12/15]:  59%|█████▉    | 47/80 [01:56<01:23,  2.52s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.44, critic_loss=118]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-8.44, critic_loss=118]\n",
            "Episode [12/15]:  61%|██████▏   | 49/80 [02:01<01:16,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.62, critic_loss=144]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-8.62, critic_loss=144]\n",
            "Episode [12/15]:  64%|██████▍   | 51/80 [02:06<01:10,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.68, critic_loss=130]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-7.68, critic_loss=130]\n",
            "Episode [12/15]:  66%|██████▋   | 53/80 [02:11<01:11,  2.65s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-9.51, critic_loss=135]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-9.51, critic_loss=135]\n",
            "Episode [12/15]:  69%|██████▉   | 55/80 [02:16<01:03,  2.54s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-10.6, critic_loss=149]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-10.6, critic_loss=149]\n",
            "Episode [12/15]:  71%|███████▏  | 57/80 [02:21<00:57,  2.51s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.68, critic_loss=115]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-8.68, critic_loss=115]\n",
            "Episode [12/15]:  74%|███████▍  | 59/80 [02:27<00:53,  2.53s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.47, critic_loss=977]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-2.47, critic_loss=977]\n",
            "Episode [12/15]:  76%|███████▋  | 61/80 [02:31<00:47,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.27, critic_loss=416]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s, actor_loss=-3.27, critic_loss=416]\n",
            "Episode [12/15]:  79%|███████▉  | 63/80 [02:36<00:41,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.45, critic_loss=152]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-7.45, critic_loss=152]\n",
            "Episode [12/15]:  81%|████████▏ | 65/80 [02:41<00:37,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-9.46, critic_loss=154]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-9.46, critic_loss=154]\n",
            "Episode [12/15]:  84%|████████▍ | 67/80 [02:46<00:31,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=3.45, critic_loss=1.03e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=3.45, critic_loss=1.03e+3]\n",
            "Episode [12/15]:  86%|████████▋ | 69/80 [02:51<00:26,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-9.14, critic_loss=163]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-9.14, critic_loss=163]\n",
            "Episode [12/15]:  89%|████████▉ | 71/80 [02:56<00:21,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-5.11, critic_loss=220]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-5.11, critic_loss=220]\n",
            "Episode [12/15]:  91%|█████████▏| 73/80 [03:01<00:17,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=14.1, critic_loss=3.81e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=14.1, critic_loss=3.81e+3]\n",
            "Episode [12/15]:  94%|█████████▍| 75/80 [03:06<00:12,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=8.35, critic_loss=6.75e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=8.35, critic_loss=6.75e+3]\n",
            "Episode [12/15]:  96%|█████████▋| 77/80 [03:11<00:07,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=8.72, critic_loss=555]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=8.72, critic_loss=555]\n",
            "Episode [12/15]:  99%|█████████▉| 79/80 [03:16<00:02,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.56, critic_loss=133]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-6.56, critic_loss=133]\n",
            "Episode [12/15]: 100%|██████████| 80/80 [03:19<00:00,  2.49s/it]\n",
            "Episode [13/15]:   1%|▏         | 1/80 [00:02<03:07,  2.37s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-11.3, critic_loss=165]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-11.3, critic_loss=165]\n",
            "Episode [13/15]:   4%|▍         | 3/80 [00:07<03:09,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.848, critic_loss=368]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-.848, critic_loss=368]\n",
            "Episode [13/15]:   6%|▋         | 5/80 [00:12<03:04,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.24, critic_loss=160]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-6.24, critic_loss=160]\n",
            "Episode [13/15]:   9%|▉         | 7/80 [00:17<02:55,  2.40s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=17, critic_loss=5.36e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=17, critic_loss=5.36e+3]\n",
            "Episode [13/15]:  11%|█▏        | 9/80 [00:22<02:51,  2.41s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=1.87, critic_loss=1.52e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=1.87, critic_loss=1.52e+3]\n",
            "Episode [13/15]:  14%|█▍        | 11/80 [00:26<02:45,  2.40s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.45, critic_loss=285]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-6.45, critic_loss=285]\n",
            "Episode [13/15]:  16%|█▋        | 13/80 [00:31<02:41,  2.41s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-9.68, critic_loss=167]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-9.68, critic_loss=167]\n",
            "Episode [13/15]:  19%|█▉        | 15/80 [00:36<02:38,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-5.7, critic_loss=181]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-5.7, critic_loss=181]\n",
            "Episode [13/15]:  21%|██▏       | 17/80 [00:41<02:33,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.416, critic_loss=731]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=0.416, critic_loss=731]\n",
            "Episode [13/15]:  24%|██▍       | 19/80 [00:46<02:28,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-10.8, critic_loss=152]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-10.8, critic_loss=152]\n",
            "Episode [13/15]:  26%|██▋       | 21/80 [00:51<02:23,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-9.87, critic_loss=152]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, actor_loss=-9.87, critic_loss=152]\n",
            "Episode [13/15]:  29%|██▉       | 23/80 [00:56<02:22,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-5.2, critic_loss=280]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-5.2, critic_loss=280]\n",
            "Episode [13/15]:  31%|███▏      | 25/80 [01:01<02:16,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-5.37, critic_loss=159]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-5.37, critic_loss=159]\n",
            "Episode [13/15]:  34%|███▍      | 27/80 [01:06<02:12,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-9.7, critic_loss=122]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-9.7, critic_loss=122]\n",
            "Episode [13/15]:  36%|███▋      | 29/80 [01:11<02:08,  2.53s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=1.16, critic_loss=730]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=1.16, critic_loss=730]\n",
            "Episode [13/15]:  39%|███▉      | 31/80 [01:16<02:01,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.11, critic_loss=134]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-7.11, critic_loss=134]\n",
            "Episode [13/15]:  41%|████▏     | 33/80 [01:21<01:53,  2.41s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.78, critic_loss=104]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, actor_loss=-7.78, critic_loss=104]\n",
            "Episode [13/15]:  44%|████▍     | 35/80 [01:26<01:51,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=107, critic_loss=1.58e+5]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=107, critic_loss=1.58e+5]\n",
            "Episode [13/15]:  46%|████▋     | 37/80 [01:31<01:44,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=39.9, critic_loss=1.01e+4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=39.9, critic_loss=1.01e+4]\n",
            "Episode [13/15]:  49%|████▉     | 39/80 [01:36<01:38,  2.40s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.26, critic_loss=246]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-4.26, critic_loss=246]\n",
            "Episode [13/15]:  51%|█████▏    | 41/80 [01:41<01:36,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-11.5, critic_loss=160]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-11.5, critic_loss=160]\n",
            "Episode [13/15]:  54%|█████▍    | 43/80 [01:46<01:29,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=5.6, critic_loss=605]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=5.6, critic_loss=605]\n",
            "Episode [13/15]:  56%|█████▋    | 45/80 [01:51<01:24,  2.41s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.932, critic_loss=222]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, actor_loss=-.932, critic_loss=222]\n",
            "Episode [13/15]:  59%|█████▉    | 47/80 [01:56<01:21,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-9.55, critic_loss=148]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-9.55, critic_loss=148]\n",
            "Episode [13/15]:  61%|██████▏   | 49/80 [02:01<01:15,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.199, critic_loss=882]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=0.199, critic_loss=882]\n",
            "Episode [13/15]:  64%|██████▍   | 51/80 [02:06<01:09,  2.41s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.79, critic_loss=152]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-7.79, critic_loss=152]\n",
            "Episode [13/15]:  66%|██████▋   | 53/80 [02:11<01:06,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.76, critic_loss=180]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-6.76, critic_loss=180]\n",
            "Episode [13/15]:  69%|██████▉   | 55/80 [02:16<01:01,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-9.35, critic_loss=149]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-9.35, critic_loss=149]\n",
            "Episode [13/15]:  71%|███████▏  | 57/80 [02:20<00:55,  2.41s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-10.6, critic_loss=154]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-10.6, critic_loss=154]\n",
            "Episode [13/15]:  74%|███████▍  | 59/80 [02:26<00:51,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.43, critic_loss=111]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-7.43, critic_loss=111]\n",
            "Episode [13/15]:  76%|███████▋  | 61/80 [02:31<00:46,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.4, critic_loss=166]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-8.4, critic_loss=166]\n",
            "Episode [13/15]:  79%|███████▉  | 63/80 [02:36<00:41,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.05, critic_loss=223]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-2.05, critic_loss=223]\n",
            "Episode [13/15]:  81%|████████▏ | 65/80 [02:41<00:37,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-9.7, critic_loss=146]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-9.7, critic_loss=146]\n",
            "Episode [13/15]:  84%|████████▍ | 67/80 [02:45<00:31,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=45.8, critic_loss=9.16e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=45.8, critic_loss=9.16e+3]\n",
            "Episode [13/15]:  86%|████████▋ | 69/80 [02:50<00:26,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.65, critic_loss=156]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s, actor_loss=-8.65, critic_loss=156]\n",
            "Episode [13/15]:  89%|████████▉ | 71/80 [02:55<00:21,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.866, critic_loss=418]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-.866, critic_loss=418]\n",
            "Episode [13/15]:  91%|█████████▏| 73/80 [03:00<00:17,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.32, critic_loss=128]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-8.32, critic_loss=128]\n",
            "Episode [13/15]:  94%|█████████▍| 75/80 [03:05<00:12,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.73, critic_loss=147]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-8.73, critic_loss=147]\n",
            "Episode [13/15]:  96%|█████████▋| 77/80 [03:10<00:07,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.4, critic_loss=191]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s, actor_loss=-7.4, critic_loss=191]\n",
            "Episode [13/15]:  99%|█████████▉| 79/80 [03:15<00:02,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=170, critic_loss=5.7e+5]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s, actor_loss=170, critic_loss=5.7e+5]\n",
            "Episode [13/15]: 100%|██████████| 80/80 [03:18<00:00,  2.48s/it]\n",
            "Episode [14/15]:   1%|▏         | 1/80 [00:02<03:10,  2.41s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=23.8, critic_loss=1.34e+4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=23.8, critic_loss=1.34e+4]\n",
            "Episode [14/15]:   4%|▍         | 3/80 [00:07<03:11,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.05, critic_loss=125]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-8.05, critic_loss=125]\n",
            "Episode [14/15]:   6%|▋         | 5/80 [00:12<03:07,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-9.21, critic_loss=137]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-9.21, critic_loss=137]\n",
            "Episode [14/15]:   9%|▉         | 7/80 [00:17<03:00,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-5.18, critic_loss=265]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-5.18, critic_loss=265]\n",
            "Episode [14/15]:  11%|█▏        | 9/80 [00:22<02:54,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8, critic_loss=128]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-8, critic_loss=128]\n",
            "Episode [14/15]:  14%|█▍        | 11/80 [00:27<02:52,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.79, critic_loss=312]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-8.79, critic_loss=312]\n",
            "Episode [14/15]:  16%|█▋        | 13/80 [00:32<02:42,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.14, critic_loss=555]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-3.14, critic_loss=555]\n",
            "Episode [14/15]:  19%|█▉        | 15/80 [00:37<02:38,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.95, critic_loss=153]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, actor_loss=-6.95, critic_loss=153]\n",
            "Episode [14/15]:  21%|██▏       | 17/80 [00:42<02:37,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.47, critic_loss=375]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-3.47, critic_loss=375]\n",
            "Episode [14/15]:  24%|██▍       | 19/80 [00:47<02:29,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=79.6, critic_loss=1.59e+5]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, actor_loss=79.6, critic_loss=1.59e+5]\n",
            "Episode [14/15]:  26%|██▋       | 21/80 [00:52<02:26,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-11.7, critic_loss=174]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-11.7, critic_loss=174]\n",
            "Episode [14/15]:  29%|██▉       | 23/80 [00:57<02:22,  2.51s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.11, critic_loss=520]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-6.11, critic_loss=520]\n",
            "Episode [14/15]:  31%|███▏      | 25/80 [01:02<02:15,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-9.39, critic_loss=137]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-9.39, critic_loss=137]\n",
            "Episode [14/15]:  34%|███▍      | 27/80 [01:07<02:10,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=5.69, critic_loss=5.23e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, actor_loss=5.69, critic_loss=5.23e+3]\n",
            "Episode [14/15]:  36%|███▋      | 29/80 [01:12<02:05,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.89, critic_loss=309]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-4.89, critic_loss=309]\n",
            "Episode [14/15]:  39%|███▉      | 31/80 [01:17<02:00,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-1.2, critic_loss=309]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-1.2, critic_loss=309]\n",
            "Episode [14/15]:  41%|████▏     | 33/80 [01:22<01:54,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-5.6, critic_loss=189]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-5.6, critic_loss=189]\n",
            "Episode [14/15]:  44%|████▍     | 35/80 [01:27<01:52,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.95, critic_loss=147]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-7.95, critic_loss=147]\n",
            "Episode [14/15]:  46%|████▋     | 37/80 [01:32<01:46,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.282, critic_loss=1.4e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=0.282, critic_loss=1.4e+3]\n",
            "Episode [14/15]:  49%|████▉     | 39/80 [01:37<01:40,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-12.2, critic_loss=185]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-12.2, critic_loss=185]\n",
            "Episode [14/15]:  51%|█████▏    | 41/80 [01:42<01:37,  2.51s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.92, critic_loss=160]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-6.92, critic_loss=160]\n",
            "Episode [14/15]:  54%|█████▍    | 43/80 [01:47<01:31,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.15, critic_loss=1.74e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=0.15, critic_loss=1.74e+3]\n",
            "Episode [14/15]:  56%|█████▋    | 45/80 [01:52<01:26,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-5.75, critic_loss=222]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-5.75, critic_loss=222]\n",
            "Episode [14/15]:  59%|█████▉    | 47/80 [01:57<01:22,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.12, critic_loss=148]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-8.12, critic_loss=148]\n",
            "Episode [14/15]:  61%|██████▏   | 49/80 [02:02<01:16,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.76, critic_loss=145]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-8.76, critic_loss=145]\n",
            "Episode [14/15]:  64%|██████▍   | 51/80 [02:07<01:11,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-11.4, critic_loss=166]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-11.4, critic_loss=166]\n",
            "Episode [14/15]:  66%|██████▋   | 53/80 [02:12<01:06,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.58, critic_loss=314]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-2.58, critic_loss=314]\n",
            "Episode [14/15]:  69%|██████▉   | 55/80 [02:17<01:01,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-9.23, critic_loss=138]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-9.23, critic_loss=138]\n",
            "Episode [14/15]:  71%|███████▏  | 57/80 [02:22<00:56,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-9.92, critic_loss=202]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-9.92, critic_loss=202]\n",
            "Episode [14/15]:  74%|███████▍  | 59/80 [02:27<00:51,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-5.96, critic_loss=200]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-5.96, critic_loss=200]\n",
            "Episode [14/15]:  76%|███████▋  | 61/80 [02:32<00:46,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.57, critic_loss=594]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-4.57, critic_loss=594]\n",
            "Episode [14/15]:  79%|███████▉  | 63/80 [02:36<00:40,  2.39s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.5, critic_loss=606]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-4.5, critic_loss=606]\n",
            "Episode [14/15]:  81%|████████▏ | 65/80 [02:41<00:35,  2.39s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=3.62, critic_loss=1.83e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=3.62, critic_loss=1.83e+3]\n",
            "Episode [14/15]:  84%|████████▍ | 67/80 [02:46<00:32,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=10.1, critic_loss=136]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=10.1, critic_loss=136]\n",
            "Episode [14/15]:  86%|████████▋ | 69/80 [02:51<00:27,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.89, critic_loss=370]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-7.89, critic_loss=370]\n",
            "Episode [14/15]:  89%|████████▉ | 71/80 [02:56<00:22,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.2, critic_loss=657]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-6.2, critic_loss=657]\n",
            "Episode [14/15]:  91%|█████████▏| 73/80 [03:01<00:17,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-11.3, critic_loss=163]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.20it/s, actor_loss=-11.3, critic_loss=163]\n",
            "Episode [14/15]:  94%|█████████▍| 75/80 [03:06<00:12,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=36.2, critic_loss=1.77e+4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=36.2, critic_loss=1.77e+4]\n",
            "Episode [14/15]:  96%|█████████▋| 77/80 [03:11<00:07,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-3.9, critic_loss=440]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-3.9, critic_loss=440]\n",
            "Episode [14/15]:  99%|█████████▉| 79/80 [03:16<00:02,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-10.2, critic_loss=138]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-10.2, critic_loss=138]\n",
            "Episode [14/15]: 100%|██████████| 80/80 [03:19<00:00,  2.49s/it]\n",
            "Episode [15/15]:   1%|▏         | 1/80 [00:02<03:00,  2.29s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=2.92, critic_loss=394]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=2.92, critic_loss=394]\n",
            "Episode [15/15]:   4%|▍         | 3/80 [00:07<03:07,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.91, critic_loss=235]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, actor_loss=-6.91, critic_loss=235]\n",
            "Episode [15/15]:   6%|▋         | 5/80 [00:12<03:05,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=12.2, critic_loss=1.11e+4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=12.2, critic_loss=1.11e+4]\n",
            "Episode [15/15]:   9%|▉         | 7/80 [00:17<02:58,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.25, critic_loss=162]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-8.25, critic_loss=162]\n",
            "Episode [15/15]:  11%|█▏        | 9/80 [00:22<02:52,  2.42s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.26, critic_loss=245]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s, actor_loss=-4.26, critic_loss=245]\n",
            "Episode [15/15]:  14%|█▍        | 11/80 [00:27<02:51,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-7.23, critic_loss=384]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-7.23, critic_loss=384]\n",
            "Episode [15/15]:  16%|█▋        | 13/80 [00:32<02:44,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.18, critic_loss=251]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-6.18, critic_loss=251]\n",
            "Episode [15/15]:  19%|█▉        | 15/80 [00:37<02:40,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-11.4, critic_loss=173]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.10it/s, actor_loss=-11.4, critic_loss=173]\n",
            "Episode [15/15]:  21%|██▏       | 17/80 [00:42<02:36,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=17.9, critic_loss=5.55e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=17.9, critic_loss=5.55e+3]\n",
            "Episode [15/15]:  24%|██▍       | 19/80 [00:47<02:29,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-11.8, critic_loss=166]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-11.8, critic_loss=166]\n",
            "Episode [15/15]:  26%|██▋       | 21/80 [00:52<02:24,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-11.7, critic_loss=186]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-11.7, critic_loss=186]\n",
            "Episode [15/15]:  29%|██▉       | 23/80 [00:57<02:21,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.45, critic_loss=1.29e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-4.45, critic_loss=1.29e+3]\n",
            "Episode [15/15]:  31%|███▏      | 25/80 [01:02<02:15,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=19, critic_loss=7.62e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=19, critic_loss=7.62e+3]\n",
            "Episode [15/15]:  34%|███▍      | 27/80 [01:07<02:10,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.63, critic_loss=213]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-6.63, critic_loss=213]\n",
            "Episode [15/15]:  36%|███▋      | 29/80 [01:12<02:07,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=11.8, critic_loss=692]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=11.8, critic_loss=692]\n",
            "Episode [15/15]:  39%|███▉      | 31/80 [01:17<02:03,  2.51s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.444, critic_loss=1.56e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-.444, critic_loss=1.56e+3]\n",
            "Episode [15/15]:  41%|████▏     | 33/80 [01:22<01:55,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=7.64, critic_loss=2.57e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=7.64, critic_loss=2.57e+3]\n",
            "Episode [15/15]:  44%|████▍     | 35/80 [01:27<01:52,  2.50s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.563, critic_loss=542]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=0.563, critic_loss=542]\n",
            "Episode [15/15]:  46%|████▋     | 37/80 [01:32<01:46,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.07, critic_loss=144]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-8.07, critic_loss=144]\n",
            "Episode [15/15]:  49%|████▉     | 39/80 [01:37<01:41,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.99, critic_loss=255]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.12it/s, actor_loss=-6.99, critic_loss=255]\n",
            "Episode [15/15]:  51%|█████▏    | 41/80 [01:42<01:37,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-9.82, critic_loss=146]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.09it/s, actor_loss=-9.82, critic_loss=146]\n",
            "Episode [15/15]:  54%|█████▍    | 43/80 [01:47<01:32,  2.49s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.73, critic_loss=188]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-6.73, critic_loss=188]\n",
            "Episode [15/15]:  56%|█████▋    | 45/80 [01:52<01:26,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-10, critic_loss=142]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-10, critic_loss=142]\n",
            "Episode [15/15]:  59%|█████▉    | 47/80 [01:57<01:21,  2.47s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=3.76, critic_loss=1.67e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=3.76, critic_loss=1.67e+3]\n",
            "Episode [15/15]:  61%|██████▏   | 49/80 [02:02<01:16,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-6.19, critic_loss=424]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.13it/s, actor_loss=-6.19, critic_loss=424]\n",
            "Episode [15/15]:  64%|██████▍   | 51/80 [02:07<01:10,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-9.01, critic_loss=199]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-9.01, critic_loss=199]\n",
            "Episode [15/15]:  66%|██████▋   | 53/80 [02:12<01:06,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-2.25, critic_loss=1.34e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s, actor_loss=-2.25, critic_loss=1.34e+3]\n",
            "Episode [15/15]:  69%|██████▉   | 55/80 [02:17<01:01,  2.48s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.56, critic_loss=233]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-8.56, critic_loss=233]\n",
            "Episode [15/15]:  71%|███████▏  | 57/80 [02:22<00:56,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=14.7, critic_loss=421]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=14.7, critic_loss=421]\n",
            "Episode [15/15]:  74%|███████▍  | 59/80 [02:27<00:51,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-.595, critic_loss=341]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-.595, critic_loss=341]\n",
            "Episode [15/15]:  76%|███████▋  | 61/80 [02:31<00:45,  2.41s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-5.82, critic_loss=161]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.17it/s, actor_loss=-5.82, critic_loss=161]\n",
            "Episode [15/15]:  79%|███████▉  | 63/80 [02:36<00:41,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=0.0173, critic_loss=1.72e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=0.0173, critic_loss=1.72e+3]\n",
            "Episode [15/15]:  81%|████████▏ | 65/80 [02:41<00:36,  2.46s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-11.9, critic_loss=180]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, actor_loss=-11.9, critic_loss=180]\n",
            "Episode [15/15]:  84%|████████▍ | 67/80 [02:46<00:31,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-4.16, critic_loss=474]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-4.16, critic_loss=474]\n",
            "Episode [15/15]:  86%|████████▋ | 69/80 [02:51<00:26,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=7.3, critic_loss=1.51e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, actor_loss=7.3, critic_loss=1.51e+3]\n",
            "Episode [15/15]:  89%|████████▉ | 71/80 [02:56<00:21,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-11.3, critic_loss=171]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-11.3, critic_loss=171]\n",
            "Episode [15/15]:  91%|█████████▏| 73/80 [03:01<00:17,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=22.7, critic_loss=1.23e+4]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=22.7, critic_loss=1.23e+4]\n",
            "Episode [15/15]:  94%|█████████▍| 75/80 [03:06<00:12,  2.44s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=4.31, critic_loss=2.94e+3]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=4.31, critic_loss=2.94e+3]\n",
            "Episode [15/15]:  96%|█████████▋| 77/80 [03:11<00:07,  2.45s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-8.15, critic_loss=198]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, actor_loss=-8.15, critic_loss=198]\n",
            "Episode [15/15]:  99%|█████████▉| 79/80 [03:16<00:02,  2.43s/it]\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Train epoch [1/1]:   0%|          | 0/1 [00:00<?, ?it/s, actor_loss=-9.2, critic_loss=328]\u001b[A\n",
            "Train epoch [1/1]: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s, actor_loss=-9.2, critic_loss=328]\n",
            "Episode [15/15]: 100%|██████████| 80/80 [03:19<00:00,  2.49s/it]\n"
          ]
        }
      ],
      "source": [
        "# configure trainer\n",
        "trainer = PPOTrainer(strategy,\n",
        "                     actor,\n",
        "                     critic,\n",
        "                     reward_model,\n",
        "                     initial_model,\n",
        "                     actor_optim,\n",
        "                     critic_optim,\n",
        "                     max_epochs=args.max_epochs,\n",
        "                     train_batch_size=args.train_batch_size,\n",
        "                     tokenizer=tokenize_fn,\n",
        "                     max_length=128,\n",
        "                     do_sample=True,\n",
        "                     temperature=1.0,\n",
        "                     top_k=50,\n",
        "                     pad_token_id=tokenizer.pad_token_id,\n",
        "                     eos_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "## train!\n",
        "trainer.fit(list_prompt,  # 입력 prompt\n",
        "            num_episodes=args.num_episodes,\n",
        "            max_timesteps=args.max_timesteps,\n",
        "            update_timesteps=args.update_timesteps)\n",
        "\n",
        "## save\n",
        "# save model checkpoint after fitting on only rank0\n",
        "strategy.save_model(actor, os.path.join(args.output_dir, 'actor.pt'), only_rank0=True)\n",
        "# save optimizer checkpoint on all ranks\n",
        "strategy.save_optimizer(actor_optim,\n",
        "                        os.path.join(args.output_dir, 'actor_optim_checkpoint_%d.pt' % (torch.cuda.current_device())),\n",
        "                        only_rank0=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 추론"
      ],
      "metadata": {
        "id": "51F0fXFgY4Di"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjmSYfy2xBi5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "ea08e6e3-e4dc-4afd-8722-cb53c0350c2f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6c42318838f0>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_text\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_prompt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-6c42318838f0>\u001b[0m in \u001b[0;36mgeneration\u001b[0;34m(input_text)\u001b[0m\n\u001b[1;32m      4\u001b[0m         torch.cuda.current_device())\n\u001b[1;32m      5\u001b[0m     outputs = actor.generate(input_ids,\n\u001b[0;32m----> 6\u001b[0;31m                              \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                              \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                              \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
          ]
        }
      ],
      "source": [
        "## inference\n",
        "def generation(input_text):\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
        "        torch.cuda.current_device())\n",
        "    outputs = actor.generate(input_ids,\n",
        "                             max_length=args.max_length,\n",
        "                             do_sample=True,\n",
        "                             top_k=50,\n",
        "                             top_p=0.95,\n",
        "                             num_return_sequences=1)\n",
        "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
        "    print('#' * 70)\n",
        "    print(output)\n",
        "    return output\n",
        "\n",
        "\n",
        "list_prompt = PROMPT_LIST\n",
        "\n",
        "list_prompt = [PROMPT_DICT['prompt_no_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
        "\n",
        "for input_text in list_prompt:\n",
        "    output = generation(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NY84CFCvA6N-"
      },
      "outputs": [],
      "source": [
        "raise Exception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvp1QP0VA582"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihMgjx60hCHM"
      },
      "source": [
        "# PPO까지 모두 완료된 모델로 추론하기\n",
        "\n",
        "맨 위의 상수 설정 필수"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import json\n",
        "\n",
        "SFT_MODEL_NAME = './drive/MyDrive/Models/final_SFT_F'\n",
        "PPO_MODEL_PATH = './drive/MyDrive/Models/final_PPO_light_F'\n",
        "PPO_MODEL_EVAL_DATA_PATH = './drive/MyDrive/Models/eval_response_kogpt2F.txt'\n",
        "\n",
        "with open('./drive/MyDrive/Models/eval_queries.jsonl', 'r') as r:\n",
        "\teval_queries = json.load(r)\n",
        "\n",
        "PROMPT_LIST = [query['query'] for query in eval_queries]\n",
        "print(PROMPT_LIST[:10])\n",
        "\n",
        "# PROMPT_LIST = [\n",
        "#   '나 기분 좋아서 옷 샀어',\n",
        "# \t'나 오늘 좋은 일 있어서 신발 샀어',\n",
        "# \t'나 기분 안 좋아서 쇼핑다녀왔어',\n",
        "# \t'너 기분 안 좋아보여서 아이스크림 사왔어',\n",
        "# \t'나 돈 모아서 컴퓨터 샀어',\n",
        "# \t'나 학교 가는 길에 교통사고 났어',\n",
        "# \t'나 기분 안 좋아서 머리 잘랐어',\n",
        "# \t'요즘 취업 준비하느라 힘들어',\n",
        "# \t'오늘 늦게일어나서 대충 머리감고 나왔어',\n",
        "# \t'걔가 너 싫어한대',\n",
        "# \t'나 배탈 난 것 같아',\n",
        "# \t'나 감기 걸린 것 같아',\n",
        "# \t'코로나 걸렸어',\n",
        "# \t'시험에 떨어졌어',\n",
        "# \t'우울해서 아이패드 샀어',\n",
        "# \t'나 부모님한테 혼났어',\n",
        "# \t'이러면 아무도 너 안 좋아해',\n",
        "# ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfoxLdDKQbdL",
        "outputId": "bcb06320-a64e-4b71-8e8a-6c2f51b5e3d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "['모르겠어. 약간 특수 펌 같기도 하던데', '어 업무가 너무 힘들어서 그런지 맨날 전화 와서 운다 ㅠ', '사랑해서 결혼하는데 무슨 기를 꺾어...', '건강해지는 방법이라고? 왜?', '어우 맞아요! 전 그거 보고 너무 미안해지더라고요', '아니 궁금해서 눈을 못 떼겠던데', '고등학교 때 가사 수업 하기 싫어서 선택했지', '첫째 누나 무섭다 그러고 둘째 누나는 착하다 그러더라', '요즘 엄마들은 교육열 장난 아닐 듯...', '경주에 엑스포도 있었어? 처음 들어보는데?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcRr_cZThBqa"
      },
      "outputs": [],
      "source": [
        "# import\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "from chatgpt.models.gpt import GPTActor\n",
        "from transformers import AutoTokenizer\n",
        "from transformers.models.gpt2.tokenization_gpt2 import GPT2Tokenizer\n",
        "import os\n",
        "\n",
        "# data config\n",
        "IGNORE_INDEX = -100\n",
        "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
        "DEFAULT_EOS_TOKEN = \"</s>\"\n",
        "DEFAULT_BOS_TOKEN = \"</s>\"\n",
        "DEFAULT_UNK_TOKEN = \"</s>\"\n",
        "PROMPT_DICT = {\n",
        "    \"prompt_input\":\n",
        "    (\n",
        "     \"### Instruction(명령어):\\n{prompt}\\n\\n### Input(입력):\\n{input}\\n\\n### Response(응답):\"\n",
        "     ),\n",
        "    \"prompt_no_input\":\n",
        "    (\n",
        "     \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_hA3_OChEwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c39797b3-81b5-4049-dad1-5272005e6fbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "# define argment\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--model',\n",
        "                    default='gpt2')\n",
        "# We suggest to use the pretrained model from HuggingFace, use pretrain to configure model\n",
        "parser.add_argument('--pretrain', type=str, default=None)\n",
        "parser.add_argument('--model_path', type=str, default=None)\n",
        "parser.add_argument('--input',\n",
        "                    type=str,\n",
        "                    default='Question: How are you ? Answer:')\n",
        "parser.add_argument('--max_length', type=int, default=250)\n",
        "args_inference = parser.parse_args([])\n",
        "\n",
        "args_inference.model = 'gpt2'\n",
        "args_inference.pretrain = SFT_MODEL_NAME\n",
        "args_inference.model_directory = PPO_MODEL_PATH\n",
        "args_inference.model_path = os.path.join(args_inference.model_directory, 'actor.pt')\n",
        "\n",
        "# configure model, tokenizer\n",
        "actor = GPTActor(pretrained=args_inference.pretrain).to(torch.cuda.current_device())\n",
        "# tokenizer = GPT2Tokenizer.from_pretrained(args_inference.pretrain)\n",
        "# tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "                                          padding_side=\"right\",\n",
        "                                          model_max_length=512)\n",
        "tokenizer.add_special_tokens({\n",
        "    \"eos_token\": DEFAULT_EOS_TOKEN,\n",
        "    \"bos_token\": DEFAULT_BOS_TOKEN,\n",
        "    \"unk_token\": DEFAULT_UNK_TOKEN,\n",
        "})\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "state_dict = torch.load(args_inference.model_path, map_location='cpu');\n",
        "actor.model.load_state_dict(state_dict);\n",
        "\n",
        "actor.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTuxkw5bhEmJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe7b49e1-33f5-455d-fdc1-4485925cb5a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "모르겠어. 약간 특수 펌 같기도 하던데\n",
            "\n",
            "### Response(응답):응, 맞아. 그런 느낌이야. 너도 그런 특수 시술을 받고 싶어해?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "어 업무가 너무 힘들어서 그런지 맨날 전화 와서 운다 ᅲ\n",
            "\n",
            "### Response(응답):그래서 조금은 지칠 때가 있잖아. 어떻게 하면 좀 쉬어질까?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "사랑해서 결혼하는데 무슨 기를 꺾어...\n",
            "\n",
            "### Response(응답):사랑한다는 의지와 의지가 있으시군요! 어떤 상황에서 그런 인연을\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "건강해지는 방법이라고? 왜?\n",
            "\n",
            "### Response(응답):아마 도움이 필요하면 같이 할 것 같아.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "어우 맞아요! 전 그거 보고 너무 미안해지더라고요\n",
            "\n",
            "### Response(응답):그랬군요. 그러면 나중에 다른 영화 추천해주세요!\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "아니 궁금해서 눈을 못 떼겠던데\n",
            "\n",
            "### Response(응답):아, 그렇군요. 궁금한 것이 있으면 언제든지 말해봐요. 함께 고민해 볼까요?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "고등학교 때 가사 수업 하기 싫어서 선택했지\n",
            "\n",
            "### Response(응답):아, 그렇구나. 그때는 정말 많이 외로웠겠다. 어떤 노래를 부르면서 그랬어?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "첫째 누나 무섭다 그러고 둘째 누나는 착하다 그러더라\n",
            "\n",
            "### Response(응답):네, 그렇군요. 강아지가 항상 착하게 대해주시는데, 첫째가 자꾸 무섭다면\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "요즘 엄마들은 교육열 장난 아닐 듯...\n",
            "\n",
            "### Response(응답):네, 요즘은 새로운 교육이 많이 배우고 있는 것 같아요.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "경주에 엑스포도 있었어? 처음 들어보는데?\n",
            "\n",
            "### Response(응답):응, 맞아. 그런데 가보면 항상 예쁘고 멋진 음식들이 많이 있더라.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "근데 진짜 기술이 발달을 해 가지고~ 우리 어릴 때 전기차가 어었냐\n",
            "\n",
            "### Response(응답):네, 우리 어릴 때 전기차가 유행했었는데 지금은 SUV도 많이 있답니다.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "오 해외는 어디가 좋았어?\n",
            "\n",
            "### Response(응답):나는 국내는 일본이나 동남아 같은 곳에 관심이 없었어. 그래도 미국이나 유럽 같은 나라는\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "운이 나빠서 현역으로 갔군요\n",
            "\n",
            "### Response(응답):그래도 좋았던 추억이 있나봐요! 혹시 군대에서 어떤 일들을 경험하셨나요?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "그거는 지방 cc당 얼마 이렇게 측정하는 거 같던데?\n",
            "\n",
            "### Response(응답):맞아, CIVP- LvR형은 지방세대로 인식해줘야 해.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "우리가... 어땠더라... 둘 다 이상했던 것 같은데\n",
            "\n",
            "### Response(응답):아 그러네요. 우리도 서로 이상하지 않았나봐요. \n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "오늘 아침은 내가 요리사야~\n",
            "\n",
            "### Response(응답):그래 그래, 그거 좋은 생각이야! 같이 먹자!)\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "뭐? 무인 택시? 그게 가능함?\n",
            "\n",
            "### Response(응답):음, 보통은 택시를 이용할 수 있어요. 보통은 대부분 인터넷에서 구매할 수 있어요.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "너무 추워. 요새 극세사 이불 덮고 잔다\n",
            "\n",
            "### Response(응답):어떡해? 이불 덮고 자는게 좋겠다.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "오... 그 생각 한번 해봤는데...\n",
            "\n",
            "### Response(응답):응, 해봤어. 꽤 재미있었어. 다음에 같이 가자!\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "지방은 노노해~ 닭가슴살 먹어랏\n",
            "\n",
            "### Response(응답):음.. 그러면 다른 맛집에서 먹을까요? 지방노해도 좋아하세요!\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "응답하라 1997에서도 너무 매력 있게 나왔어 연기도 잘하고\n",
            "\n",
            "### Response(응답):오! 그럼 이번에도 같이 봐야겠네! 어떤 장면이 가장 기억에 남았어?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "응 내가 겪은 거로 충분하다 ᅲ...\n",
            "\n",
            "### Response(응답):그래, 나도 그렇게 생각해. 그 시절 추억이 생각나.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "안 그래도 요즘 빠르면 유아 영어 시작한다고 해서 시켜볼까 싶어\n",
            "\n",
            "### Response(응답):저도 영어 배우고 싶어요! 어떤 언어를 배우고 싶은지 정해보세요.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "멋지네여? 이것 역시 인생 선배의 조언인가요?\n",
            "\n",
            "### Response(응답):네, 그렇습니다. 인생 선배들과 함께하는 추천 메뉴는 대부분 맛있어요.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "영화관에서 봐야 잼 나는데\n",
            "\n",
            "### Response(응답):진짜? 그럼 함께 영화를 보는 건 어때? 좋아!\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "뭐래 모바일로 카트라이더 나왔거든\n",
            "\n",
            "### Response(응답):아 그래? 재밌었어? 게임 추천해줄만한 게임 있어?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "너 그거 알아 풋풋인가? 자동차 게임?\n",
            "\n",
            "### Response(응답):응응 맞아! 그거 재밌어! 나도 이 게임을 해보고 싶다.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "그니까 현질 하면 유행 지나가도 해 놓은 게 있으니 아까워서 계속할만함\n",
            "\n",
            "### Response(응답):그렇지만 현질하면 게임은 같이 즐기면서 재미를 찾는 게 중요해!\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "하하 맞아 나 해운대 영화 보고 맨날 해일 일어나면 어디로 도망가야지 고민했잖아\n",
            "\n",
            "### Response(응답):맞아! 나도 그래~ 이젠 그 곳으로 가야지~\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "셋이서 큰 영화관에 누워서 봄\n",
            "\n",
            "### Response(응답):그럼 영화를 볼 때는 항상 **가 편안해 보여줘!\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "혼자 살면서 반려동물 키우면서 사는 사람들 많으니 그런 산업들이 진짜 발전 많이 하겠네\n",
            "\n",
            "### Response(응답):맞아요. 다양한 인종과 지구의 혼혈 문제를 해결하시는\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "너 정말 지독하게 혼자 살찌기 싫구나...? 배달앱 켰다\n",
            "\n",
            "### Response(응답):응, 그래서 나는 자주 시켜먹었어. 근데 나 혼자 사니 좀 무섭기도 해.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "맞아 이제 강아지들도 겨울옷 장만해야겠어\n",
            "\n",
            "### Response(응답):네, 그렇네요. 강아지들은 겨울을 더욱 따뜻하게 보내는 것 같아요. 어떤\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "언제까지 버스 타고 다녀야 하냐 \n",
            "\n",
            "### Response(응답):네, 버스 타고 다녀야 합니다. 어디 가실 건가요?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "나 술쟁이잖아 부어라 마셨어\n",
            "\n",
            "### Response(응답):나도 술쟁이는 못 좋아해. 그런데 나 혼자 힘으로 해결할 수 있을까...?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "그건 좀 에바다 감옥도 아니고  \n",
            "\n",
            "### Response(응답):에바다 감옥도 좋은 영화죠! 어떤 영화인가요? 추천해주시겠어요?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "응 우리 엄마도 맨날 그렇게 말씀하셔\n",
            "\n",
            "### Response(응답):그러면 우리 엄마는 항상 그랬으면 좋겠다.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "이러다가 진짜 매년 맞을 것 같기도 하고\n",
            "\n",
            "### Response(응답):맞아요. 그래도 건강 관리는 항상 중요해요.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "이렇게 안 돌아 다녀서 어떻게\n",
            "\n",
            "### Response(응답):다른 여행지로 여행을 가는 것도 좋을 것 같아요. 어디를 가볼까요?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "무슨 소리임? 너 KTX나 SRT 한번도 안 타봤음?\n",
            "\n",
            "### Response(응답):응, KTX는 아직 안 타봤어. 추천해.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "아 맞아 식당 알려줘서 고마워!\n",
            "\n",
            "### Response(응답):네, 맛있는 음식을 자주 먹는 편입니다. 어떤 음식이 좋으세요?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "알 것 같다 잘했네 웃겨 정말\n",
            "\n",
            "### Response(응답):그래서 나도 잘했어! 다행이야  웃겨)\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "나도! 근데 최근에 이광수 하차했잖아  \n",
            "\n",
            "### Response(응답):맞아! 나도 최근에 너무 이발신을 해서 이발사를 다녀왔어. 그래서 어떤 일이 있었어?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "어 재밌긴 하겠다 나도 경험해 보고 싶어\n",
            "\n",
            "### Response(응답):그러면 같이 가서 해보는 건 어때? !\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "응 그러자 새 노선도 체험해보고 심심하지 않게 가고! 좋다\n",
            "\n",
            "### Response(응답):네, 그런 방법도 있죠! 언젠가 그런 경험이 있으면 좋겠죠?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "저번에도 받았어 언니?\n",
            "\n",
            "### Response(응답):아니요, 그냥 작년에는 받지 않았어요. 저도 작년에는 받지 않았어요.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "그니까... 회사 다닐 때는 병원도 정해 주고 하던데...\n",
            "\n",
            "### Response(응답):네, 맞아요. 병원은 꾸준하게 관리하면 할만할 수 있어서 좋아요. 근데 병원은 좀 많이 힘들\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "응... 생각만 해도 숨이 막힌다...\n",
            "\n",
            "### Response(응답):응, 정말 힘들겠다. 정말 힘들면 그만둬도 돼.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "아 좋은 회사네 거기 어디야?\n",
            "\n",
            "### Response(응답):저도 가보고 싶어요. 혹시 가고 싶은 이유가 뭐에요?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "와우... 그렇게나 많이 한다고? 안 힘드니\n",
            "\n",
            "### Response(응답):네, 운동은 영양과 영양학이 가장 유명합니다. 다양한 종류의 운동들을 많\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "그래서 그런가\n",
            "\n",
            "### Response(응답):아마도 새로운 것을 배우는 것도 좋은 일이에요.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "그게 게임이야? 그냥 프로그램이잖아.\n",
            "\n",
            "### Response(응답):네, 제가 그 프로그램을 자주 플레이하고 있어요. 특히 \"Funz 활동과 비타민보이즈\"라는 프로그램을\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "그러게나 말이다... 디자인 이쁜 게 확실히 비싸네  \n",
            "\n",
            "### Response(응답):네, 요즘 SUV는 높은 시야각이 단점으로 인해 안전성이 높지 않아요. 그러나 그만큼 경제\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "부모님이 보시는구나\n",
            "\n",
            "### Response(응답):응, 엄마께서는 오늘 집에서 푹 쉬세요!\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "근데 나는 성형수술 좀 별로라서 하고 싶은 마음은 없는데 진짜 경이롭더라\n",
            "\n",
            "### Response(응답):나도 그렇긴 하지만 그래도 성형수술은 큰 도전이고 내 인생에서 큰 도움이 될 거라고 생각해!\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "갈비뼈를 제거하는 건 진짜 난 절대 이해 못함\n",
            "\n",
            "### Response(응답):네, 갈비뼈가 없다면 좋은 결과가 나올 수 있을 거 같아요.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "언제부터 잔 거야 치과 다녀오고 나서?\n",
            "\n",
            "### Response(응답):아직은 여행 계획이 없어서 잘 모르겠어. 그래도 한번 해보는 건 어때?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "코로나 끝나도 지금이랑 비슷하려나 \n",
            "\n",
            "### Response(응답):맞아요. 지금은 여행이나 소통을 하면서 서로 알아가는 것이 중요해요.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "응응 말티즈거든? 근데 할머니 할아버지가 맛있는 걸 계속 줬는데 살이 네모로 쪄 귀엽지\n",
            "\n",
            "### Response(응답):오! 그래서 이게 진짜 귀여워!\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "맞아... 이제 가을이라서 점점 밖에 빨래 널기 힘든데  \n",
            "\n",
            "### Response(응답):네, 가을은 날씨도 따뜻하고 계절의 변화가 아직 느껴지네요. 그래도 나들이 가는 것이 추천\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "지금은 절대 못해\n",
            "\n",
            "### Response(응답):왜 그렇게 무서워해요? 무서워하지 마세요.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "뭐꼬 낚시터? 낚시터에서 잡아도 먹어도 됨...?\n",
            "\n",
            "### Response(응답):음... 낚시를 하면서 낚시를 하는 건가요? 그럼 스노보트나 이불이나 담요 같은 것도\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "엄마 나 버스 탔어\n",
            "\n",
            "### Response(응답):어디로 가셨어요? 좋은 추억이 되겠네요!\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "아 맞어! 그렇게 가서 거기서 사는 애들도 만나고 재미있었지\n",
            "\n",
            "### Response(응답):그랬구나, 다음에 가서 맛있는 음식으로 유명한 음식점에서 회식도 해봐야겠다.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "뭐야 엄청 비싼 운동이였네 달에 30이라니\n",
            "\n",
            "### Response(응답):아, 그러면 조금 비싸지 않았나봐요. 제가 살던 곳도 하루에 30만원 이상이였어요.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "어휴 좀 있으면 아주 아예 대놓고 기능 소개도 쫙 나열할 듯\n",
            "\n",
            "### Response(응답):그렇죠! 요새 군인들의 일들이 점점 늘어나서 소개팅은 어떨까요?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "넌 싫어하는 동물 있어?\n",
            "\n",
            "### Response(응답):저는 동물을 좋아해서 다들 별로 좋아하지 않아요.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "언니 멕시코에서 7.1 강진 일어났대  \n",
            "\n",
            "### Response(응답):정말 끔찍한 일이에요. 근데 왜 그렇게 생각하게 됐어요?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "군대에서는 뭔가 디게 시끄럽고 듣기 싫었어\n",
            "\n",
            "### Response(응답):아, 그러셨군요. 제가 잘못 이해한 것 같아요. 군대는 사람들이 시끄러움을 느끼기 때문에\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "크으 대박이지... 근데 응답하라 봐 재밌어\n",
            "\n",
            "### Response(응답):네, 응답하라 진짜 재밌어요. 언제 봤어요?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "트레일 트럭 몰면서 유럽에서 여행도 하면서 배달하는 게임이야\n",
            "\n",
            "### Response(응답):와, 정말 멋진 경험이에요! 유럽에서도 다양한 즐길 거리를 경험할 수 있겠네요. 어떤\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "나는 오빠가 물 떠와라 라면 끓여라 불 꺼라 그러는데 너는?\n",
            "\n",
            "### Response(응답):아하, 그럴 수도 있어. 오빠도 건강 조심하면서 지낼래?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "아 그래?너무 멀던데 남해 치고  넌 가봄?\n",
            "\n",
            "### Response(응답):어디로 가봤어? 나한테 배우는 거면 추천해줘!!\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "응응 좋아하고 잘 먹는 편? 하하\n",
            "\n",
            "### Response(응답):음... 나는 매운 음식을 좋아하지 않아. 그래도 당신은 매운 음식을 좋아하나봐?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "괜찮아 알아서들 잘 살겠지 하하\n",
            "\n",
            "### Response(응답):네, 그렇게 자신감 갖고 살아봐요! \n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "아니 나는 근데 언니가 뭐 하는지 동생이 뭐 하는지 다 관심 없어... 인생은 혼자\n",
            "\n",
            "### Response(응답):나도 그래. 동생이 뭐하는 건 알아? 형님이 이제 조카\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "그러니까 그걸 못 잡으니까 진짜 더 속상함  \n",
            "\n",
            "### Response(응답):그래도 그 일로 인해서 서로 속상하고 안타깝게 느껴지는 사람은 없나봐요. 그래도 함께 노력\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "이제 9월 초인데 벌써 바꿔야 하나...\n",
            "\n",
            "### Response(응답):이번에 바꾸고 싶은 것도 있어요! 바꾸고 싶으면 언제 바꿀 수 있을지 생각해보세요.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "그냥 우리 부모님 인생에 결혼식은 포기해야겠다.\n",
            "\n",
            "### Response(응답):그래! 나도 그래. 우리 부모님도 우리 가족처럼 행복하게 살아나가자!\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "말도 마라... 나랑 팀장님이랑 죽을라 한다...\n",
            "\n",
            "### Response(응답):그래, 팀장님이랑 함께하면 더 좋은 결과를 얻을 수 있을 거야. 이번에 어떤 일 있었어?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "법을 개정하나?\n",
            "\n",
            "### Response(응답):법 개정도 필요한 것 같아요. 어떻게 하면법정을수 시킬지 생각해보세요.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "아니 그럼 후기가 알바였던 거 아니야? 너무 심한데?\n",
            "\n",
            "### Response(응답):아니요, 저는 보통 네이버에서 일하는 알바를 했어요. 하지만 혹시 특정 질병이 있으면 알\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "수성못인가? 나 이번에 수성못에 갔었거든\n",
            "\n",
            "### Response(응답):아, 그거 정말 재밌었겠다. 수성못에서는 어떤 생각을 했었어?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "근데 일하는 곳이 멀어 송도야\n",
            "\n",
            "### Response(응답):아쉽네요. 그래도 찾아가서 한번 만나보는 건 어때요?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "막 난 왜 남친룩 이런 게 이쁜지 모르겠어 캐쥬얼 좋아해서 그른가\n",
            "\n",
            "### Response(응답):아! 그래 그 남친룩도 예쁘고 깔끔해. 나도 그남친룩 정말 좋아~\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "야 요즘엔 아들 군대 보낸 엄마들이 육군 사단장? 뭐 그런 사람 단톡방 만들어서 훈련한 거 사진 찍어 달라 한다더라\n",
            "\n",
            "### Response(응답):아 그래요? 그러면 부모님들 함락 ᄒᄒ\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "그러게 말이다  아 오늘 업무 너무 많아서 정신이 하나도 없다\n",
            "\n",
            "### Response(응답):일이 너무 많아서 정신이 하나도 없어 보이네요.. 어서 일 끝내고 카페에서 만나서 커피 한잔 함께\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "그 집 산 사람들 횡재했네요\n",
            "\n",
            "### Response(응답):그 집 주인님한테 얘기해 봐요. 혹시 괜찮은가요?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "어어 케이크 먹을 때는 나도 그냥 아메리카노가 좋더라고 느끼한 게 싹 가라앉는 느낌\n",
            "\n",
            "### Response(응답):그래서 나는 커피를 좋아해. 너는 어떤 케이크를 좋아해?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "응응 뉴스에 어제부터 나왔어 바보야\n",
            "\n",
            "### Response(응답):오, 그렇군요. 무슨 일이 있었나요?)\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "그니깐... 평소에는  폼클렌징만 해서 근가?\n",
            "\n",
            "### Response(응답):아뇨, 평소에는 그냥 클렌징으로 거칠게 표현하시는 거예요.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "그래도 막 설레려나?\n",
            "\n",
            "### Response(응답):당연하지! 나는 스키보다는 설레이던게 제일 좋아. 언제 한번 같이 스키장 가봐요!\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "응 지금 달리는 지옥철 안이야 하하\n",
            "\n",
            "### Response(응답):아하하하 그러게 이거지? 어떤 노선 타는데?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "맞아 이제 내년은 5살이라 유치원 고민이야\n",
            "\n",
            "### Response(응답):아, 그럼 어떻게 해결해보자. 함께 생각해보자.\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "그래서 운전선 쪽이 차량을 바짝 주차하면 그때부터 감정 싸움 몸싸움 나는 거지.\n",
            "\n",
            "### Response(응답):맞아요. 드라이브할 때 항상 긴장되시던데, 지금은 좀 나아졌나요?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "그 일본 여자 모더나 맞고 탈모 왔다 그래서... 코로나보다 탈모가 더 무서운 것...\n",
            "\n",
            "### Response(응답):탈모는 정말 무서운 일이죠. 그 사람의 코로나19 증상이 언제 나타나는데\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "알았어 시킬게 근데 내가 좋은 샴푸 하나 알아 왔어\n",
            "\n",
            "### Response(응답):오 좋은 샴푸를 감사해! 어떤 종류의 샴푸를 좋아해?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "나는 가족들끼리 살 땐 주택만 살아서 주택이 좋았는데 지금은 아파트 ᄏ\n",
            "\n",
            "### Response(응답):주택은 조용하고 편안한 분위기가 느껴지는 좋은 층간이인 것 같아!\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "뭐... 나는 미국 가서 살 일은 없겠지만... 미국에서는 못살겠네... ᅮ\n",
            "\n",
            "### Response(응답):아, 그렇군요. 미국 음식은 어떤가요? 추천하실 만한 음식 있나요?\n",
            "######################################################################\n",
            "### Instruction(명령어):\n",
            "그러고 보니까 너도 저번에 애니메이션 보는 거 같던데?\n",
            "\n",
            "### Response(응답):응, 나는 저번에 애니메이션을 보는 걸 좋아해. 너도 저번에 애니메이션을 보는 거 좋아해?\n"
          ]
        }
      ],
      "source": [
        "## inference\n",
        "def generation(input_text):\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
        "        torch.cuda.current_device())\n",
        "    outputs = actor.generate(input_ids,\n",
        "                             max_length=args_inference.max_length,\n",
        "                             do_sample=True,\n",
        "                             top_k=50,\n",
        "                             top_p=0.95,\n",
        "                             num_return_sequences=1)\n",
        "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
        "    print('#' * 70)\n",
        "    print(output)\n",
        "    return output\n",
        "\n",
        "\n",
        "list_prompt = PROMPT_LIST\n",
        "list_prompt = [PROMPT_DICT['prompt_no_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
        "output_list = []\n",
        "\n",
        "for input_text in list_prompt:\n",
        "    output = generation(input_text)\n",
        "    output_list.append(output.split(\"Response(응답):\")[1])\n",
        "\n",
        "with open(PPO_MODEL_EVAL_DATA_PATH, 'w') as w:\n",
        "  w.write('\\n'.join(output_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BLEU 스코어 측정"
      ],
      "metadata": {
        "id": "LLaREfmQfLh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "code로 작성하는 것보단, 추론 결과를 전달해줘서 한 코드에서 돌리는 것이 좋겠다!\n",
        "bleu_score vs sententce_blue?"
      ],
      "metadata": {
        "id": "kDsu5ex-lqfO"
      }
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "51f53054f35c43609fefbef62ee8ed92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1958146b06b4e29bb8794fabc775a5f",
              "IPY_MODEL_ad4eb471a04748ff897d55cb60dfab4d",
              "IPY_MODEL_98d1e8ee6204491e9e7f0462d84ff49c"
            ],
            "layout": "IPY_MODEL_463dc4f821394b159e9432b480ea8b88"
          }
        },
        "d1958146b06b4e29bb8794fabc775a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_891388bbcdcc45609401a21daaedf958",
            "placeholder": "​",
            "style": "IPY_MODEL_45f977b115e74b27b29bfafdaacc12cf",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "ad4eb471a04748ff897d55cb60dfab4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a5354b120b14a3196ddb68d7eee6984",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49615a5471ec4dfaa680ce17bbdb0b20",
            "value": 1000
          }
        },
        "98d1e8ee6204491e9e7f0462d84ff49c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e09124830fe34f1188de39b032442e71",
            "placeholder": "​",
            "style": "IPY_MODEL_c04152833afd4698a433b412e7cdaa34",
            "value": " 1.00k/1.00k [00:00&lt;00:00, 37.8kB/s]"
          }
        },
        "463dc4f821394b159e9432b480ea8b88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "891388bbcdcc45609401a21daaedf958": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45f977b115e74b27b29bfafdaacc12cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a5354b120b14a3196ddb68d7eee6984": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49615a5471ec4dfaa680ce17bbdb0b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e09124830fe34f1188de39b032442e71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c04152833afd4698a433b412e7cdaa34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae570e523488454db2e15497cb559193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3aacfbe5cea742cb9c14b3fd7d83a22f",
              "IPY_MODEL_b545ebc814c84849a3a4135b4e63eecc",
              "IPY_MODEL_97e9d31cb0944577b8af3474ff4de4d0"
            ],
            "layout": "IPY_MODEL_249beea318ff4a7c8a79c404e4eb396f"
          }
        },
        "3aacfbe5cea742cb9c14b3fd7d83a22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb64d32bee974a1e94a78b743e8edd8d",
            "placeholder": "​",
            "style": "IPY_MODEL_9e35effea1de4071978b21429e35e101",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "b545ebc814c84849a3a4135b4e63eecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a7738b9877e4446b94149ec5c10c720",
            "max": 2825034,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5908361288184762b6b783a15d0658b5",
            "value": 2825034
          }
        },
        "97e9d31cb0944577b8af3474ff4de4d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d70d737823f4ccfb761e3f53bef1e33",
            "placeholder": "​",
            "style": "IPY_MODEL_9b11074f6edb4f899c10eb2764def0d5",
            "value": " 2.83M/2.83M [00:00&lt;00:00, 26.3MB/s]"
          }
        },
        "249beea318ff4a7c8a79c404e4eb396f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb64d32bee974a1e94a78b743e8edd8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e35effea1de4071978b21429e35e101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a7738b9877e4446b94149ec5c10c720": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5908361288184762b6b783a15d0658b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d70d737823f4ccfb761e3f53bef1e33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b11074f6edb4f899c10eb2764def0d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c42212169dd142b187891ae00899cdbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90421c9714764cb58b12cbd97425210f",
              "IPY_MODEL_d416153857704318bf073727295c7f17",
              "IPY_MODEL_fdb7094202424f43815dc444891e83a1"
            ],
            "layout": "IPY_MODEL_c0eca855ae2b4043a16226e5aa0e104d"
          }
        },
        "90421c9714764cb58b12cbd97425210f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebfe23c3b0e24c8db6db9d25295d0d4d",
            "placeholder": "​",
            "style": "IPY_MODEL_01cf0d336a5d40178b7d9d44a2a29534",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "d416153857704318bf073727295c7f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_287f1dac848148e7abfff0f2fd2f7bee",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c5e4848adc34783ac1edf6df3a1e3f3",
            "value": 1000
          }
        },
        "fdb7094202424f43815dc444891e83a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_645f7c7da3a242f6bd109435a3abe248",
            "placeholder": "​",
            "style": "IPY_MODEL_934a7cc9ac394bd9a887def3254a97e6",
            "value": " 1.00k/1.00k [00:00&lt;00:00, 40.5kB/s]"
          }
        },
        "c0eca855ae2b4043a16226e5aa0e104d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebfe23c3b0e24c8db6db9d25295d0d4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01cf0d336a5d40178b7d9d44a2a29534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "287f1dac848148e7abfff0f2fd2f7bee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c5e4848adc34783ac1edf6df3a1e3f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "645f7c7da3a242f6bd109435a3abe248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "934a7cc9ac394bd9a887def3254a97e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0bfc5fa5c4a44798b661b3917d459e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_091d6922084d4c37bcf32d44cc922a13",
              "IPY_MODEL_407fc7a4381e45ed8055cfd1084dce03",
              "IPY_MODEL_cb2b71e3663241189724139c53d1308c"
            ],
            "layout": "IPY_MODEL_6d9fdac856d74d6c884944e177b60345"
          }
        },
        "091d6922084d4c37bcf32d44cc922a13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f323550d64be4ab8bd96dcde3b20e5f6",
            "placeholder": "​",
            "style": "IPY_MODEL_5ef6968a652849abbd3d9c79ea65d59e",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "407fc7a4381e45ed8055cfd1084dce03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d24caf9a62f40f88ad911c77888f0c6",
            "max": 2825034,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39c3b738fe164a639b6a2b80ebed4373",
            "value": 2825034
          }
        },
        "cb2b71e3663241189724139c53d1308c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e017504dc5f741d0b1afbabc3b316f1d",
            "placeholder": "​",
            "style": "IPY_MODEL_899a004ed222431ba0635181c4ee60a7",
            "value": " 2.83M/2.83M [00:01&lt;00:00, 2.16MB/s]"
          }
        },
        "6d9fdac856d74d6c884944e177b60345": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f323550d64be4ab8bd96dcde3b20e5f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ef6968a652849abbd3d9c79ea65d59e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d24caf9a62f40f88ad911c77888f0c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39c3b738fe164a639b6a2b80ebed4373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e017504dc5f741d0b1afbabc3b316f1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "899a004ed222431ba0635181c4ee60a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}